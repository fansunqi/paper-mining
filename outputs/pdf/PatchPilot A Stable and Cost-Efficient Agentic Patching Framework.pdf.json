{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Software patching",
    "Automated bug fixing"
  ],
  "datasets": [
    "SWE-Bench-Lite",
    "SWE-Bench-Verified"
  ],
  "methods": [
    "Human-based planning",
    "LLM-driven",
    "Reproduction",
    "Localization",
    "Generation",
    "Validation",
    "Refinement"
  ],
  "results": [
    "45.33% resolved rate on SWE-Bench-Lite",
    "53.60% resolved rate on SWE-Bench-Verified",
    "0.97$ cost per instance on SWE-Bench-Lite",
    "0.99$ cost per instance on SWE-Bench-Verified"
  ],
  "title": "PatchPilot A Stable and Cost-Efficient Agentic Patching Framework.pdf",
  "abstract": "Recent research builds various patching agents that combine large language models (LLMs) with non-ML tools and achieve promising results on the state-of-the-art (SOTA) software patching benchmark, SWE-Bench. Based on how to deter- mine the patching workflows, existing patching agents can be categorized as agent-based planning methods, which rely on LLMs for planning, and human-based planning methods, which follow a pre-defined workflow. At a high level, agent- based planning methods achieve high patching performance but with a high cost and limited sta- bility. Human-based planning methods, on the other hand, are more stable and efficient but have key workflow limitations that compromise their patching performance. In this paper, we propose PatchPilot, an agentic patcher that strikes a bal- ance between patching efficacy, stability, and cost- efficiency. PatchPilot proposes a novel human- based planning workflow with five components: reproduction, localization, generation, validation, and refinement (where refinement is unique to PatchPilot). We introduce novel and customized designs to each component to optimize their effec- tiveness and efficiency. Through extensive experi- ments on the SWE-Bench benchmarks, PatchPilot shows a superior performance than existing open- source methods while maintaining low cost (less than 1$ per instance) and ensuring higher stabil- ity. We also conduct a detailed ablation study to validate the key designs in each component. 1. Introduction Automatic patching of issues and vulnerabilities has long been a challenging task in software engineering and secu- rity (Jiang et al., 2021; Le Goues et al., 2021; Monperrus, 2018; Gazzola et al., 2018). Before the emergence of gen- erative AI, automated code generation primarily relied on 1Department of Computer Science, University of California, Santa Barbara, USA 2Meta, New York, USA. Correspondence to: Wenbo Guo <henrygwb@ucsb.edu>. program synthesis (Feng et al., 2018; Huang et al., 2019), which requires human-written specifications and cannot be applied to complex programs due to the constraints of SMT solvers. With the recent success of LLMs in various gen- erative tasks (Peng et al., 2023; Lian et al., 2023; Ghosal et al., 2023; Huang et al., 2024), particularly in code genera- tion (Zhu et al., 2024; Anthropic, 2024; Achiam et al., 2023; Team et al., 2023; Roziere et al., 2023), researchers recently started exploring their applications in automatically fixing software vulnerabilities. They build LLM-based agents that automatically analyze and fix issues in real-world code- bases (Wang et al., 2024b; Liu et al., 2024; Ruan et al., 2024; Zhang et al., 2024; Yang et al., 2024a). Technically speaking, existing patching agents consist of three main components: localization, generation, and val- idation. The localization component identifies the code snippets responsible for the issue that need to be fixed. The generation component produces patch candidates, while the validation component selects the final patch from candi- dates. There are two ways to schedule these components: agent-based planning(Yang et al., 2024a; moatless, 2024; Zhang et al., 2024; IBM, 2024; Liu et al., 2024; CodeR, 2024; Pedregosa et al., 2011; Ma et al., 2024; Wang et al., 2024b; Amazon, 2024), which utilizes LLMs to dynami- cally determine the patching workflow for different issues; and human-based planning(Xia et al., 2024; Ouyang et al., 2024) that follows a fixed, predefined workflow for all is- sues, as specified by humans. Although achieving high patching performance, agent-based planning methods suffer a high cost and are not stable, which significantly limits their applicability in the real world. In contrast, existing human- based planning methods are more stable and cost-efficient but have limited patching performance due to limitations in their planning workflows. In this paper, we present PatchPilot, a novel patching frame- work that balances the patching efficacy, stability, and cost- efficiency. At a high level, PatchPilot designs a human-based planning workflow composed of five components: repro- duction, localization, generation, validation, and refinement. Given an issue as input, PatchPilot first reproduces the is- sue and retrieves related testing cases and finds the root cause (code snippets causing the issue) through localiza- tion. Its generation and validation components then generate patch candidates and validate whether they fix the issues 1 arXiv:2502.02747v1 [cs.RO] 4 Feb 2025"
}