{
  "code_links": [
    "None"
  ],
  "tasks": [
    "AI governance"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Complexity theory"
  ],
  "results": [
    "Proposed a set of complexity-compatible principles for AI governance"
  ],
  "title": "Lessons from Complexity Theory for AI Governance.pdf",
  "abstract": "The study of complex adaptive systems, pioneered in physics, biology, and the social sciences, o\ufb00ers important lessons for AI governance. Contem- porary AI systems and the environments in which they operate exhibit many of the properties characteristic of complex systems, including non- linear growth patterns, emergent phenomena, and cascading e\ufb00ects that can lead to tail risks. Complexity theory can help illuminate the features of AI that pose central challenges for policymakers, such as feedback loops induced by training AI models on synthetic data and the interconnected- ness between AI systems and critical infrastructure. Drawing on insights from other domains shaped by complex systems, including public health and climate change, we examine how e\ufb00orts to govern AI are marked by deep uncertainty. To contend with this challenge, we propose a set of complexity-compatible principles concerning the timing and structure of AI governance, and the risk thresholds that should trigger regulatory intervention. Correspondence to: noam.kolt@mail.huji.ac.il. 1"
}