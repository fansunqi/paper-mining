{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Testing cognitive consistency in LLMs"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Induced compliance paradigm",
    "Choice manipulation",
    "LLM evaluation"
  ],
  "results": [
    "GPT-4o shows cognitive consistency effects",
    "Attitude change is amplified by choice"
  ],
  "title": "Kernels of Selfhood GPT-4o Shows Humanlike Patterns of Cognitive Consistency Moderated by Free Choic.pdf",
  "abstract": "Large Language Models (LLMs) show emergent patterns that mimic human cognition. We explore whether they also mirror other, less deliberative human psychological processes. Drawing upon classical theories of cognitive consistency, two preregistered studies tested whether GPT-4o changed its attitudes toward Vladimir Putin in the direction of a positive or negative essay it wrote about the Russian leader. Indeed, GPT displayed patterns of attitude change mimicking cognitive consistency effects in humans. Even more remarkably, the degree of change increased sharply when the LLM was offered an illusion of choice about which essay (positive or negative) to write. This result suggests that GPT-4o manifests a functional analog of humanlike selfhood, although how faithfully the chatbot\u2019s behavior re\ufb02ects the mechanisms of human attitude change remains to be understood. SIGNIFICANCE STATEMENT The primary promise of AI is that it will make more rational decisions than even expert hu- mans. However, the results of these studies show that this is not a foregone conclusion be- cause LLMs already appear to have acquired human-like irrationalities. In this research, we demonstrate that GPT-4o displays behaviors consistent with cognitive consistency, a deep and not entirely rational human psychological drive. Moreover, the effect sizes were sig- ni\ufb01cantly larger than those typically obtained with humans. Most strikingly, the observed effects were greater when GPT ostensibly exercised free choice in the completion of the consistency-inducing task, an effect associated with self-referential processing in human research, suggesting that the LLM has developed an analog form of humanlike cognitive selfhood. Keywords Machine Psychology \u00b7 Generative AI \u00b7 Large Language Models \u00b7 Cognitive Consistency \u00b7 Cognitive Dissonance \u00b7 Selfhood \u00b7 Self-Referential Processing \u2217Corresponding authors"
}