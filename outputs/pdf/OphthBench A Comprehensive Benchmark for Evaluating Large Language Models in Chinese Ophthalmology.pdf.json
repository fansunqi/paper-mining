{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Large language model evaluation"
  ],
  "datasets": [
    "OphthBench"
  ],
  "methods": [
    "None"
  ],
  "results": [
    "Accuracy: 70% on average",
    "MMLU score improvement",
    "Prompt engineering optimization"
  ],
  "title": "OphthBench A Comprehensive Benchmark for Evaluating Large Language Models in Chinese Ophthalmology.pdf",
  "abstract": "Large language models (LLMs) have shown significant promise across various medical applications, with ophthalmology being a notable area of focus. Many ophthalmic tasks have shown substan- tial improvement through the integration of LLMs. However, before these models can be widely adopted in clinical practice, evaluating their capabilities and identifying their limitations is crucial. To address this research gap and support the real-world application of LLMs, we introduce the OphthBench, a specialized benchmark designed to assess LLM performance within the context of Chinese ophthalmic practices. This benchmark systematically divides a typical ophthalmic clinical workflow into five key scenarios: Education, Triage, Diagnosis, Treatment, and Prognosis. For each scenario, we developed multiple tasks featuring diverse question types, resulting in a comprehen- sive benchmark comprising 9 tasks and 591 questions. This comprehensive framework allows for a thorough assessment of LLMs\u2019 capabilities and provides insights into their practical application in Chinese ophthalmology. Using this benchmark, we conducted extensive experiments and analyzed the results from 39 popular LLMs. Our evaluation highlights the current gap between LLM develop- ment and its practical utility in clinical settings, providing a clear direction for future advancements. By bridging this gap, we aim to unlock the potential of LLMs and advance their development in ophthalmology. Keywords Large language model \u00b7 Ophthalmology \u00b7 Benchmarking 1 Introduction Large language models (LLMs) have revolutionized a wide range of applications driven by their remarkable ability to understand and interpret real-world contexts [1, 2, 3, 4, 5]. In the medical domain, LLMs have demonstrated significant potential across diverse applications, such as disease management [6], medical document summarization [7, 8], clinical workflows optimization [9], and patient-clinical trial matching [10, 11]. Despite these advancements, ongoing debates persist regarding the ethical use of LLM technology in healthcare, addressing concerns such as \u201challucination\u201d(generating plausible-sounding but inaccurate or misleading content), biases inherent in training data, and broader ethical considerations [12, 13, 14, 15]. Accurately assessing LLMs\u2019 potential and inherent limitations is urgently needed to ensure their beneficial use for patients and practitioners. arXiv:2502.01243v1 [cs.CL] 3 Feb 2025"
}