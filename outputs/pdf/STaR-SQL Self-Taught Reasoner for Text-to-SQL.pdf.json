{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Text-to-SQL"
  ],
  "datasets": [
    "Spider"
  ],
  "methods": [
    "Reasoning-driven approach",
    "Few-shot prompting",
    "Finetuning",
    "Outcome-supervised Reward Model (ORM)"
  ],
  "results": [
    "Execution accuracy of 86.6%",
    "Outperforms few-shot baselines and baseline fine-tuned to predict answers directly",
    "Improves performance on complex queries"
  ],
  "title": "STaR-SQL Self-Taught Reasoner for Text-to-SQL.pdf",
  "abstract": "Generating step-by-step \u201cchain-of-thought\u201d ra- tionales has proven effective for improving the performance of large language models on com- plex reasoning tasks. However, applying such techniques to structured tasks, such as text-to- SQL, remains largely unexplored. In this paper, we introduce Self-Taught Reasoner for text-to- SQL (STaR-SQL), a novel approach that re- frames SQL query generation as a reasoning- driven process. Our method prompts the LLM to produce detailed reasoning steps for SQL queries and fine-tunes it on rationales that lead to correct outcomes. Unlike traditional meth- ods, STaR-SQL dedicates additional test-time computation to reasoning, thereby positioning LLMs as spontaneous reasoners rather than mere prompt-based agents. To further scale the inference process, we incorporate an outcome- supervised reward model (ORM) as a verifier, which enhances SQL query accuracy. Experi- mental results on the challenging Spider bench- mark demonstrate that STaR-SQL significantly improves text-to-SQL performance, achieving an execution accuracy of 86.6%. This sur- passes a few-shot baseline by 31.6% and a baseline fine-tuned to predict answers directly by 18.0%. Additionally, STaR-SQL outper- forms agent-like prompting methods that lever- age more powerful yet closed-source models such as GPT-4. These findings underscore the potential of reasoning-augmented training for structured tasks and open the door to extend- ing self-improving reasoning models to text-to- SQL generation and beyond. 1 Introduction Large Language Models (LLMs) have demon- strated remarkable potential in various language tasks (Brown et al., 2020; Achiam et al., 2023), including text-to-SQL translation (Rajkumar et al., 2022; Liu et al., 2023a). Interacting with com- plex relational databases typically requires both \u2020Corresponding author. programming expertise and a deep understanding of the underlying data. Text-to-SQL bridges this gap by allowing non-experts to ask questions in nat- ural language, automatically translating them into SQL queries and returning the results (Cai et al., 2017; Xu et al., 2017; Yaghmazadeh et al., 2017). Despite significant advancements in this field, most existing approaches primarily harness LLMs for their instruction-following capabilities, focus- ing on schema selection optimization and result refinement (Pourreza and Rafiei, 2024a), as illus- trated in Figure 1. However, these prompts can be rigid and consume a substantial portion of the available context tokens. Smaller open-source mod- els may also struggle to interpret and follow the carefully crafted prompts on which these methods rely. Moreover, this narrow emphasis on prompt engineering frequently overlooks the powerful rea- soning capabilities inherent in LLMs (Liu et al., 2023b; Frieder et al., 2024). While these meth- ods perform well on simple queries, they tend to falter when confronted with more complex ones (Eyal et al., 2023). This shortcoming is particularly problematic for non-experts, who may have trou- ble verifying whether the generated SQL queries accurately capture their original intent. Complex misalignments in SQL queries can be especially difficult for users to detect and correct. To address these challenges, we reconceptual- ize text-to-SQL as a reasoning-driven process, en- abling LLMs to handle complex queries by gener- ating step-by-step rationales. This approach offers several key advantages: \u2022 Robustness for Complex Queries: A step-by- step chain-of-thought reasoning method enables the model to systematically break down complex queries, handle intricate database schemas more effectively, and produce more accurate results. \u2022 Scalability through Reasoning: By allocating additional computational resources at inference arXiv:2502.13550v1 [cs.CL] 19 Feb 2025"
}