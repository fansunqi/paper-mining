{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Popular Micro-video Generation",
    "LLM-Assisted Video Creation"
  ],
  "datasets": [
    "Microlens"
  ],
  "methods": [
    "LLMPopcorn Pipeline",
    "Prompt Enhancement",
    "RAG",
    "CoT"
  ],
  "results": [
    "Competitive performance with human-created videos",
    "Enhanced popularity with prompt enhancement",
    "DeepSeek-V3 and DeepSeek-R1 excel as LLMs",
    "LTX-Video and HunyuanVideo excel as video generators"
  ],
  "title": "LLMPopcorn an Empirical Study of LLMs As Assistants for Popular Micro-video Generation.pdf",
  "abstract": "Popular Micro-videos, dominant on platforms like TikTok and YouTube, hold significant com- mercial value. The rise of high-quality AI- generated content has spurred interest in AI- driven micro-video creation. However, despite the advanced capabilities of large language models (LLMs) like ChatGPT and DeepSeek in text generation and reasoning, their potential to assist the creation of popular micro-videos remains largely unexplored. In this paper, we conduct an empirical study on LLM-assisted popular micro-video generation (LLMPopcorn1). Specifically, we investigate the following research questions: (i) How can LLMs be effectively utilized to assist popular micro-video generation? (ii) To what extent can prompt-based enhancements optimize the LLM- generated content for higher popularity? (iii) How well do various LLMs and video genera- tors perform in the popular micro-video gener- ation task? By exploring these questions, we show that advanced LLMs like DeepSeek-V3 enable micro-video generation to achieve pop- ularity comparable to human-created content. Prompt enhancements further boost popular- ity, and benchmarking highlights DeepSeek-V3 and DeepSeek-R1 among LLMs, while LTX- Video and HunyuanVideo lead in video gen- eration. This pioneering work advances AI- assisted micro-video creation, uncovering new research opportunities. We will release the code and datasets to support future studies. 1 Introduction Micro-videos (or short videos) have emerged as a fundamental element of the digital economy, repre- senting a multi-billion-dollar industry (Guo et al., 2024). They have become an integral part of daily *Corresponding author. 1We selected popcorn as the icon for this paper because it symbolizes leisure and entertainment. This aligns with this study on leveraging LLMs as assistants for generating popular micro-videos, which are often consumed during leisure time. life for people worldwide, providing substantial commercial value for social media platforms and content creators. Popular content creators can re- ceive significant revenue through their content (Ran et al., 2022), which underscores the ever-growing influence of micro-videos in modern society. Despite their widespread popularity and finan- cial impact, producing popular micro-video con- tent remains a costly and labor-intensive process. Professional filming, scripting, and editing require significant time and resources, which not all cre- ators or businesses can afford. Driven by these challenges, we explore simplifying the micro-video creation process using AI solutions, with a particu- lar focus on generating popular micro-videos. On one hand, the rapid advancement of Large Language Models (LLMs) like ChatGPT has un- locked new possibilities for content generation, demonstrating strong capabilities in tasks such as document summarization (Jin et al., 2024), pro- gramming (Cai et al., 2023; Ouyang et al., 2023), mathematical reasoning (Shao et al., 2024; Zhang et al., 2024a) and recommendation (Yuan et al., 2023; Fu et al., 2024a,b,c). On the other hand, video generation models powered by diffusion tech- niques and neural rendering are transforming cre- ative content production, enabling high-quality syn- thesis for applications in film production (Liu et al., 2024b) and interactive media (Zhang et al., 2024b). Significant breakthroughs in LLMs and video gen- eration models have prompted many studies (Zhou et al., 2024) to integrate LLM to facilitate the ca- pability of automatic video generation. For in- stance, VideoLLMs like VideoPoet (Kondratyuk et al., 2023) and GPT4Video (Wang et al., 2024) leverage LLMs and video generation models for multimodal video understanding and generation. Although LLMs can assist in video generation, existing studies have neglected the ability of differ- ent LLMs to assist in the generation of \u201cpopular\u201d micro-videos. The main reason for this is that exist- 1 arXiv:2502.12945v1 [cs.CL] 18 Feb 2025"
}