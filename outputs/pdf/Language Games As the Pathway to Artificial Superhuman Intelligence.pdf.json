{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Generating novel ideas",
    "Knowledge creation and transmission",
    "AI governance"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Language games",
    "Role fluidity",
    "Reward variety",
    "Rule plasticity",
    "Global co-evolution"
  ],
  "results": [
    "None"
  ],
  "title": "Language Games As the Pathway to Artificial Superhuman Intelligence.pdf",
  "abstract": "The evolution of large language models (LLMs) toward artificial superhuman intelligence (ASI) hinges on data reproduction, a cyclical process in which models generate, curate and retrain on novel data to refine capabilities. Current methods, however, risk getting stuck in a data reproduc- tion trap: optimizing outputs within fixed human- generated distributions in a closed loop leads to stagnation, as models merely recombine existing knowledge rather than explore new frontiers. In this paper, we propose language games as a path- way to expanded data reproduction, breaking this cycle through three mechanisms: (1) role fluid- ity, which enhances data diversity and coverage by enabling multi-agent systems to dynamically shift roles across tasks; (2) reward variety, em- bedding multiple feedback criteria that can drive complex intelligent behaviors; and (3) rule plas- ticity, iteratively evolving interaction constraints to foster learnability, thereby injecting continual novelty. By scaling language games into global so- ciotechnical ecosystems, human-AI co-evolution generates unbounded data streams that drive open- ended exploration. This framework redefines data reproduction not as a closed loop but as an engine for superhuman intelligence. 1. Introduction The evolution of large language models (LLMs) on the pathway to artificial superhuman intelligence (ASI) (Morris et al., 2023) is fundamentally driven by data reproduc- tion\u2014an iterative process where models acquire novel data streams, evaluate outputs against human feedback and task- specific ground truth, and refine capabilities through tar- geted retraining (Ouyang et al., 2022). This cyclical regen- eration of knowledge creates a dynamic interaction between model improvement and the data ecosystem, where each iteration aims to better approximate real-world linguistic pat- 1Shanghai Jiao Tong University. Correspondence to: Ying Wen <ying.wen@sjtu.edu.cn>. terns (Bommasani et al., 2021). Unlike traditional machine learning paradigms constrained by fixed training sets, mod- ern LLMs exhibit metabolic characteristics: continuously ingesting diverse inputs, transforming them through neural computations, and regenerating outputs that fuel subsequent learning cycles (Thompson, 2010). The current data production paradigms widely used in large-scale pretraining (Brown et al., 2020), supervised fine-tuning, and reinforcement learning from human feed- back (Christiano et al., 2017; Trung et al., 2024) increasingly reveal their limitations. These methods, while effective for enhancing performance in established tasks, inadvertently confine the models to a data reproduction trap. By optimiz- ing outputs within fixed distributions of human-annotated examples and user preferences, they reinforce historical biases (Shumailov et al., 2023) and prioritize short-term alignment over long-term intellectual growth. The result is a self-referential loop in which models become adept at recombining known concepts but struggle to generate fundamentally novel ideas: a stagnation akin to Marx\u2019s cri- tique of economic systems trapped in simple reproduction (Marx, 1859). This impasse demands a paradigm shift from closed-loop optimization to open-ended conceptual explo- ration, ultimately pushing toward ASI by exploring beyond established distributional boundaries. Escaping the data reproduction trap requires the transi- tion to expanded data reproduction, where models sys- tematically transcend knowledge boundaries through en- vironmental pressures. In this paper, we propose lan- guage games\u2014dynamic linguistic interaction frameworks inspired by Wittgenstein\u2019s view of meaning as use (Straw- son, 1954)\u2014as a means to operationalize expanded data reproduction. We argue that language games are the pivotal mechanism for escaping the data reproduction trap in LLMs, thereby enabling open-ended concep- tual exploration on the pathway to ASI. As stated in Fig. 1, language games establish three mutually reinforc- ing mechanisms: role fluidity enables models or agents to navigate diverse task spaces as both knowledge consumers and producers (Subramaniam et al., 2025; Shah & White, 2024; Yang et al., 2021); reward variety embodies the \u201cre- ward is enough\u201d hypothesis (Sutton & Barto, 1999; Silver et al., 2021; Chambers et al., 2024) at metacognitive levels through pluralistic success criteria; Rule plasticity sustains 1 arXiv:2501.18924v1 [cs.AI] 31 Jan 2025"
}