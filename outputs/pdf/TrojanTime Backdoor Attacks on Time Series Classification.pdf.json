{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Backdoor Attacks on Time Series Classification"
  ],
  "datasets": [
    "UCR benchmark datasets"
  ],
  "methods": [
    "Data synthesis",
    "Logits alignment",
    "BatchNorm Freezing",
    "Unlearning"
  ],
  "results": [
    "Maintained clean accuracy while achieving a high ASR",
    "Successfully reduced ASR while maintaining clean accuracy"
  ],
  "title": "TrojanTime Backdoor Attacks on Time Series Classification.pdf",
  "abstract": ". Time Series Classification (TSC) is highly vulnerable to back- door attacks, posing significant security threats. Existing methods pri- marily focus on data poisoning during the training phase, designing sophisticated triggers to improve stealthiness and attack success rate (ASR). However, in practical scenarios, attackers often face restrictions in accessing training data. Moreover, it is a challenge for the model to maintain generalization ability on clean test data while remaining vul- nerable to poisoned inputs when data is inaccessible. To address these challenges, we propose TrojanTime, a novel two-step training algo- rithm. In the first stage, we generate a pseudo-dataset using an external arbitrary dataset through target adversarial attacks. The clean model is then continually trained on this pseudo-dataset and its poisoned ver- sion. To ensure generalization ability, the second stage employs a care- fully designed training strategy, combining logits alignment and batch norm freezing. We evaluate TrojanTime using five types of triggers across four TSC architectures in UCR benchmark datasets from diverse domains. The results demonstrate the effectiveness of TrojanTime in executing backdoor attacks while maintaining clean accuracy. Finally, to mitigate this threat, we propose a defensive unlearning strategy that effectively reduces the ASR while preserving clean accuracy. Keywords: Backdoor Attack \u00b7 Backdoor Defense \u00b7 Time Series Classi- fication \u00b7 UCR2018. 1 Introduction Time series data mining has become a crucial area in modern data mining. With the advancement of deep neural networks (DNNs), an increasing number of time series classification (TSC) tasks leverage deep learning methods, especially in healthcare [25], finance [18], and remote sensing [23], etc. However, current DNNs face threats from malicious attacks [11,10,9], one of the most concerning being backdoor attacks [12,21]. In such attacks, the Trojan model produces cor- rect outputs for clean inputs but exhibits abnormal predictions when the inputs are corrupted by specific triggers. The attacker can poison the training data by \u22c6Corresponding Author arXiv:2502.00646v1 [cs.CR] 2 Feb 2025"
}