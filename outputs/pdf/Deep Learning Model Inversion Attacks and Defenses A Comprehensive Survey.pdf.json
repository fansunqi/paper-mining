{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Model Inversion Attacks and Defenses"
  ],
  "datasets": [
    "MNIST",
    "F-MNIST",
    "CIFAR-10",
    "CIFAR-100",
    "LFW",
    "CelebA",
    "ImageNet",
    "FFHQ",
    "ChestX-ray8",
    "UBMD",
    "LDC",
    "AT&T",
    "SVHN"
  ],
  "methods": [
    "Gradient Inversion",
    "Generative Model-based Attacks",
    "Optimization-based Attacks",
    "Feature Perturbation/Obfuscation",
    "Gradient Pruning",
    "Gradient Perturbation/Obfuscation",
    "Differential Privacy",
    "Cryptographic Encryption",
    "Model/Architecture Enhancement"
  ],
  "results": [
    "None"
  ],
  "title": "Deep Learning Model Inversion Attacks and Defenses A Comprehensive Survey.pdf",
  "abstract": "The rapid adoption of deep learning in sensitive domains has brought tremendous benefits. However, this widespread adoption has also given rise to serious vulner- abilities, particularly model inversion (MI) attacks, posing a significant threat to the privacy and integrity of personal data. The increasing prevalence of these attacks in applications such as biometrics, healthcare, and finance has created an urgent need to understand their mechanisms, impacts, and defense methods. This survey aims to fill the gap in the literature by providing a structured and in-depth review of MI attacks and defense strategies. Our contributions include a system- atic taxonomy of MI attacks, extensive research on attack techniques and defense mechanisms, and a discussion about the challenges and future research directions in this evolving field. By exploring the technical and ethical implications of MI attacks, this survey aims to offer insights into the impact of AI-powered systems on privacy, security, and trust. In conjunction with this survey, we have devel- oped a comprehensive repository to support research on MI attacks and defenses. The repository includes state-of-the-art research papers, datasets, evaluation metrics, and other resources to meet the needs of both novice and experienced researchers interested in MI attacks and defenses, as well as the broader field of AI security and privacy. The repository will be continuously maintained to ensure 1 arXiv:2501.18934v1 [cs.CR] 31 Jan 2025"
}