{
  "code_links": [
    "https://github.com/yjdy/CAPE"
  ],
  "tasks": [
    "Sequential Recommendation"
  ],
  "datasets": [
    "AmazonElectronics",
    "KuaiVideo",
    "AmazonBooks"
  ],
  "methods": [
    "Contextual-Aware Position Encoding (CAPE)"
  ],
  "results": [
    "AUC and gAUC significantly improved with all backbones",
    "SOTA performance",
    "eCPM increased by 3.62% in online A/B testing"
  ],
  "title": "A Contextual-Aware Position Encoding for Sequential Recommendation.pdf",
  "abstract": "Sequential recommendation (SR), which encodes user activity to predict the next action, has emerged as a widely adopted strategy in developing commercial personalized recommendation systems. A critical component of modern SR models is the attention mecha- nism, which synthesizes users\u2019 historical activities. This mechanism is typically order-invariant and generally relies on position encod- ing (PE). Conventional SR models simply assign a learnable vector to each position, resulting in only modest gains compared to tra- ditional recommendation models. Moreover, limited research has been conducted on position encoding tailored for sequential rec- ommendation, leaving a significant gap in addressing its unique requirements. To bridge this gap, we propose a novel Contextual- Aware Position Encoding method for sequential recommendation, abbreviated as CAPE. To the best of our knowledge, CAPE is the first PE method specifically designed for sequential recommen- dation. Comprehensive experiments conducted on benchmark SR datasets demonstrate that CAPE consistently enhances multiple mainstream backbone models and achieves state-of-the-art perfor- mance, across small and large scale model size. Furthermore, we deployed CAPE in an industrial setting on a real-world commercial platform, clearly showcasing the effectiveness of our approach. Our source code is available at https://github.com/yjdy/CAPE. CCS CONCEPTS \u2022 Information systems \u2192Recommender systems. KEYWORDS Recommender Systems, Position Encoding, Sequential Recommen- dation ACM Reference Format: Jun Yuan, Guohao Cai, and Zhenhua Dong. 2025. A Contextual-Aware Position Encoding for Sequential Recommendation. In Companion Proceed- ings of the ACM Web Conference 2025 (WWW Companion \u201925), April 28- May 2, 2025, Sydney, NSW, Australia. ACM, New York, NY, USA, 10 pages. https://doi.org/10.1145/3701716.3715206 \u2217Both authors contributed equally to this research. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. WWW Companion \u201925, April 28-May 2, 2025, Sydney, NSW, Australia \u00a9 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-1331-6/25/04...$15.00 https://doi.org/10.1145/3701716.3715206 Figure 1: Overview of mainstream sequential recommen- dation models. We only demonstrate the target attention mechanism, which can be seen as calculating the attention output of last item in self-attention 1 INTRODUCTION Recommendation systems play a pivotal role in current online con- tent platforms and e-commerce. The recommendation algorithm is a complex problem that requires extracting user interests to pre- dict future behaviors across various items. Nowadays, sequential recommendation (SR) has occupied a dominant position in commer- cial recommendations systems, including e-commerce [2], social media [23], news/video feeds [22], and online advertising [29]. The goal of sequential recommendation systems is to combine personal- ized models of user behavior (based on historical activities) with a notion of \"context\" derived from users\u2019 recent actions [8]. Sequen- tial recommendation has been explored for years and various SR models have been proposed [18, 21, 28]. In recent years, the attention mechanism has emerged as a crit- ical component of sequential recommendation models, enabling interactions among items in a sequence despite being inherently order-invariant. Incorporating position encoding (PE) addresses this limitation by enabling position-aware item representations [3]. Var- ious methods have been developed to incorporate position informa- tion into attention in natural language processing (NLP). However, the mainstream PE approach in SR primarily involves assigning a learnable vector to each position [2, 30]. Moreover, some widely- used sequential recommendation models, such as DIN [29] and DIEN [28], do not employ any PE methods at all. As a result, these attempts have only achieved modest improvements over traditional recommendation models. Simply adopting PE methods from NLP may not be suitable for sequential recommendation due to three key differences between models in SR and those in NLP: arXiv:2502.09027v1 [cs.IR] 13 Feb 2025"
}