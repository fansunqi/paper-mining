{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Understanding Generalization in Physics Informed Models"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Affine Variety Dimension Analysis"
  ],
  "results": [
    "Generalization capacity determined by dimension of affine variety",
    "Effective dimension of PI kernel bounded by dimension of affine variety"
  ],
  "title": "Understanding Generalization in Physics Informed Models Through Affine Variety Dimensions.pdf",
  "abstract": "In recent years, physics-informed machine learning has gained significant attention for its ability to enhance statistical performance and sample efficiency by integrating physical structures into machine learning models. These structures, such as differential equations, conservation laws, and symmetries, serve as inductive biases that can improve the general- ization capacity of the hybrid model. However, the mechanisms by which these physical structures enhance generalization capacity are not fully understood, limiting the ability to guarantee the performance of the models. In this study, we show that the generalization performance of linear regressors incorporating differential equation structures is determined by the dimension of the associated affine variety, rather than the number of parameters. This finding enables a unified analysis of various equations, including nonlinear ones. We intro- duce a method to approximate the dimension of the affine variety and provide experimental evidence to validate our theoretical insights. 1 INTRODUCTION In recent years, physics-informed machine learning (PIML) has garnered significant attention (Rai & Sahu, 2020; Karniadakis et al., 2021; Cuomo et al., 2022; Hao et al., 2022). PIML is a hybrid approach that integrates physical knowledge into machine learning models for tasks involving physical phenomena. The hybrid models can leverage physical structures such as differential equations (Raissi et al., 2019), conservation laws (Jagtap et al., 2020), and symmetries (Akhound-Sadegh et al., 2024) as inductive biases. This approach can potentially enhance sample efficiency and generalization capabilities. These models have been empirically applied to a wide range of phenomena, with successful applications including thrombus material properties (Yin et al., 2021), fluid dynamics (Cai et al., 2021a; Jin et al., 2021), turbulence (Wang et al., 2020), and heat transfer problems (Cai et al., 2021b). Despite these empirical successes, the impact of physical structures on the generalization capacity of models is primarily understood for linear equations or equations with specific regularity (Arnone et al., 2022; Doum`eche et al., 2024a). This limited understanding hampers the ability to ensure the performance and reliability of these hybrid methods. In this study, we theoretically analyze the generalization capacity of physics-informed linear regressors that incorporate the structure of differential equations. We show that the generalization capacity of these models is determined by the dimension of the affine variety associated with the differential equations, rather than the number of parameters. This novel perspective allows for a unified analysis of various equations, including nonlinear ones. To support our theoretical findings, we introduce a method for approximately calculating the dimension of the affine variety and provide extensive experimental validation. Our results demonstrate that even in scenarios with a large number of parameters relative to the amount of data, the physical structure reduces the intrinsic dimension of the hypothesis space and prevents overfitting, corroborating our theoretical findings. Our paper is structured as follows. In Section 3, we outline the problem setup and present our main theoretical results, including a minimax risk analysis that underscores the role of the dimension of the affine variety. In Section 4, we discuss the dimension of affine variety especially in the context of nonlinear operators and introduce methods for their approximate calculation. Section 5 provides experimental evidence supporting our theoretical claims, demonstrating the practical advantages of incorporating physical structures in machine learning models. 1 arXiv:2501.18879v1 [cs.LG] 31 Jan 2025"
}