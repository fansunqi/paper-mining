{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Physical learning",
    "Autonomous learning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Tight-binding Hamiltonian",
    "Coherent Ising Machine",
    "Contrastive learning",
    "Spinor field",
    "Nonlinear interactions"
  ],
  "results": [
    "None"
  ],
  "title": "Learning in a Multifield Coherent Ising Machine.pdf",
  "abstract": "parameter update equation, termed a learning rule. We introduce a physical model for self-learning that encodes the learning rule in the Hamiltonian of the system. The model consists of a network of multi-modal resonators. One of the modes is driven parametrically into a bi-stable regime, forming a coherent Ising machine (CIM)\u2014that provides the long-term memory that stores learned responses (weights). The CIM is augmented with an additional spinor field that acts as short-term (activation) memory. We numerically demonstrate that, in the presence of suitable nonlinear interactions between the long-term memory Ising machine and the short-term memory auxiliary field, the system autonomously learns from examples. Keywords: Physical computing, parametric oscillators, physical learning, tight-binding model INTRODUCTION Physical computing [1]\u2014computing based on novel and unconventional phenomena and information carri- ers, has achieved remarkable successes. Some examples are photonic image recognition [2, 3] and equation solv- ing [4, 5]; the use of thermal noise for matrix inver- sion [6], to perform inference [7] and to sample prob- ability distributions [8]; the application of condensed- matter ideas such as topology [9], symmetry [10] and parametric phenomena [11] for computing; and the use of mechanical information carriers for the realization of acoustic arithmetic operations [12], passive speech recog- nition [13], passive event counting [14], and to embody intelligent responses in soft robots [15]. In contrast, physical learning\u2014the process by which a physical com- puter autonomously improves its performance at a task by updating its parameters according to feedback and examples\u2014is still comparatively in its infancy. Remark- able steps have been taken with the discovery of learning rules [16\u201323]\u2014that indicate how parameters should be updated to improve system performance in a given infor- mation processing task; and some of these learning rules have been demonstrated in table-top experiments [24\u2013 26]. However, a significant gap remains between learning rules\u2014which are abstract parameter update equations, and physical systems\u2014governed by a Hamiltonian, and its interaction with the environment in the form of fluc- tuations and dissipation. In this letter, we introduce a material model\u2014a tight- binding Hamiltonian\u2014that learns autonomously from a set of examples (Fig. 1). The model harnesses ther- mal fluctuations to drive transitions between states, and uses symmetry-protected degeneracies to construct two copies of the system, as required by contrastive learn- ing rules. The incorporation of degeneracy and noise as building blocks of a self-learning physical system illus- trates how phenomena that are not traditionally used for computation\u2014or that are even actively avoided\u2014can be reclaimed in novel information processing paradigms. \u03c8x \u03c8y effect of spin on coupling clamped free weights t learning potential inter-site potential short-term memory long-term memory \u03c3 \u03c3 HL = \u00b5(t)\u03c82 x\u2212y\u03c32 HI = \u03bb(t) c0 + (\u03c3i \u2212\u03c3j)2 \u20d7\u03c8T i \u20d7\u03c8j FIG. 1. A multifield coherent Ising machine is a network of multi-modal resonators, represented by a tight-binding model consisting of a scalar field \u03c3 interacting with a spinor field \u20d7\u03c8. At every site i, the model has three degrees of freedom \u03c8x,i, \u03c8y,i and \u03c3i, coupled via the nonlinear terms HL and HI. The field \u20d7\u03c8 corresponds to the computational degrees of freedom (neural activations). \u20d7\u03c8 is composed of two identical sub-systems \u03c8x and \u03c8y (mass-spring lattices). During train- ing, the output degree of freedom of the sub-system \u03c8y is clamped to a target value (\u03c8x is left free). The modes \u03c3i are parametrically pumped (dotted green line) into a bistable self- oscillation regime, modeled by a spin (up or down depending on the phase of oscillation). This results in an Ising-like sys- tem that provides a long-term memory and stores the learned weights. The nonlinear interaction term HI modulates the dy- namics of the computational field \u20d7\u03c8 according to the weights \u03c3 (resulting in strong springs between antiferromagnetically- aligned sites). The term HL causes the weights \u03c3 to be up- dated in response to a difference (contrast) between the free (\u03c8x) and clamped (\u03c8y) computational sub-systems. In a ma- terial, the field \u20d7\u03c8 can be realized by mapping the two spin components to a pair of doubly-degenerate localized orbitals. arXiv:2502.12020v1 [cond-mat.mes-hall] 17 Feb 2025"
}