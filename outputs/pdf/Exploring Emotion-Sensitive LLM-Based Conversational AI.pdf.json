{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Emotion-Sensitive Conversational AI"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "LLM ChatGPT-3.5",
    "Sentiment Analysis (VADER)"
  ],
  "results": [
    "Emotion-sensitive chatbots were perceived as more competent than emotion-insensitive chatbots",
    "No significant difference in emotional state after interaction with either chatbot"
  ],
  "title": "Exploring Emotion-Sensitive LLM-Based Conversational AI.pdf",
  "abstract": "Conversational AI chatbots have become in- creasingly common within the customer ser- vice industry. Despite improvements in their emotional development, they often lack the authenticity of real customer service interac- tions or the competence of service providers. By comparing emotion-sensitive and emotion- insensitive LLM-based chatbots across 30 par- ticipants, we aim to explore how emotional sen- sitivity in chatbots influences perceived com- petence and overall customer satisfaction in service interactions. Additionally, we employ sentiment analysis techniques to analyze and interpret the emotional content of user inputs. We highlight that perceptions of chatbot trust- worthiness and competence were higher in the case of the emotion-sensitive chatbot, even if issue resolution rates were not affected. We dis- cuss implications of improved user satisfaction from emotion-sensitive chatbots and potential applications in support services. 1 Introduction Within the context of customer service, emotional labor involves employees managing their feelings and expressions to promote customer satisfaction (Hochschild, 1979). Beyond the actual service provided, customers are more likely to trust an employee or organization when their emotional needs are met, particularly if these emotions are perceived as genuine. This understanding has mo- tivated increased interest in embedding emotional- sensitivity into customer service chatbots (Bilquise et al., 2022; Li et al., 2021; Pamungkas, 2019). However, it is unclear if emotions from an AI would have the same effect. For example, a re- cent study found that emotion-sensitivity backfired when customers were aware that it was generated by AI, leading them to assume it was inauthentic (Han et al., 2023). Yet the growing sophistication of large language models (LLMs) suggests that these systems can convey emotionally nuanced language that might be perceived as authentic. To examine this, we performed a study using LLMs to simulate an IT customer service inter- action, manipulating the emotional sensitivity of the model. Our preliminary findings indicate that while the addition of emotional sensitivity did not alter the problem-solving abilities of the system (two-thirds of participants reported having their issue resolved and this was the same across both conditions), it did significantly increase their trust and belief in the competence of the emotionally- sensitive system. These results align with findings from emotional labor and reinforce attempts to in- tegrate emotion into such systems. However, they also raise concerns about users potentially over- trusting systems that exhibit human-like emotional expressions (Hancock et al., 2020). Future work will need to investigate if user trust is appropri- ately calibrated when interacting with emotionally- sensitive customer service agents (e.g., do people under-trust non-emotional agents or over-trust emo- tional ones?) and examine the longer-term conse- quences of such technology for both customers and employees. 2 Background Empathy has long been recognized as a key factor in enhancing customer satisfaction within the ser- vice industry (Kernbach and Schutte, 2005). Well- tailored emotional responses from a customer ser- vice agent may help regulate the emotion of an im- passioned customer (Delcourt et al., 2013). Early evidence suggests that chatbots may serve to bene- fit from increased emotional sensitivity in the same way that humans do, although this relationship has not yet been studied comprehensively (Gelbrich et al., 2021). As a novel technology, AI chatbot systems must also build trustworthiness to increase user satisfaction and perceived competence (Huang arXiv:2502.08920v1 [cs.HC] 13 Feb 2025"
}