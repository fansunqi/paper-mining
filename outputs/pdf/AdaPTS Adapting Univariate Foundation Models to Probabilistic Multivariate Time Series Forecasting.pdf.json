{
  "code_links": [
    "https://github.com/abenechehab/AdaPTS"
  ],
  "tasks": [
    "Time series forecasting"
  ],
  "datasets": [
    "ETTh1",
    "ExchangeRate",
    "Weather",
    "Influenza-like Illness"
  ],
  "methods": [
    "Adapters",
    "Variational AutoEncoders",
    "Dropout",
    "PCA"
  ],
  "results": [
    "8% improvement on ETTh1",
    "15% improvement on Illness",
    "VAE achieves significant improvement"
  ],
  "title": "AdaPTS Adapting Univariate Foundation Models to Probabilistic Multivariate Time Series Forecasting.pdf",
  "abstract": "Pre-trained foundation models (FMs) have shown exceptional performance in univariate time se- ries forecasting tasks. However, several practi- cal challenges persist, including managing intri- cate dependencies among features and quantify- ing uncertainty in predictions. This study aims to tackle these critical limitations by introducing adapters\u2014feature-space transformations that fa- cilitate the effective use of pre-trained univariate time series FMs for multivariate tasks. Adapters operate by projecting multivariate inputs into a suitable latent space and applying the FM inde- pendently to each dimension. Inspired by the literature on representation learning and partially stochastic Bayesian neural networks, we present a range of adapters and optimization/inference strategies. Experiments conducted on both syn- thetic and real-world datasets confirm the effi- cacy of adapters, demonstrating substantial en- hancements in forecasting accuracy and uncer- tainty quantification compared to baseline meth- ods. Our framework, AdaPTS, positions adapters as a modular, scalable, and effective solution for leveraging time series FMs in multivariate con- texts, thereby promoting their wider adoption in real-world applications. We release the code at https://github.com/abenechehab/AdaPTS. 1. Introduction Time series forecasting is a well-established machine learn- ing problem that involves analyzing sequential data to pre- dict future trends based on historical patterns. Two key challenges frequently arise in this context: (a) time series are often multivariate, incorporating multiple descriptive 1Huawei Noah\u2019s Ark Lab, Paris, France 2Department of Data Science, EURECOM 3Statistics Program, KAUST. Correspondence to: Abdelhakim Benechehab <abdel- hakim.benechehab@gmail.com>. Preprint, under review. Copyright 2025 by the author(s). 460 480 500 520 540 560 580 600 Time Steps ETTh1 (H = 96) Ground Truth Moment Moment+AdaPTS \u00b11, 3, 5 std (a) (b) Figure 1: (a) Augmenting Moment time series foundation model with the AdaPTS framework provides probabilistic and more accurate predictions. (b) The AdaPTS frame- work: The input time series is transformed through a feature space transformation \u03c6 that maps into a stochastic latent space. The prediction is then conducted using a pre-trained FM before transforming back the predicted, now distribu- tion, to the original feature space. The fire symbol indicate trainable weights while the snowflake implicates that the parameters of the FM are kept frozen. features (Wei, 2019), and (b) estimating the uncertainty of a forecast is equally important, requiring probabilistic model outputs (Gneiting & Katzfuss, 2014). These challenges are particularly relevant in real-world applications where risk assessment depends on reliable forecasts, such as health- care (Jones & Spiegelhalter, 2012), finance (Groen et al., 2013), energy management (Zhang et al., 2014; Nowotarski & Weron, 2018), and weather prediction (Palmer, 2012; Bi et al., 2023). Existing foundation models (FMs) for time series forecast- ing, such as Chronos (Ansari et al., 2024), are typically trained for univariate forecasting tasks due to tractability constraints, as the wide range of real world time series prob- lems typically have different numbers of features. Even 1 arXiv:2502.10235v1 [stat.ML] 14 Feb 2025"
}