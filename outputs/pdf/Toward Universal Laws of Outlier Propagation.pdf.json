{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Anomaly detection",
    "Root cause analysis"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Algorithmic Information Theory",
    "Causal Bayesian networks"
  ],
  "results": [
    "Randomness deficiency",
    "Monotonicity of randomness deficiency"
  ],
  "title": "Toward Universal Laws of Outlier Propagation.pdf",
  "abstract": "We argue that Algorithmic Information The- ory (AIT) admits a principled way to quan- tify outliers in terms of so-called random- ness de\ufb01ciency. For the probability distribu- tion generated by a causal Bayesian network, we show that the randomness de\ufb01ciency of the joint state decomposes into randomness de\ufb01ciencies of each causal mechanism, sub- ject to the Independence of Mechanisms Prin- ciple. Accordingly, anomalous joint observa- tions can be quantitatively attributed to their root causes, i.e., the mechanisms that behaved anomalously. As an extension of Levin\u2019s law of randomness conservation, we show that weak outliers cannot cause strong ones when Inde- pendence of Mechanisms holds. We show how these information theoretic laws provide a bet- ter understanding of the behaviour of outliers de\ufb01ned with respect to existing scores. 1 INTRODUCTION Anomaly detection plays a crucial role in business, technology, and medicine. Typical use cases range from fraud detection in \ufb01nance and online trad- ing [Donoho, 2004], performance drops in manufac- turing lines [Susto et al., 2017] or cloud comput- ing applications [Gan et al., 2021, Ma et al., 2020, Hardt et al., 2023], health monitoring in intensive care units [Maslove et al., 2016], to explaining ex- treme weather and climate events [Zscheischler et al., 2022]. It has motivated a vast e\ufb00ort towards de- veloping methodologies relevant to outlier analy- sis. As example, we refer the reader to some of *These authors contributed equally to this work. the early works in statistics and computer sci- ence [Freeman, 1995, Rocke and Woodru\ufb00, 1996, Rousseeuw and Leroy, 2003, Aggarwal, 2017]. In com- plex systems, an anomaly will typically cause a large cascades of related anomalies [Panjei et al., 2022]. In order to mitigate them, it is not su\ufb03cient to merely detect the anomalies; we must also identify which of the anomalies was the root cause [Budhathoki et al., 2022, Ikram et al., 2022, Li et al., 2022, Hardt et al., 2023, Wang et al., 2023b,a]. Thus, we implicitly face the counterfactual question of what conditions could have been di\ufb00erent to prevent the (usually undesired) anomalous event. To render a complex system accessible to human under- standing, we begin with a causal model of its relevant mechanisms, specifying not only their default behav- ior, but also their behavior under modi\ufb01cations called interventions. Such a model should be modular in two respects. First, we may want to understand the causal pathway, along which a perturbation of any part of the system propagates through its components until it generates the event. Second, we want to \u201cblame\u201d some component(s) of the system, while acknowledging that others worked as expected. Causal Bayesian networks o\ufb00er a framework that sup- ports both kinds of modular description, specifying causal relations via a directed acyclic graph (DAG) G with random variables X1, . . . , Xn as nodes [Pearl, 2009, Spirtes et al., 1993]. Due to the causal Markov condition [Pearl, 2009], the joint distribution factorizes according to P(X1, . . . , Xn) = n Y i=1 P(Xj | PAj), (1) where PAj denotes the parents of Xj in G, i.e., its direct causes. We will think of each conditional distri- bution P(Xj | PAj) as an independent mechanism of the system, which can in principle be changed or re- placed without changing the others (see 2.1 and 2.2 in Peters et al. [2017] for a historic overview). Following"
}