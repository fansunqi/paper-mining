{
  "code_links": [
    "https://github.com/bingreeky/MaAS"
  ],
  "tasks": [
    "Multi-agent Architecture Search",
    "Automated Agent Design"
  ],
  "datasets": [
    "HumanEval",
    "MBPP",
    "GSM8K",
    "MATH",
    "MultiArith",
    "GAIA"
  ],
  "methods": [
    "Agentic Supernet",
    "Controller Network",
    "Monte Carlo Sampling",
    "Textual Gradient"
  ],
  "results": [
    "Accuracy: 83.59%",
    "Cost Efficiency: 0.42$ API Cost",
    "Transferability: Cross-model and Cross-dataset"
  ],
  "title": "Multi-agent Architecture Search Via Agentic Supernet.pdf",
  "abstract": "Large Language Model (LLM)-empowered multi- agent systems extend the cognitive boundaries of individual agents through disciplined collabo- ration and interaction, while constructing these systems often requires labor-intensive manual de- signs. Despite the availability of methods to automate the design of agentic workflows, they typically seek to identify a static, complex, one- size-fits-all system, which, however, fails to dy- namically allocate inference resources based on the difficulty and domain of each query. To ad- dress this challenge, we shift away from the pur- suit of a monolithic agentic system, instead op- timizing the agentic supernet, a probabilistic and continuous distribution of agentic architec- tures. We introduce MaAS, an automated frame- work that samples query-dependent agentic sys- tems from the supernet, delivering high-quality solutions and tailored resource allocation (e.g., LLM calls, tool calls, token cost). Comprehensive evaluation across six benchmarks demonstrates that MaAS (I) requires only 6 \u223c45% of the inference costs of existing handcrafted or auto- mated multi-agent systems, (II) surpasses them by 0.54% \u223c11.82%, and (III) enjoys superior cross-dataset and cross-LLM-backbone transfer- ability. The code will be available at https: //github.com/bingreeky/MaAS. 1. Introduction Large Language Model (LLM)-based agents (Richards & et al., 2023; Nakajima, 2023; Reworkd, 2023) have made remarkable strides in a spectrum of domains, such as ques- tion answering (Zhu et al., 2024a), data analysis (Hong et al., 2024; Li et al., 2024), code generation (Shinn et al., 2023), web navigation (Deng et al., 2024), and data syn- thesis (Butt et al., 2024), by equipping LLMs with high- *Equal contribution 1Tongji University 2National University of Singapore 3University of Science and Technology of China 4Shanghai AI Laboratory. Primary Contact: Guibin Zhang <guib- inz@outlook.com>. level features, including persona (Wang et al., 2023b; Chen et al., 2024), tools (Shen et al., 2024; Richards & et al., 2023), planning (Qiao et al., 2024; Wu et al., 2024; He et al., 2023), and memory (Zhong et al., 2024; Hatalis et al., 2023; Packer et al., 2023). Building upon the success of single agents, researchers have demonstrated that combining mul- tiple agents, either cooperatively (Zhuge et al., 2024) or competitively (Zhao et al., 2023), can surpass the cognitive and intellectual capabilities of individuals (Du et al., 2023; Liang et al., 2023; Wang et al., 2023b; Jiang et al., 2023; Wu et al., 2023; Zhang et al., 2024a), showcasing the collective intelligence in a society of LLM-agents (Piatti et al., 2024). Early multi-agent systems, such as CAMEL (Li et al., 2023), AutoGen (Wu et al., 2023), and MetaGPT (Hong et al., 2023), while delivering specialized capacity, often heav- ily rely on manual configurations, including prompt engi- neering, agent profiling, and inter-agent communication pipelines (Qian et al., 2024). This dependency significantly limits the rapid adaptation of multi-agent systems to di- verse domains and application scenarios (Tang et al., 2023; Zhang et al., 2024c). More recently, the research com- munity has shifted toward automating multi-agent system design. For instance, DsPy (Khattab et al., 2023) and Evo- Prompting (Guo et al., 2023) automate prompt optimization, GPTSwarm (Zhuge et al., 2024) and G-Designer (Zhang et al., 2024b) optimize inter-agent communication, and EvoAgent (Yuan et al., 2024) and AutoAgents (Chen et al., 2023a) self-evolve agent profiling. Nevertheless, they typ- ically focus on automating specific aspects of the system. Subsequently, ADAS (Hu et al., 2024a), AgentSqure (Shang et al., 2024), and AFlow (Zhang et al., 2024c) broaden the design search space. These state-of-the-art (SOTA) meth- ods optimize a single, complex (multi-)agent workflow for a given dataset via different search paradigms, e.g., heuristic search (Hu et al., 2024a), Monte Carlo tree search (Zhang et al., 2024c), and evolution (Shang et al., 2024), surpassing the performance of manually designed systems. Although the paradigm of searching for a one-size-fits- all multi-agent system appears sufficient to optimize performance-related metrics such as accuracy and pass@k, its performance is largely constrained on resource-related metrics, such as token cost, LLM calls, and inference la- tency (Dilemma 1). Specifically, contemporary methods tend to optimize for a complex and resource-intensive agen- 1 arXiv:2502.04180v1 [cs.LG] 6 Feb 2025"
}