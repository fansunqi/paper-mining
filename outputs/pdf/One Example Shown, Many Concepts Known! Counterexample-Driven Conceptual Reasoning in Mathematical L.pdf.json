{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Mathematical reasoning",
    "Proof generation",
    "Conceptual reasoning"
  ],
  "datasets": [
    "COUNTERMATH"
  ],
  "methods": [
    "Counterexample-driven reasoning",
    "Data engineering framework",
    "Supervised fine-tuning"
  ],
  "results": [
    "LLMs struggle with counterexample-driven reasoning",
    "Fine-tuned model shows improved performance",
    "Generalization to OOD benchmarks"
  ],
  "title": "One Example Shown, Many Concepts Known! Counterexample-Driven Conceptual Reasoning in Mathematical L.pdf",
  "abstract": "Leveraging mathematical Large Language Mod- els (LLMs) for proof generation is a fundamental topic in LLMs research. We argue that the abil- ity of current LLMs to prove statements largely depends on whether they have encountered the rel- evant proof process during training. This reliance limits their deeper understanding of mathemati- cal theorems and related concepts. Inspired by the pedagogical method of \u201cproof by counterex- amples\u201d commonly used in human mathematics education, our work aims to enhance LLMs\u2019 abil- ity to conduct mathematical reasoning and proof through counterexamples. Specifically, we manu- ally create a high-quality, university-level math- ematical benchmark, COUNTERMATH, which requires LLMs to prove mathematical statements by providing counterexamples, thereby assess- ing their grasp of mathematical concepts. Ad- ditionally, we develop a data engineering frame- work to automatically obtain training data for further model improvement. Extensive exper- iments and detailed analyses demonstrate that COUNTERMATH is challenging, indicating that LLMs, such as OpenAI o1, have insufficient counterexample-driven proof capabilities. More- over, our exploration into model training reveals that strengthening LLMs\u2019 counterexample-driven conceptual reasoning abilities is crucial for im- proving their overall mathematical capabilities. We believe that our work offers new perspectives on the community of mathematical LLMs. *Equal contribution. 1Tsinghua University. E-mail: liyinghu20@mails.tsinghua.edu.cn 2Sun-Yat Sen University 3School of Mathematical Science, Fu- dan University 4ARC Lab, Arizona State University 5Bytedance Inc. 6Peng Cheng Laboratory 7INFLY TECH (Shanghai) Co., Ltd. 8University of Illinois Chicago. Correspondence to: Zhikun Xu <zhikunxu@asu.edu>. 1. Introduction Mathematics, as a fundamental aspect of reasoning, has garnered significant research interest. Recent studies have demonstrated that Large Language Models (LLMs) exhibit strong mathematical reasoning abilities (OpenAI, 2023; Google, 2024; Yang et al., 2024; Shao et al., 2024; Ying et al., 2024; Chern et al., 2023; Luo et al., 2023; Yu et al., 2024a). Enhancing the mathematical reasoning capabilities of LLMs has become a prominent and fundamental topic within the LLMs research community. Currently, there are two main paradigms for enhancing the mathematical reasoning capabilities of LLMs. The first involves synthetic generation based on seed math ques- tions (Yu et al., 2023; Li et al., 2024a). For example, Wiz- ardMath (Luo et al., 2023) introduces a variety of math instructions to generate math questions of different com- plexities using GPT-3.5. The second approach leverages formal mathematical languages to train LLM-based theo- rem provers, such as Lean 4 (Moura & Ullrich, 2021). For instance, Draft-Sketch-Prove (Jiang et al., 2023), Hunyuan- Prover (Li et al., 2024c), and Lean-STaR (Lin et al., 2024a) interact with formal languages through informal proofs, au- tomatic formalization, and natural language thoughts for theorem proving. The two methods above enable LLMs to develop problem- solving skills either by training on massive similar problems, or by gaining proficiency through exposure to similar proof processes (Mirzadeh et al., 2024; Yu et al., 2024b). In both cases, these approaches enhance LLMs\u2019 mathematical reasoning abilities through training, where proficiency is achieved through familiarity, akin to \u201cdrill-based\u201d learning in human mathematics learning. However, relying solely on intensive-practice by inundating LLMs with math problems is neither sufficient nor essential for true mathematics learn- ing. In other words, drill-based learning alone does not foster a deep understanding of mathematical concepts in either humans or LLMs. As illustrated in Figure 1, for human mathematics learning, \u201cexample-based\u201d learning is a more important strategy than drill-based learning. In particular, for mathematical proofs, 1 arXiv:2502.10454v1 [cs.LG] 12 Feb 2025"
}