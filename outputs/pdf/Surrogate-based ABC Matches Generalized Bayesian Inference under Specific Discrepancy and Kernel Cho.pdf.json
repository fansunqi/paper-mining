{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Generalized Bayesian inference",
    "ABC inference",
    "Surrogate-based inference"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Gaussian process surrogate modeling",
    "Loss-based inference",
    "ABC likelihood",
    "Generalized posterior"
  ],
  "results": [
    "None"
  ],
  "title": "Surrogate-based ABC Matches Generalized Bayesian Inference under Specific Discrepancy and Kernel Cho.pdf",
  "abstract": "Generalized Bayesian inference (GBI) is an alternative inference framework motivated by robust- ness to modeling errors, where a specific loss function is used to link the model parameters with ob- served data, instead of the log-likelihood used in standard Bayesian inference. Approximate Bayesian Computation (ABC) refers in turn to a family of methods approximating the posterior distribution via a discrepancy function between the observed and simulated data instead of using the likelihood. In this paper we discuss the connection between ABC and GBI, when the loss function is defined as an expected discrepancy between the observed and simulated data from the model under consideration. We show that the resulting generalized posterior corresponds to an ABC-posterior when the latter is obtained under a Gaussian process -based surrogate model. We illustrate the behavior of the approxi- mations as a function of specific discrepancy and kernel choices to provide insights of the relationships between these different approximate inference paradigms. 1 Introduction Complex parametric statistical models are a major work horse in many fields of science and Bayesian inference is often used for them as it allows coherent estimation and uncertainty quantification of the pa- 1 arXiv:2502.11738v1 [stat.ME] 17 Feb 2025"
}