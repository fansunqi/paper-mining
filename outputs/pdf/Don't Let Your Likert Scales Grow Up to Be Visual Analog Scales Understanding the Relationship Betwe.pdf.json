{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Understanding the relationship between number of response categories and measurement error"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Monte Carlo simulation",
    "Graded Response Model (GRM)",
    "Item Response Theory (IRT)"
  ],
  "results": [
    "No optimal number of response options when measurement error is independent of number of response categories",
    "Optimal number of response options lower when measurement error is dependent on number of categories",
    "Reliability declines beyond optimal number of categories"
  ],
  "title": "Don't Let Your Likert Scales Grow Up to Be Visual Analog Scales Understanding the Relationship Betwe.pdf",
  "abstract": "The use of Visual Analog Scales (VAS), which can be broadly conceptualized as items where the response scale is 0-100, has surged recently due to the convenience of digital assessments. However, there is no consensus as to whether the use of VAS scales is optimal in a measurement sense. Put differently, in the 90+ years since Likert introduced his eponymous scale, the field does not know how to determine the optimal number of response options for a given item. In the current work, we investigate the optimal number of response categories using a series of simulations. We find that when the measurement error of an item is not dependent on the number of response categories, there is no true optimum; rather, reliability increases with number of response options and then plateaus. However, under the more realistic assumption that the measurement error of an item increases with the number of response categories, we find a clear optimum that depends on the rate of that increase. If measurement error increases with the number of response categories, then conversion of any Likert scale item to VAS will result in a drastic decrease in reliability. Finally, if researchers do want to change the response scale of a validated measure, they must re-validate the new measure as the measurement error of the scale is likely to change. 1 Introduction The precision and utility of psychological assessments are contingent not only on the construct being measured or the specific item text, but also on the specific response scale employed. Traditionally, Likert scales have dominated psychological research with their fixed point ordinal system, ranging from \u201cStrongly Disagree\u201d to \u201cStrongly Agree\u201d (Likert, 1932). Likert scales consist of a series of statements or items, and respondents are asked to indicate their level of agreement or disagreement with each statement. A traditional 5-point Likert scale has five response options, ranging from \u201dStrongly Disagree\u201d to \u201dStrongly Agree\u201d, with a neutral midpoint such as \u201dNeutral\u201d or \u201dNeither Agree nor Disagree\u201d. The respondents select the option that best represents their point of view on the given statement, and then the responses are numerically coded for analysis. The conventional use of Likert scales generally involves a relatively small number of response options (2-7 points), resulting in limited variability and subsequent challenges in data analysis (Sung & Wu, 2018). Despite its popular use, the limited variability of Likert scales to accurately model and capture the nuances of human feelings remains heavily questioned. As an alternative to Likert scales, researchers often use Visual Analog Scales (VAS), particularly in computerized Ecological Momentary Assessment (EMA) designs (e.g. Bosch, Revilla, DeCastellarnau, & Weber, 2019; Flynn, Van Schaik, & Van Wersch, 2004; Guyatt, Townsend, Berman, & Keller, 1987; Hayes, 1921; Jaeschke, Singer, & Guyatt, 1990; Sung & Wu, 2018; Zealley & Aitken, 1969). A traditional VAS (such as one administered in a pen-and-paper instrument) has a horizontal line anchored by opposing extremes (e.g., \u201dnot at all stressed\u201d to \u201dextremely stressed\u201d), where respondents mark a point that reflects their perception on the issue being measured, and the distance from the line\u2019s beginning to the mark represents the quantitative score. This quantitative score is usually coded from 0-100. Electronic versions of VAS items typically use a slider, where respondents move an indicator 1 arXiv:2502.02846v1 [stat.ME] 5 Feb 2025"
}