{
  "code_links": [
    "https://github.com/ielab/densereviewer"
  ],
  "tasks": [
    "Systematic Reviews"
  ],
  "datasets": [
    "PubMed"
  ],
  "methods": [
    "Dense Retrieval",
    "Active Learning",
    "Rocchio's algorithm"
  ],
  "results": [
    "DenseReviewer improves efficiency and effectiveness compared to previous methods"
  ],
  "title": "DenseReviewer A Screening Prioritisation Tool for Systematic Review Based on Dense Retrieval.pdf",
  "abstract": ". Screening is a time-consuming and labour-intensive yet re- quired task for medical systematic reviews, as tens of thousands of studies often need to be screened. Prioritising relevant studies to be screened al- lows downstream systematic review creation tasks to start earlier and save time. In previous work, we developed a dense retrieval method to prioritise relevant studies with reviewer feedback during the title and abstract screening stage. Our method outperforms previous active learn- ing methods in both effectiveness and efficiency. In this demo, we ex- tend this prior work by creating (1) a web-based screening tool that en- ables end-users to screen studies exploiting state-of-the-art methods and (2) a Python library that integrates models and feedback mechanisms and allows researchers to develop and demonstrate new active learning methods. We describe the tool\u2019s design and showcase how it can aid screening. The tool is available at https://densereviewer.ielab.io. The source code is also open sourced at https://github.com/ielab/ densereviewer. Keywords: Systematic Reviews \u00b7 Dense Retrieval \u00b7 Relevance Feedback. 1 Introduction and Related Work Medical systematic reviews (SRs) synthesise evidence from the literature, requir- ing high recall to avoid missing relevant studies. The screening process is critical to ensure high recall and is a two-stage process: Firstly, the title and abstract of studies are assessed by medical researchers or librarians for relevance, fol- lowed by the full text. The former title and abstract (T&A) screening generally involves tens of thousands of studies [1], leading to a high workload and cost. Several tools and products have been developed to reduce this workload, includ- ing ASReview [17],1 Covidence,2 DistillerSR,3 and RobotAnalyst [11].4 These tools classify studies using classical machine learning. Each study is suggested for inclusion or exclusion or labelled with a confidence score by the model. 1 https://asreview.nl/ 2 https://www.covidence.org/ 3 https://www.distillersr.com/ 4 https://nactem.ac.uk/robotanalyst/ arXiv:2502.03400v1 [cs.IR] 5 Feb 2025"
}