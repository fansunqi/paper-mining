{
  "code_links": [
    "None"
  ],
  "tasks": [
    "LLM Fingerprinting"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Hybrid Fingerprinting",
    "Static Fingerprinting",
    "Dynamic Fingerprinting",
    "LLMMap",
    "Manual Fingerprinting",
    "ModernBERT"
  ],
  "results": [
    "Combined approach achieves 86.5% accuracy at n=10",
    "Dynamic fingerprinting achieves 79.4% accuracy at n=10",
    "Static fingerprinting achieves 74.4% accuracy at n=10"
  ],
  "title": "Invisible Traces Using Hybrid Fingerprinting to Identify Underlying LLMs in GenAI Apps.pdf",
  "abstract": "Fingerprinting refers to the process of identify- ing underlying Machine Learning (ML) models of AI Systemts, such as Large Language Models (LLMs), by analyzing their unique characteristics or patterns, much like a human fingerprint. The fingerprinting of Large Language Models (LLMs) has become essential for ensuring the security and transparency of AI-integrated applications. While existing methods primarily rely on access to direct interactions with the application to infer model identity, they often fail in real-world scenarios involving multi-agent systems, frequent model updates, and restricted access to model internals. In this paper, we introduce a novel fingerprinting framework designed to address these challenges by integrating static and dynamic fingerprinting techniques. Our approach identifies architectural features and behavioral traits, enabling accurate and robust fingerprinting of LLMs in dynamic environments. We also highlight new threat sce- narios where traditional fingerprinting methods are ineffective, bridging the gap between theo- retical techniques and practical application. To validate our framework, we present an extensive evaluation setup that simulates real-world con- ditions and demonstrate the effectiveness of our methods in identifying and monitoring LLMs in Gen-AI applications. Our results highlight the framework\u2019s adaptability to diverse and evolving deployment contexts. 1. Introduction The fingerprinting of Large Language Models (LLMs) has emerged as a critical area of research, playing an impor- tant role in ensuring AI security and transparency (Pasquini et al., 2024), (Yang & Wu, 2024), (Zhang et al., 2024), (Yamabe et al., 2024). As LLMs become deeply embed- ded in a variety of applications, their widespread adoption brings forth significant vulnerabilities (Chao et al., 2023), (Anil et al., 2024), (Carlini et al., 2024), (Liu et al., 2023a), (Liu et al., 2023b), (Russinovich & Salem, 2024), (Xu et al., 2024). Identifying and monitoring the specific models un- derlying these systems is a crucial step in mitigating these risks. However, existing fingerprinting methods, which pre- dominantly rely on direct interaction and crafted queries to infer model identity or behavior (Pasquini et al., 2024), have some limitations. While effective in controlled environ- ments, these approaches struggle to address the complexities of real-world deployments. In this paper, we categorize current LLM fingerprinting into two primary paradigms: Static Fingerprinting and Dynamic Fingerprinting. We provide an in-depth analy- sis of each paradigm, exploring their individual strengths and limitations. We propose a novel combined pipeline that integrates the complementary strengths of static and dynamic fingerprinting. This pipeline enhances the robust- ness and accuracy of model identification in complex, real- world scenarios. Our experimental results demonstrate that this combined approach significantly outperforms individ- ual methods, establishing it as a reliable solution for LLM fingerprinting. We also share a unique insight through our dynamic finger- printing model: in our experiments, we discovered that by simply observing the outputs of LLMs on generic prompts, it is possible to determine the underlying LLM. In other words, we demonstrate that different LLM model families produce semantically distinct types of outputs. This aligns with the findings of existing works which show the different lexical features being generated by different model families. (McGovern et al., 2024) Our contributions can be summarized as follows: 1. We provide an in-depth analysis of LLM fingerprinting, focusing on real-world use cases. Dividing the LLM fingerprinting into two new paradigms. 2. We present a hybrid pipeline that effectively integrates static and dynamic fingerprinting techniques, offering improved adaptability to real-world constraints. 3. We share a novel finding from our experiments that demonstrates how observing the outputs of LLMs on 1 arXiv:2501.18712v4 [cs.LG] 7 Feb 2025"
}