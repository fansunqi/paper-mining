{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Generative AI",
    "Selective Response"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Game Theory",
    "Economic Analysis",
    "Selective Response Strategy"
  ],
  "results": [
    "Increased User Welfare",
    "Increased GenAI Revenue",
    "Increased Data Generation"
  ],
  "title": "Selective Response Strategies for GenAI.pdf",
  "abstract": "The rise of Generative AI (GenAI) has signi\ufb01cantly impacted human-based forums like Stack Over\ufb02ow, which are essential for generating high-quality data. This creates a negative feedback loop, hindering the development of GenAI systems, which rely on such data to provide accurate responses. In this paper, we provide a possible remedy: A novel strategy we call selective response. Selective response implies that GenAI could strategically provide inaccurate (or conservative) responses to queries involv- ing emerging topics and novel technologies, thereby driving users to use human-based forums like Stack Over\ufb02ow. We show that selective response can potentially have a compounding e\ufb00ect on the data gener- ation process, increasing both GenAI\u2019s revenue and user welfare in the long term. From an algorithmic perspective, we propose an approximately optimal approach to maximize GenAI\u2019s revenue under social welfare constraints. From a regulatory perspective, we derive su\ufb03cient and necessary conditions for selective response to improve welfare improvements. 1 Introduction The maxim, \u201cBetter to remain silent and be thought a fool than to speak and to remove all doubt,\u201d o\ufb00ers a compelling perspective on the strategic value of withholding information. While often invoked in interper- sonal contexts, it resonates surprisingly well in the context of Generative AI (GenAI) systems like ChatGPT. These systems are designed to answer user queries immediately, yet one might wonder: Are there situations where the system should remain silent? One such scenario arises when the system hallucinates. Hallucinations, de\ufb01ned as the generation of incorrect or fabricated information, are an intrinsic property of generative models that cannot be entirely avoided Kalai and Vempala [2024]. Another scenario involves questions concerning safety and ethics, with potentially life-threatening consequences Shin [2023], Mello and Guha [2023], Li et al. [2024b]. However, as we argue in this paper, it can be advantageous for both GenAI operators and users if the system avoids responding indiscriminately to every prompt, especially when addressing emerging technologies and novel content. To illustrate, consider GenAI\u2019s competitive relationship with a human-driven platform like Stack Over\ufb02ow. Users may direct their questions to either GenAI or Stack Over\ufb02ow, seeking solutions to their problems. Posting a code-related question on Stack Over\ufb02ow generates clari\ufb01cation questions in the comments, solutions o\ufb00ered by experts, feedback from other users (upvotes) and the original poster (acceptance \ufb02ag), etc. Such valuable data could signi\ufb01cantly enhance GenAI, improving its performance. In contrast, querying GenAI can lead to quicker user satisfaction and increased engagement with GenAI, potentially enhancing its revenue streams. On the downside, the lack of community interaction may result in less comprehensive solutions and reduce the opportunity for generating rich, labeled data that community-driven platforms like Stack Over\ufb02ow thrive on. This absence of dynamic, user-generated content and in-depth discussions can be detrimental to user welfare in the long term, as GenAI\u2019s ability to provide high-quality answers depends on such data. Motivated by the issue above, this paper pioneers the framework of selective response. Namely, strategi- cally choosing when, if, and how to engage with user queries, particularly those involving emerging topics and novel technologies. We explicitly suggest that when a new topic emerges, GenAI could strategically de- cide to provide lower-quality answers than what it can or even disclaim to have not enough data to respond. \u2217Technion\u2014Israel Institute of Technology (boaztaitler@campus.technion.ac.il) \u2020Technion\u2014Israel Institute of Technology (omerbp@technion.ac.il) 1"
}