{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Understanding Human Feedback in Reinforcement Learning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "TAMER",
    "Stochastic TAMER"
  ],
  "results": [
    "Cute robots received higher ratio of positive to negative feedback",
    "Stochastic TAMER improved learning outcomes with 50% positive feedback"
  ],
  "title": "Use of Winsome Robots for Understanding Human Feedback (UWU).pdf",
  "abstract": "\u2014As social robots become more common, many have adopted cute aesthetics aiming to enhance user comfort and acceptance. However, the effect of this aesthetic choice on human feedback in reinforcement learning scenarios remains unclear. Previous research has shown that humans tend to give more positive than negative feedback, which can cause failure to reach optimal robot behavior. We hypothesize that this positive bias may be exacerbated by the robot\u2019s level of perceived cuteness. To investigate, we conducted a user study where participants critique a robot\u2019s trajectories while it performs a task. We then analyzed the impact of the robot\u2019s aesthetic cuteness on the type of participant feedback. Our results suggest that there is a shift in the ratio of positive to negative feedback when perceived cuteness changes. In light of this, we experiment with a stochastic version of TAMER which adapts based on the user\u2019s level of positive feedback bias to mitigate these effects. I. INTRODUCTION Human-robot interaction (HRI) is becoming more common as robots become integrated into everyday society. As robots become more widely adopted, inevitably they will encounter scenarios outside of their training scope and programmed capabilities. However, it is unrealistic to expect these robots to be configured for all new situations; therefore, to function successfully they must possess the ability to learn and adapt to new circumstances. One promising approach for this challenge is Learning from Demonstration (LfD), a method where users teach robots tasks through demonstrations or by providing feedback on their performance. Unlike traditional programming approaches, LfD allows users to directly teach the robot without requiring technical expertise. This accessibility makes LfD particularly attractive for enabling general users to customize robot behavior and improve their performance. Such a high level of interaction necessitates that users feel comfortable and are willing to engage closely with the robot. To promote user comfort, recently many companies have released robots that have utilized \u201ccute\u201d aesthetics, using features that align with the baby schema principle (a psychological schema based on infant features) proposed by Lorenz [1]\u2013[3]. Research suggests that robots whose appearance adheres to this cuteness schema were considered more trustworthy than their counterparts [3]. However, cuteness alone is insufficient to incite this engagement; users may still experience frustration if the robot lacks adequate skills or cannot perform the task [2]. Fig. 1: This figure depicts a robotic pick-and-place task. We record positive and negative feedback provided by users on the robot\u2019s task execution. Our paper explores the impact of robotic aesthetics, such as perceived cuteness, on users\u2019 feedback tendencies and subsequent robot learning outcomes. Allowing users the ability to refine the robot\u2019s skills through training methods like LfD may help mitigate such frustrations. Many HRI and LfD studies use machine-like robots for their research, overlooking the potential impact of the robot\u2019s visual aesthetic on user feedback. In cases such as reinforcement learning where human feedback is the driver for shaping the robot\u2019s learning process, it is important to understand how this aesthetic change may impact the type and quality of the user\u2019s demonstrations or feedback. Prior HRI research has shown that humans tend to give more positive than negative feedback during training [5]\u2013[7]. This positive bias can pose an issue to robotic learning algorithms as users may give positive feedback for poor robot performance, creating a noisy reward [5], [6]. Furthermore, the inaccurate positive feedback may cause the robot to enter a \u201cpositive reward circuit,\u201d where it will become stuck in a loop of suboptimal states and never reach the goal [5]. Additionally, others have shown that appearance can influence a user\u2019s rating of a robot\u2019s trustworthiness and acceptance of a robot [8]. However, no previous study has directly investigated the relationship between the robot\u2019s perceived cuteness and the type of feedback a user gives. This research aims to provide a framework for investigating this relationship between visual robotic cuteness and the quality of user feedback in an LfD setting. In this work, we make the following contributions: \u2022 We conduct a proof-of-concept, IRB-approved (Protocol H24178), pilot study that investigates the impact of perceived robotic cuteness on user feedback. \u2022 We propose additions to Interactive Robot Learning (IRL) algorithm, TAMER, aimed at mitigating suboptimal arXiv:2502.05118v1 [cs.RO] 7 Feb 2025"
}