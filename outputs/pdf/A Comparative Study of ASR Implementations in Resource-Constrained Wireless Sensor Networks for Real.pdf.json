{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Automatic Speech Recognition (ASR) in resource-constrained Wireless Sensor Networks"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Network Speech Recognition (NSR)",
    "Distributed Speech Recognition (DSR)",
    "Embedded Speech Recognition (ESR)"
  ],
  "results": [
    "None"
  ],
  "title": "A Comparative Study of ASR Implementations in Resource-Constrained Wireless Sensor Networks for Real.pdf",
  "abstract": "This paper investigates the challenges and trade-offs associated with implementing Automatic Speech Recognition (ASR) in resource-limited Wireless Sensor Networks (WSNs) for real-time voice communication. We analyze three main architectural approaches: Network Speech Recognition (NSR), Distributed Speech Recognition (DSR), and Embedded Speech Recognition (ESR). Each approach is evaluated based on factors such as bandwidth consumption, processing power requirements, latency, accuracy (Word Error Rate - WER), and adaptability to offline operation. We discuss the advantages and disadvantages of each method, considering the computational and communication limitations of WSN nodes. This comparative study provides insights for selecting the most appropriate ASR implementation strategy based on specific application requirements and resource constraints. Keywords: Wireless Sensor Networks, Automatic Speech Recognition, Real-time communication, Network Speech Recognition, Distributed Speech Recognition, Embedded Speech Recognition, Word Error Rate, Resource Constraints, Bandwidth Optimization, Power Efficiency. I. INTRODUCTION Wireless voice transmission represents an expeditious communication mechanism and therefore unsurprising that it is always wanted in a wide range of emergency scenarios. Generally, in emergency scenarios the time plays a dominant role in the rescue operation. For an efficient communication mechanism, voice can be a significant interfacing tool between the persons in the disaster zone and the rescue center. Typically, voice interface doesn\u2019t require visual or physical contact with WSN devices. As a result this feature can speed up the input process and consequently speeding up the rescue operation. However, Real-time voice transmission applications have strict requirements by means of end-to-end delay, data losing and dedicated Bandwidth (B.W) during passing the network. So transmitting audio data from disaster zone toward a rescue center with an acceptable quality within Real-Time constraints is an important issue. As explained in the previous chapter, a Real-Time voice transmission platform based streaming system using different encoding techniques was implemented and evaluated. In this chapter an alternative solution which depends on Automatic Speech Recognition (ASR) system is proposed, implemented and evaluated. ASR technology provides tools to transform human voice signals into text. Consequently this text can be sent toward a rescue center with less B.W. and power instead of sending the original voice signal. So in this chapter we aim to evaluate the performance of a proposed VoWSN based on ASR system for efficiently voice transmission system within Real-Time constraints. The workflow principle of our proposed system is depending on a proposed protocol that transforms system category gradually from network dependent ASR system with a full dictionary and language model (i.e. large vocabulary) to fully embedded ASR system with customized dictionary and language model (i.e. small vocabulary ) specified to closer resemble typical domain. This transformation is performed by deploying Category Transformation Protocol (CTP) which is designed for this purpose (as illustrated in section 4.4). The purpose of optimizing the dictionary (Dic.) and Language Model (LM) is to enhance the ASR system performance in terms of decoding time, Word Error rate (WER) and efficiency. As a result, the"
}