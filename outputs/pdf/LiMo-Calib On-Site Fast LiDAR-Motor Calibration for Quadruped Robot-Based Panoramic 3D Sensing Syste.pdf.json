{
  "code_links": "None",
  "tasks": [
    "LiDAR-motor calibration",
    "3D sensing"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "LiMo-Calib",
    "normal distribution feature selection",
    "adaptive neighborhood correspondence",
    "normal homogenization"
  ],
  "results": [
    "Improved calibration efficiency and 3D sensing accuracy",
    "Lower plane fitting errors",
    "Faster convergence speed"
  ],
  "title": "LiMo-Calib On-Site Fast LiDAR-Motor Calibration for Quadruped Robot-Based Panoramic 3D Sensing Syste.pdf",
  "abstract": "\u2014 Conventional single LiDAR systems are inherently constrained by their limited field of view (FoV), leading to blind spots and incomplete environmental awareness, particularly on robotic platforms with strict payload limitations. Integrating a motorized LiDAR offers a practical solution by significantly expanding the sensor\u2019s FoV and enabling adaptive panoramic 3D sensing. However, the high-frequency vibrations of the quadruped robot introduce calibration challenges, causing variations in the LiDAR-motor transformation that degrade sensing accuracy. Existing calibration methods that use artificial targets or dense feature extraction lack feasibility for on- site applications and real-time implementation. To overcome these limitations, we propose LiMo-Calib, an efficient on- site calibration method that eliminates the need for external targets by leveraging geometric features directly from raw LiDAR scans. LiMo-Calib optimizes feature selection based on normal distribution to accelerate convergence while maintain- ing accuracy and incorporates a reweighting mechanism that evaluates local plane fitting quality to enhance robustness. We integrate and validate the proposed method on a motorized LiDAR system mounted on a quadruped robot, demonstrat- ing significant improvements in calibration efficiency and 3D sensing accuracy, making LiMo-Calib well-suited for real-world robotic applications. The demo video is available at: https: //youtu.be/FMINa-sap7g. I. INTRODUCTION In recent years, robotic platforms, particularly quadruped robots, have seen significant advancements, making them increasingly valuable for applications such as autonomous inspection, search and rescue, and exploration of complex environments [1], [2]. However, conventional LiDAR sys- tems are inherently constrained by their limited field of view (FoV), leading to blind spots and incomplete environmental awareness [3]. Given the weight and size constraints of quadruped robots, mounting multiple LiDAR units to en- hance FoV is often impractical [4]\u2013[8]. A more efficient solu- tion is integrating a motorized LiDAR [9] onto the quadruped robot platform for a panoramic 3D sensing system as shown in Fig. 1. By leveraging motor control, the motorized LiDAR substantially expands the sensor\u2019s FoV, enabling broader spatial coverage and adaptive scanning to focus on critical features. This work was supported by National Research Foundation, Singapore, under its Medium-Sized Center for Advanced Robotics Technology Innovation. J. Li, Z. Liu, X. Xu, J. Liu, S. Yuan, and L. Xie are with School of Electrical and Electronic Engineering, Nanyang Technological University, 50 Nanyang Avenue, Singapore. (E-mail: jianping.li@ntu.edu.sg, zliu051@e.ntu.edu.sg, xu0021ng@e.ntu.edu.sg, jinxin.liu@ntu.edu.sg, shyuan@ntu.edu.sg, elhxie@ntu.edu.sg) (Jianping Li and Zhongyuan Liu contribute equally to this work.) LiDAR Motor Robot Dog Fig. 1: Coordinates and mechanical design of the proposed motorized LiDAR system on a quadruped robot. Integrating a motorized LiDAR with a quadruped robot introduces significant calibration issues due to the high- frequency vibrations inherent in the robot\u2019s movement [10]. These vibrations and oscillations cause fluctuations in the relative transformation between the LiDAR and the mo- tor, leading to potential misalignment. If not compensated properly on site, these variations can severely degrade the accuracy of 3D sensing, compromising the reliability of the system. The calibration of the LiDAR system has been long studied in the field of robotics [11], [12] and photogrammetry [13], [14]. Artificial targets are usually used for calibration of the LiDAR system [15]. But the artificial targets may not be available for the on-site calibration applications. De- spite the artificial targets distributed in the calibration filed, planar features extracted from the environment are the most commonly used primitives for automatically constructing the calibration functions [11], [13], [16]. Nevertheless, the large number of extracted planar features significantly increases computational complexity, leading to long processing times that are impractical for edge computing units on mobile robots. Existing LiDAR-motor calibration methods inher- ently involve a trade-off between the number of extracted primitives and calibration accuracy. A higher number of primitives can enhance accuracy by providing more con- straints, but it also leads to increased computational demands arXiv:2502.12655v1 [cs.RO] 18 Feb 2025"
}