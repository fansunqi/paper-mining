{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Remote Ultrasound"
  ],
  "datasets": [
    "Blue Phantom branched 2-vessel training block"
  ],
  "methods": [
    "Visual-Haptic Model Mediated Teleoperation",
    "Robot Control with ROS and LibFranka",
    "Communication with WebRTC",
    "Calibration with ArUco markers",
    "Haptics with point cloud-based models"
  ],
  "results": [
    "VH-MMT compensates completely for time delays up to 1000 ms round trip",
    "VH-MMT significantly outperforms MMT for longer time delays in terms of motion accuracy and force control",
    "VH-MMT decreases completion time significantly",
    "VH-MMT reduces mental demand and effort and increases perceived performance"
  ],
  "title": "Visual-Haptic Model Mediated Teleoperation for Remote Ultrasound.pdf",
  "abstract": "\u2014 Tele-ultrasound has the potential greatly to im- prove health equity for countless remote communities. However, practical scenarios involve potentially large time delays which cause current implementations of telerobotic ultrasound (US) to fail. Using a local model of the remote environment to provide haptics to the expert operator can decrease teleop- eration instability, but the delayed visual feedback remains problematic. This paper introduces a robotic tele-US system in which the local model is not only haptic, but also visual, by re-slicing and rendering a pre-acquired US sweep in real time to provide the operator a preview of what the delayed image will resemble. A prototype system is presented and tested with 15 volunteer operators. It is found that visual-haptic model- mediated teleoperation (MMT) compensates completely for time delays up to 1000 ms round trip in terms of operator effort and completion time while conventional MMT does not. Visual- haptic MMT also significantly outperforms MMT for longer time delays in terms of motion accuracy and force control. This proof-of-concept study suggests that visual-haptic MMT may facilitate remote robotic tele-US. I. INTRODUCTION With growing populations, global pandemics like COVID- 19, and the rising economic and environmental cost of transportation, the ability to provide quality healthcare at a distance is of increasing importance. Furthermore, many countries struggle to provide adequate healthcare for their rural communities. For example, geographical isolation is cited as a central barrier to US (US) imaging for many remote communities in Canada [1]. To solve this problem, a spectrum of solutions has been proposed and tested, from video conferencing-based tele- guidance to mixed reality \u201chuman teleoperation\u201d [2], to robotic teleoperation [3]. The latter has been heavily studied, with many recent surveys covering robotic US [4], [5], machine learning in robotic US [6], and autonomous US scans [7]. Autonomous execution of a full US exam is still far from reality, so teleoperation is essential. In telerobotic US, an expert physician remotely controls a follower robot that has an US transducer on its end effector. The expert manipulates a master device to input their desired motion and receive force feedback through bilateral teleoperation. Sonographers usually look almost exclusively at the US image while scanning, relying on a haptic sense of the patient to move their transducer precisely. Moreover, it is often necessary to press relatively hard, commonly up to 1Department of Electrical and Computer Engineering, University of British Columbia, Vancouver, Canada dgblack@ece.ubc.ca, tims@ece.ubc.ca 2ImFusion GmbH, 80992 Munich, Germany tirindelli@imfusion.com, wein@imfusion.com, esposito@imfusion.com 25 N for abdominal scans [8], to modulate the force to avoid deforming organs, or to press in a certain way to look under the ribs or displace bowel gas that otherwise obscures the image. Without force feedback, such actions are not possible. A bilateral teleoperation system is transparent if the follower perfectly matches the master\u2019s trajectory and the master reflects exactly the force experienced by the follower. However, long-distance bilateral teleoperation over the Internet leads to potentially large and varying time delays between the master and follower, especially if the patient side is in a remote location with poor Internet connection. Even small time delays can quickly destabilize a nominally stable bilateral teleoperation system [9]. Many architectures have been proposed to overcome this challenge and guarantee stability despite delays, including wave variables [10] and the time domain passivity approach (TDPA) [11]. While the former sacrifices tracking performance and transparency to achieve stability, TDPA can reach a high degree of transparency. However, the reflected force is still ultimately delayed, as are the video and US streams. Some groups working on tele-US have implemented bilat- eral teleoperation with force feedback but negligible delay on a local network [12], [13] while Arbeille et al. had a 1-2 second delay but no force feedback [14]. Fu et al. considered delays in their system and overcame them using model- mediated teleoperation (MMT) [15]. In MMT, the remote environment is modeled and re- produced by the master as a virtual fixture, allowing the operator to interact with it directly [16]. A virtual fixture is a surface or volume in space where a haptic device can apply an outward force when the user moves the end effector into the region, according to a virtual spring and damper or other impedance model [17]. The surface can be a mesh reconstructed from a depth or RGBD image of the environment, and the impedance can be estimated using force and pose sensing on the follower robot. By having the model locally, MMT gives the operator instant haptic feedback irrespective of time delay. As a result, it has been used successfully in space teleoperation [18] and has shown better performance than TDPA in some low-velocity motions [19]. The method depends on having a static or slowly varying environment with relatively constant mechanical impedance, although methods for near-real-time updates of the model and fast impedance estimation have been proposed [20]. The static assumption works relatively well for a patient undergoing an US exam. However, instant haptic feedback does not account for the delay in the images. It has been shown that performance decreases when delay exceeds 150 ms for haptic tasks [21], arXiv:2502.07922v1 [cs.RO] 11 Feb 2025"
}