{
  "code_links": [
    "None"
  ],
  "tasks": [
    "High Frequency Partial Differential Equations in High Dimensions"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Kolmogorov high order deep neural network (K-HOrderDNN)"
  ],
  "results": [
    "K-HOrderDNNs(p>1) exhibit remarkable performance on high-dimensional problems",
    "K-HOrderDNN(p=7) achieves an error of 4.40E-03 on a 10-dimensional problem",
    "K-HOrderDNNs(p>1) can achieve higher accuracy with fewer parameters and faster convergence rates compared to HOrderDNNs"
  ],
  "title": "A Kolmogorov High Order Deep Neural Network for High Frequency Partial Differential Equations in Hig.pdf",
  "abstract": ". This paper proposes a Kolmogorov high order deep neural network (K- HOrderDNN) for solving high-dimensional partial differential equations (PDEs), which improves the high order deep neural networks (HOrderDNNs). HOrderDNNs have been demonstrated to outperform conventional DNNs for high frequency problems by introducing a nonlinear transformation layer consisting of (p+1)d basis functions. However, the number of basis functions grows exponentially with the dimension d, which results in the curse of dimensionality (CoD). Inspired by the Kolmogorov su- perposition theorem (KST), which expresses a multivariate function as superpositions of univariate functions and addition, K-HOrderDNN utilizes a HOrderDNN to effi- ciently approximate univariate inner functions instead of directly approximating the multivariate function, reducing the number of introduced basis functions to d(p+1). We theoretically demonstrate that CoD is mitigated when target functions belong to a dense subset of continuous multivariate functions. Extensive numerical experiments show that: for high-dimensional problems (d=10, 20, 50) where HOrderDNNs(p > 1) are intractable, K-HOrderDNNs(p > 1) exhibit remarkable performance. Specifically, when d=10, K-HOrderDNN(p=7) achieves an error of 4.40E-03, two orders of magni- tude lower than that of HOrderDNN(p=1) (see Table 10); for high frequency problems, K-HOrderDNNs(p>1) can achieve higher accuracy with fewer parameters and faster convergence rates compared to HOrderDNNs (see Table 8). AMS subject classifications: 68T99, 35Q68, 65N99 Key words: Deep neural network, Kolmogorov Superposition Theorem, high-dimensional and high-frequency PDEs. \u2020These authors contributed equally to this work. \u2217Corresponding author. Email addresses: huangyq@xtu.edu.cn (Y. Huang), xiangxueshuang2023@163.com (X. Xiang) http://www.global-sci.com/ Global Science Preprint arXiv:2502.01938v1 [math.NA] 4 Feb 2025"
}