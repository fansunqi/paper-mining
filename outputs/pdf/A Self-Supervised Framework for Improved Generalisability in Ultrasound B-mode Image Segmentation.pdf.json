{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Ultrasound B-mode Image Segmentation"
  ],
  "datasets": [
    "BUSI",
    "BrEaST",
    "UDIAT"
  ],
  "methods": [
    "Contrastive SSL",
    "Relation Contrastive Loss (RCL)",
    "Perceptual Loss",
    "Cross-patch Jigsaw",
    "Frequency-based Filtering"
  ],
  "results": [
    "Improved Dice similarity metric by 4% on 20% and 50% of the BUSI dataset",
    "Improved Dice similarity metric by nearly 6% and 9% on 20% and 50% of the BrEaST dataset",
    "Improved Dice similarity metric by 6.4% and 3.7% on 20% and 50% of the UDIAT dataset",
    "Performance boost of 20.6% and 13.6% on the UDIAT dataset compared to the supervised baseline"
  ],
  "title": "A Self-Supervised Framework for Improved Generalisability in Ultrasound B-mode Image Segmentation.pdf",
  "abstract": "\u2014Ultrasound (US) imaging is clinically invaluable due to its noninvasive and safe nature. However, interpreting US images is challenging, requires significant expertise, and time, and is often prone to errors. Deep learning offers assistive solutions such as segmentation. Supervised methods rely on large, high-quality, and consistently labeled datasets, which are challenging to curate. Moreover, these methods tend to underperform on out-of-distribution data, limiting their clinical utility. Self-supervised learning (SSL) has emerged as a promising alternative, leveraging unlabeled data to enhance model performance and generalisability. We introduce a contrastive SSL approach tailored for B- mode US images, incorporating a novel Relation Contrastive Loss (RCL). RCL encourages learning of distinct features by differentiating positive and negative sample pairs through a learnable metric. Additionally, we propose spatial and frequency-based augmentation strategies for the representation learning on US images. Our approach significantly outperforms traditional supervised segmen- tation methods across three public breast US datasets, particularly in data-limited scenarios. Notable improvements on the Dice similarity met- ric include a 4% increase on 20% and 50% of the BUSI dataset, nearly 6% and 9% improvements on 20% and 50% of the BrEaST dataset, and 6.4% and 3.7% improvements on 20% and 50% of the UDIAT dataset, respectively. Furthermore, we demonstrate superior generalisability on the out-of-distribution UDIAT dataset with performance boosts of 20.6% and 13.6% compared to the supervised baseline using 20% and 50% of the BUSI and BrEaST training data, respectively. Our research highlights that domain-inspired SSL can improve US segmentation, especially under data-limited conditions. Index Terms\u2014Contrastive learning, deep learning, generalisability, self-supervised learning, ultrasound imaging I. INTRODUCTION US imaging provides a non-invasive, portable and low-cost imaging solution for clinicians compared to alternative imaging modalities, such as CT and MRI. US is a popular and widely used imaging tool within clinical practice for imaging various organs, such as cardiac, breast and abdominal examination [1]. However, US imaging suffers from large variability in image quality and is considered a highly operator-dependent procedure [2]. Data acquisition and interpretation of US images require significant operator skill, is time-consuming and erroneous. Using recent advancements in artificial intelligence (AI) approaches can assist clinicians in identifying key anatomical features to support clinical diagnosis, reduce human-related errors and minimise inter-operator variability. Deep learning (DL) approaches for US image segmentation have been extensively researched in many clinical domains. State-of-the- art supervised learning approaches have been developed using both recent transformers and convolutional neural network (CNN) based architectures [3]\u2013[5]. Furthermore, memory banks have been used in supervised learning to store image features [5] or class features [6], providing additional information to enhance image segmentation through cross-image feature aggregation [5], [6]. However, supervised This work was supported by UK Research and Innovation (UKRI) [CDT grant number EP/S024336/1] and Satisfai Health. E. Ellis, A. Bulpitt and S. Ali are with the School of Computer Science, Faculty of Engineering and Physical Sciences, University of Leeds, LS2 9JT, Leeds, United Kingdom (emails: {scee, a.j.bulpitt, s.s.ali}@leeds.ac.uk) N. Parsa and M. Byrne are with Satisfai Health, 1050 Homer Street, Suite 390, Vancouver, BC V6B 2W9, Canada learning methods are dependent on large data samples to perform effectively. These datasets are difficult to curate in the US domain with significant expertise required to acquire, anonymise, and an- notate the data. Even with improvements in model development, many supervised approaches result in a steep drop in performance on unseen out-of-distribution data [7]. Models applied to data from alternative centres and under different imaging protocols can hinder performance [8]. Furthermore, most development is focused on a single clinical domain. We recognise that US B-mode image data is commonly used across many clinical domains but with unique challenges. We hypothesise that a generalisable framework can be applied to a range of public US B-mode image datasets without a significant drop in performance on out-of-distribution data. To overcome issues with limited annotated training data for ef- fective supervised learning, self-supervised learning (SSL) methods are becoming increasingly popular in medical image analysis [9], [10]. SSL pretext learning methods learn semantically meaningful feature representations from unlabelled data. The trained model is then fine-tuned for downstream tasks, such as segmentation, using available labelled data. SSL approaches improve model performance in the downstream task with limited labelled data as well as improved generalisability to out-of-distribution datasets [11], [12]. Several SSL approaches have been applied to US imaging, how- ever, these are often tailored to specific clinical domain challenges, with limited generalisability assessment (e.g., wrist US [13] and thyroid US [14]). The contrastive learning approach has demonstrated improved performance for downstream tasks like segmentation [15] in an SSL setting. All SOTA contrastive SSL approaches rely on a trans- formed image to support representation learning [16]. Transforma- tions often include image rotation, flipping, colour jittering or more complex augmentation approaches [17]. Combining transformations has also been shown to benefit representation learning in SSL [16], [18]. However, we hypothesise that learnt representations depend on a domain-specific data-engineering technique and hence we can improve US B-mode image segmentation using domain understand- ing. Inspired by pretext-invariant representation learning (PIRL) [16] strategy, we propose a novel self-supervised pretext learning approach consisting of spatial and frequency-based augmentations for US B- mode images. In addition, we develop a novel loss function that aims to minimise the feature-level discrepancy and logit-level contrastive discrepancy. Key contributions of our work include: 1) Domain-inspired data-engineered pretext learning with spatial and frequency-based augmentations for US B-mode images. 2) Novel relation contrastive loss (RCL) to enhance inter-class separation. RCL compares a logit output from a shallow learn- able neural network as a mean squared distance from the ground truth label. Minimising the RCL encourages the network to learn a non-linear separation between data points of negative samples while similar samples are pulled together. 3) Perceptual loss within contrastive SSL to weight representation learning for both higher-level and more abstract features. 4) We provide a comprehensive benchmark of our proposed ap- proach and baseline on 3 publicly available breast US datasets. arXiv:2502.02489v1 [cs.CV] 4 Feb 2025"
}