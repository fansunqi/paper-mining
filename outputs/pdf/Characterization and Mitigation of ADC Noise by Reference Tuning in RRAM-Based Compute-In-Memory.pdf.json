{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Characterization and Mitigation of ADC Noise by Reference Tuning in RRAM-Based Compute-In-Memory"
  ],
  "datasets": [
    "CIFAR-10",
    "ImageNet",
    "GridWorld",
    "Drone autonomous navigation"
  ],
  "methods": [
    "RRAM-based compute-in-memory",
    "ADC noise mitigation",
    "Reference tuning",
    "Effective bit analysis",
    "Read disturb analysis"
  ],
  "results": [
    "Impact of CIM noise on supervised learning and reinforcement learning",
    "Per-module and per-ADC tuning effectiveness",
    "Read disturb mitigation"
  ],
  "title": "Characterization and Mitigation of ADC Noise by Reference Tuning in RRAM-Based Compute-In-Memory.pdf",
  "abstract": "\u2014With the escalating demand for power-efficient neu- ral network architectures, non-volatile compute-in-memory de- signs have garnered significant attention. However, owing to the nature of analog computation, susceptibility to noise remains a critical concern. This study confronts this challenge by intro- ducing a detailed model that incorporates noise factors arising from both ADCs and RRAM devices. The experimental data is derived from a 40nm foundry RRAM test-chip, wherein different reference voltage configurations are applied, each tailored to its respective module. The mean and standard deviation values of HRS and LRS cells are derived through a randomized vector, forming the foundation for noise simulation within our analytical framework. Additionally, the study examines the read-disturb effects, shedding light on the potential for accuracy deterioration in neural networks due to extended exposure to high-voltage stress. This phenomenon is mitigated through the proposed low-voltage read mode. Leveraging our derived comprehensive fault model from the RRAM test-chip, we evaluate CIM noise impact on both supervised learning (time-independent) and reinforcement learning (time-dependent) tasks, and demonstrate the effectiveness of reference tuning to mitigate noise impacts. I. INTRODUCTION With the surge in machine learning and deep neural net- work applications, the demand for enhanced computational capability and efficiency has escalated. Yet, in settings like edge computing environments, power and efficiency become critical constraints. Non-volatile memory devices, distinguished by their negligible power consumption during data retention, emerge as potential answers to this quandary. These encompass RRAM [1], MRAM [2], PCM [3], FeFET [4], and floating-gate devices [5]. Beyond the power savings offered by these memory components, compute-in-memory (CIM) architecture [6]\u2013[10] promises further reductions in power consumption. While RRAM technology boasts several merits, it is also marred by challenges like limited on/off ratios, inter-cell varia- tions, stuck-at-fault and shifts in resistance [11]\u2013[13]. Beyond RRAM-induced noise, CIM brings forth systemic inaccuracies, such as ADC non-linearity and variance across ADCs. Recent efforts have attempted to address concerns regarding on/off ratio, ADC non-linearity, module partitioning, and the remapping of defective cells [14]\u2013[16]. Yet, these solutions often overlook variations between ADCs, which, if neglected, can culminate in challenges like diminished yields and skewed results. On the software aspect, tactics like noise injection during training to bolster robustness [17]\u2013[19] demand a grasp of the actual noise impact. However, a holistic noise analysis * These authors contributed equally to this work. This work was supported by CoCoSys, one of seven centers in JUMP2.0, a Semiconductor Research Corporation (SRC) sponsored by DARPA. CIFAR-10 (VGG-8) ImageNet (ResNext50-32x4d) GridWorld (MLP) Autonomous Navigation (3Conv-2FC) Accuracy / Task Success Rate Quantized Only RRAM CIM Noise Fig. 1: Impact of noises on different scenarios, including super- vised learning (time-independent) and unsupervised learning (time- dependent). While some adapted effectively to per-module reference adjustments, others necessitated a more refined per-ADC tuning. necessitates an intricate simulation. Hence, our goal is to create a streamlined model that encompasses primary noise sources. This model aims to gauge the feasibility of an adjustable reference for CIM structures on a module-wise scale, analyzing its influence on diverse tasks. Additionally, given that we operate the test chip under relatively low-stress conditions for the RRAM cells, we demonstrate minimal resistance shifts in these cells, rendering read disturbances almost inconsequential. This paper, therefore, makes the following contributions: \u2022 We develop a methodology to encapsulate the behavior of ADCs and RRAM cells, integrating the CIM noise into the cross-layer device-to-application analysis framework. \u2022 We analyze and quantify the impact of CIM resistance shifts caused by read disturbances, and evaluate this in the context of supervised (time-independent) and reinforce- ment (time-dependent) learning scenarios. \u2022 We evaluate the accuracy of different workloads and showcase the efficacy of per-module reference tuning. II. BACKGROUND AND MOTIVATIONS A. Compute-In-Memory To enhance the computational efficiency of neural networks, particularly in the context of Vector Matrix Multiplication (VMM), CIM structures are increasingly employed. These structures capitalize on encoding the input vector and distribut- ing it across the wordlines (WLs) of memory cells. Subse- quently, when a WL is activated, a greater current flows through the Low Resistance State (LRS) as compared to the High Resistance State (HRS) of the RRAM device. The resulting currents are then aggregated through Kirchhoff\u2019s Current Law and quantized through ADCs [7], [8]. arXiv:2502.05948v1 [cs.ET] 9 Feb 2025"
}