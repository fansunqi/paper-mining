{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Smart Ring Interaction",
    "Health Monitoring",
    "Activity Recognition",
    "Environmental Sensing",
    "Authentication"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Gesture Recognition",
    "Trajectory Tracking",
    "Text Entry",
    "Haptic Feedback",
    "Physiological Sensing",
    "Sleep Monitoring",
    "Bioelectrical Impedance",
    "Grip Force Monitoring",
    "Urodynamics Measurement",
    "Sleep Apnea Detection",
    "COVID Management",
    "Activity Recognition",
    "Environmental Information Detection",
    "Interaction Object Detection",
    "Behavioral Biometric Authentication",
    "Key-Based Authentication",
    "Cross-Device Authentication"
  ],
  "results": [
    "None"
  ],
  "title": "Computing with Smart Rings A Systematic Literature Review.pdf",
  "abstract": "Designed for use with fingers, smart rings are capable of sensing more subtle and abundant hand movements, thus making them a good platform for interaction. Meanwhile, fingers are abundant with blood vessels and nerve endings and accustomed to wearing rings, providing an ideal site for continuous health monitoring through smart rings, which combine comfort with the ability to capture vital biometric data, making them suitable for all-day wear. We collected in total of 206 smart ring-related publications and conducted a systematic literature review. We provide a taxonomy regarding the sensing and feedback modalities, applications, and phenomena. We review and categorize these literatures into four main areas: (1) interaction - input, (2) interaction - output, (3) passive sensing - in body feature, (4) passive sensing - out body activity. This comprehensive review highlights the current advancements within the field of smart ring and identifies potential areas for future research. \u2217Corresponding authors. Authors\u2019 Contact Information: Zeyu Wang, wang-zy23@mails.tsinghua.edu.cn, Key Laboratory of Pervasive Computing, Ministry of Education, Department of Computer Science and Technology, Tsinghua University, China; Ruotong Yu, yurt24@mails.tsinghua.edu.cn; Xiangyang Wang, xiangyang24@mails.tsinghua.edu.cn, Tsinghua University, China; Jiexin Ding, jxding@uw.edu, Electrical and Computer Engineering, University of Washington, The United State; Jiankai Tang; Jun Fang, fangy23@mails.tsinghua.edu.cn; Zhe He, hz23@mails.tsinghua.edu.cn; Zhuojun Li, lizj23@mails.tsinghua.edu.cn, Tsinghua University, China; Tobias R\u00f6ddiger, tobias.roeddiger@kit.edu, Karlsruhe Institute of Technology, Germany; Weiye Xu, xuwy24@mails.tsinghua.edu.cn; Xiyuxing Zhang, zxyx22@mails.tsinghua.edu.cn; Huan-ang Gao, gha24@mails.tsinghua.edu.cn; Nan Gao, nangao@tsinghua.edu.cn; Chun Yu, chunyu@tsinghua.edu.cn, Tsinghua University, China; Yuanchun Shi, Key Laboratory of Pervasive Computing, Ministry of Education, Department of Computer Science and Technology, Tsinghua University, China and Intelligent Computing and Application Laboratory of Qinghai Province, Qinghai University, China, shiyc@tsinghua.edu.cn; Yuntao Wang, yuntaowang@tsinghua.edu.cn, Key Laboratory of Pervasive Computing, Ministry of Education, Department of Computer Science and Technology, Tsinghua University, China. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. \u00a9 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM 2474-9567/2025/2-ART https://doi.org/XXXXXXX.XXXXXXX Proc. ACM Interact. Mob. Wearable Ubiquitous Technol., Vol. 1, No. 1, Article . Publication date: February 2025. arXiv:2502.02459v1 [cs.HC] 4 Feb 2025"
}