{
  "code_links": "None",
  "tasks": [
    "Cardiac Ultrasound Image Segmentation"
  ],
  "datasets": [
    "CAMUS",
    "HMC-QU"
  ],
  "methods": [
    "Gaze Augment Align Module",
    "Gaze Balance Loss"
  ],
  "results": [
    "DSC: 76.14%, ASSD: 6.976"
  ],
  "title": "Gaze-Assisted Human-Centric Domain Adaptation for Cardiac Ultrasound Image Segmentation.pdf",
  "abstract": "\u2014Domain adaptation (DA) for cardiac ultrasound image segmentation is clinically signi\ufb01cant and valuable. How- ever, previous domain adaptation methods are prone to be affected by the incomplete pseudo-label and low-quality target to source images. Human-centric domain adaptation has great advantages of human cognitive guidance to help model adapt to target domain and reduce reliance on labels. Doctor gaze trajectories contains a large amount of cross-domain human guidance. To leverage gaze information and human cognition for guiding domain adaptation, we propose gaze-assisted human- centric domain adaptation (GAHCDA), which reliably guides the domain adaptation of cardiac ultrasound images. GAHCDA includes following modules: (1) Gaze Augment Alignment (GAA): GAA enables the model to obtain human cognition general features to recognize segmentation target in different domain of cardiac ultrasound images like humans. (2) Gaze Balance Loss (GBL): GBL fused gaze heatmap with outputs which makes the segmentation result structurally closer to the target domain. The experimental results illustrate that our proposed framework is able to segment cardiac ultrasound images more effectively in the target domain than GAN-based methods and other self-train based methods, showing great potential in clinical application. Index Terms\u2014Human-Centric, Gaze-Assisted, Domain Adap- tation, Cardiac Ultrasound. I. INTRODUCTION Domain adaptation for cardiac ultrasound segmentation holds signi\ufb01cant clinical value. Through domain adaptation, models are able to address the performance degradation of models across different domain segmentation. However, exist- ing domain adaptation methods face challenges in ultrasound images. Models are prone to over\ufb01t in the target domain because they are unable to learn human cognition general features to eliminate the domain gap. Furthermore, there is a large gap in style between source domain and target domain in cardiac ultrasound images due to the differences in sampling devices, sampling settings, and sampling angles. Existing domain adaptation methods are limited when ap- plied to cardiac ultrasound images. Fully supervised domain * Corresponding author. (Email: rongjun ge@seu.edu.cn) \u2020 These authors contributed equally to this work This study was supported by the Natural Science Foundation of Jiangsu Province (No. BK20210291); the National Natural Science Foundation of China (No. 62101249, No. T2225025 and No. 62136004); the Jiangsu Shuangchuang Talent Program (No. JSSCBS20220202); the China Postdoc- toral Science Foundation (No. 2021TQ0149 and No. 2022M721611) adaptation methods require additional annotations [1], [2]. Semi-supervised or unsupervised domain adaptation methods adapt to different domains using GAN or self-training ap- proaches [3]\u2013[6]. As shown in Fig.1 (a), GAN-based domain adaptation methods struggle to adapt well to the gap in differ- ent domains of cardiac ultrasound images [7]\u2013[17], leading to mode collapse [18]. As shown in Fig.1 (b), domain adaptation based on self-train lacks human cognition guidance, making it prone to over\ufb01t on source domain data, resulting in over\ufb01t on pseudo-labels and incomplete segmentation [19]\u2013[29]. Human-centric domain adaptation holds great advantages of cognitive guidance in cardiac ultrasound domain adaptation. Doctor gaze trajectories contains a large number of cross- domain human guidance. By recording gaze trajectories using an eye tracker, we are able to extract the doctor\u2019s cross-domain recognition knowledge. As shown in Fig.1 (c), utilizing this cross-domain recognition knowledge helps the model elimi- nate the domain gap between source and target domain. In this paper, we propose gaze-assisted human-centric do- main adaptation (GAHCDA) framework for cardiac ultrasound image segmentation tasks. GAHCDA includes following mod- ules: (1) Gaze Aug Align Module (GAA): This is a feature alignment module that integrates human cognition from gaze heatmaps. It utilizes a cross-attention [30] to fuse the encoder features of teacher with gaze heatmap and aligns the features of the student with fused human cognition features, thereby ex- tracting human cognition general features between the source and target domains. (2) Gaze Balance Loss (GBL): By using gaze heatmaps, the model loss is more focused on gaze area, allowing the model to avoid over/under-segmentation in the gaze area rather than being restricted to pseudo-label. II. METHOD A. GAHCDA Framwork In the context of human-centric domain adaptation for cardiac ultrasound image segmentation, we have a source domain dataset Ds = {Xs, Ys}M s=1 and a target domain dataset Dt = {Xt}N t=1, where X represents images and Y represents labels. The objective of GAHCDA is to train a teacher model using source data and use the teacher model to obtain pseudo-labels \u02c6Y T t for target domain images Xt. These pseudo-labels are then used to train a student model for the"
}