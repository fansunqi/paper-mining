{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Understanding Vulnerabilities in the Large Language Model Supply Chain"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Systematic Study",
    "Root Cause Taxonomy",
    "Fix Pattern Investigation"
  ],
  "results": [
    "529 vulnerabilities analyzed",
    "4 categories and 11 subcategories of root causes",
    "300 vulnerabilities with available fixes analyzed"
  ],
  "title": "SoK Understanding Vulnerabilities in the Large Language Model Supply Chain.pdf",
  "abstract": "Large Language Models (LLMs) transform artificial intelli- gence, driving advancements in natural language understand- ing, text generation, and autonomous systems. The increasing complexity of their development and deployment introduces significant security challenges, particularly within the LLM supply chain. However, existing research primarily focuses on content safety, such as adversarial attacks, jailbreaking, and backdoor attacks, while overlooking security vulnerabilities in the underlying software systems. To address this gap, this study systematically analyzes 529 vulnerabilities reported across 75 prominent projects spanning 13 lifecycle stages. The findings show that vulnerabilities are concentrated in the application (50.3%) and model (42.7%) layers, with im- proper resource control (45.7%) and improper neutralization (25.1%) identified as the leading root causes. Additionally, while 56.7% of the vulnerabilities have available fixes, 8% of these patches are ineffective, resulting in recurring vulner- abilities. This study underscores the challenges of securing the LLM ecosystem and provides actionable insights to guide future research and mitigation strategies. 1 Introduction Large Language Models (LLMs) have ushered in a new era of artificial intelligence (AI), redefining what is possible in domains such as natural language understanding [31,37,65], text generation [16,65], software engineering [17,23,55], and autonomous systems [53,58]. These models, built on billions of parameters and trained on extensive datasets, have demon- strated superhuman capabilities in tasks like mathematical reasoning [2], video generation [33], and code generation [52]. Since the release of ChatGPT [39], the field has seen an ex- plosion of both commercial and open-source LLMs, with applications expanding across industries, including education, healthcare, and finance. As LLMs continue to integrate into real-world systems, their development and deployment pro- cesses have become increasingly complex and dependent on a variety of components, giving rise to the concept of the LLM Supply Chain [54]. LLM Supply Chain. The LLM supply chain, as defined in previous studies [18,19,54], refers to the interconnected ecosystem of components, stakeholders, and dependencies involved in the lifecycle of LLMs. Unlike traditional soft- ware systems, the LLM supply chain incorporates novel ele- ments such as massive datasets, development toolchains, pre- trained models, and specialized deployment environments. For instance, building an LLM-driven application may in- volve reusing an open-source model, integrating third-party li- braries, and orchestrating workflows with plugins. Each stage introduces dependencies on external components, such as data providers, model repositories, or software frameworks, which collectively form the supply chain. Research Gaps. The growing reliance on the supply chain in developing and deploying LLMs introduces a new dimen- sion of challenges, particularly in terms of security. How- ever, most existing security research has primarily focused on content safety aspects, including adversarial attacks [27,68], jailbreaks [46,59], and backdoor attacks [26,64], which ex- ploit vulnerabilities in the models themselves to manipulate outputs or bypass safety mechanisms. While these studies have provided valuable insights into specific content-related vulnerabilities, they largely overlook the security properties of the underlying system software ecosystem. Furthermore, despite some emerging efforts to address vulnerabilities in LLM software systems [28,40,63,66], these efforts remain fragmented and limited in scope, lacking a comprehensive and systematic understanding of vulnerabilities across the entire LLM ecosystem. For instance, it remains unclear which components are most prone to vulnerabilities, and what root causes underlie these issues. The effectiveness of existing detection techniques in addressing the unique challenges of LLM systems remains uncertain. Without a systematic analy- sis of these aspects, securing the increasingly complex LLM ecosystem remains a significant challenge. Our Work. In this paper, we fill this gap by providing a systematization of knowledge of vulnerabilities in the LLM 1 arXiv:2502.12497v1 [cs.CR] 18 Feb 2025"
}