{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Responsible AI Governance"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Systematic Review",
    "Meta-Analysis",
    "Stakeholder-Stage Matrix"
  ],
  "results": [
    "Significant imbalances across stakeholder roles and lifecycle stages",
    "Most tools developed for AI designers and developers",
    "Lack of validation for usability and effectiveness",
    "Limited tools for leaders, end-users, and impacted communities",
    "Fragmented approach to AI governance"
  ],
  "title": "The who\u201d, what\u201d, and how\u201d of Responsible AI Governance A Systematic Review and Meta-Analysis of (act.pdf",
  "abstract": "KIM\u2217, Carnegie Mellon University, USA JODI FORLIZZI, Carnegie Mellon University, USA HODA HEIDARI, Carnegie Mellon University, USA The implementation of responsible AI in an organization is inherently complex due to the involvement of multiple stakeholders, each with their unique set of goals and responsibilities across the entire AI lifecycle. These responsibilities are often ambiguously defined and assigned, leading to confusion, miscommunication, and inefficiencies. Even when responsibilities are clearly defined and assigned to specific roles, the corresponding AI actors lack effective tools to support their execution. Toward closing these gaps, we present a systematic review and comprehensive meta-analysis of the current state of responsible AI tools, focusing on their alignment with specific stakeholder roles and their responsibilities in various AI lifecycle stages. We categorize over 220 tools according to AI actors and stages they address. Our findings reveal significant imbalances across the stakeholder roles and lifecycle stages addressed. The vast majority of available tools have been created to support AI designers and developers specifically during data-centric and statistical modeling stages while neglecting other roles such as institutional leadership, deployers, end-users, and impacted communities, and stages such as value proposition and deployment. The uneven distribution we describe here highlights critical gaps that currently exist in responsible AI governance research and practice. Our analysis reveals that despite the myriad of frameworks and tools for responsible AI, it remains unclear who within an organization and when in the AI lifecycle a tool applies. Furthermore, existing tools are rarely validated, leaving critical gaps in their usability and effectiveness. These gaps provide a starting point for researchers and practitioners to create more effective and holistic approaches to responsible AI development and governance. Additional Key Words and Phrases: artificial intelligence, machine learning, tool, responsible, governance, stakeholder, lifecycle, transparency, auditing, risk management, ACM Reference Format: Blaine Kuehnert, Rachel M. Kim, Jodi Forlizzi, and Hoda Heidari. 2025. The \u201cWho\u201d, \u201cWhat\u201d, and \u201cHow\u201d of Responsible AI Governance: A Systematic Review and Meta-Analysis of (Actor, Stage)-Specific Tools. 1, 1 (February 2025), 21 pages. https://doi.org/10.1145/ nnnnnnn.nnnnnnn 1 Introduction As the use of Artificial Intelligence (AI) to automate or support critical tasks proliferates, a wide range of interested parties have created principles, frameworks, and tools to ensure that AI systems are aligned with stakeholders\u2019 values. In spite of the growing amount of interest in Responsible AI (RAI) and AI governance, we continue to see AI systems \u2217Both authors contributed equally to this research. Authors\u2019 Contact Information: Blaine Kuehnert, blainekuehnert@cmu.edu; Rachel M. Kim, rachelmkim@cmu.edu, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA; Jodi Forlizzi, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA, forlizzi@andrew.cmu.edu; Hoda Heidari, Carnegie Mellon University, Pittsburgh, Pennsylvania, USA, hheidari@andrew.cmu.edu. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. \u00a9 2025 Copyright held by the owner/author(s). Publication rights licensed to ACM. Manuscript submitted to ACM Manuscript submitted to ACM 1 arXiv:2502.13294v1 [cs.CY] 18 Feb 2025"
}