{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Music Information Retrieval",
    "Automatic Chord Recognition"
  ],
  "datasets": [
    "Isophonics",
    "Billboard",
    "MARL",
    "Humphrey-Bello"
  ],
  "methods": [
    "Conformer",
    "CNN",
    "BLSTM",
    "Transformer",
    "CRF",
    "Re-weighted Loss"
  ],
  "results": [
    "Root accuracy: 84.69%",
    "Maj-Min accuracy: 84.09%",
    "MIREX score: 83.62%",
    "Weighted Chord Symbol Recall (WCSR)"
  ],
  "title": "ChordFormer A Conformer-Based Architecture for Large-Vocabulary Audio Chord Recognition.pdf",
  "abstract": "\u2014Chord recognition serves as a critical task in music information retrieval due to the abstract and descriptive nature of chords in music analysis. While audio chord recognition systems have achieved significant accuracy for small vocabularies (e.g., major/minor chords), large-vocabulary chord recognition remains a challenging problem. This complexity also arises from the inherent long-tail distribution of chords, where rare chord types are underrepresented in most datasets, leading to insufficient training samples. Effective chord recognition requires leveraging contextual information from audio sequences, yet existing models, such as combinations of convolutional neural networks, bidirectional long short-term memory networks, and bidirectional transformers, face limitations in capturing long- term dependencies and exhibit suboptimal performance on large-vocabulary chord recognition tasks. This work proposes ChordFormer, a novel conformer-based architecture designed to tackle structural chord recognition (e.g., triads, bass, sevenths) for large vocabularies. ChordFormer leverages conformer blocks that integrate convolutional neural networks with transformers, thus enabling the model to capture both local patterns and global dependencies effectively. By addressing challenges such as class imbalance through a reweighted loss function and struc- tured chord representations, ChordFormer outperforms state- of-the-art models, achieving a 2% improvement in frame-wise accuracy and a 6% increase in class-wise accuracy on large- vocabulary chord datasets. Furthermore, ChordFormer excels in handling class imbalance, providing robust and balanced recognition across chord types. This approach bridges the gap between theoretical music knowledge and practical applications, advancing the field of large-vocabulary chord recognition. Index Terms\u2014Automatic chord estimation, Deep Learning, music information processing, Machine Leanrning I. INTRODUCTION A UTOMATIC chord recognition (ACR) forms the foun- dation of music information retrieval, acting as a key tool for understanding and analyzing the harmonic structure of music. ACR systems aim at decoding audio recordings into sequences of time-synchronized chord labels, enabling various applications such as automatic lead-sheet creation [1], music structure analysis [2], key classification [3], and cover Muhamamd Waseem Akram is with Department of Excellence in Robotics and AI, Sant\u2019Anna School of Advanced Studies, Itay (e-mail: muhammad- waseem.akram@santannapisa.it). Stefano Dettor is with Department of Excellence in Robotics and AI, Sant\u2019Anna School of Advanced Studies, Italy (e-mail: stefano.dettori@santannapisa.it). Valentina Colla is with Department of Excellence in Robotics and AI, Sant\u2019Anna School of Advanced Studies, Italy (e-mail: valentina.colla@santannapisa.it). Giorgio Carlo Buttazzo is with Department of Excellence in Robotics and AI, Sant\u2019Anna School of Advanced Studies, Italy (e-mail: gior- gio.buttazzo@santannapisa.it). song identification [4]. These systems not only assist musi- cians, composers, and educators but also facilitate a deeper understanding of musical content, aiding in the preservation and exploration of diverse musical traditions. Despite its transformative potential, ACR remains a challenging task due to the inherent complexities of musical chords, their temporal structures [5], and the uneven distribution of chord types in real-world music datasets [6], [7]. Chords, as fundamental elements of harmony, are more than just combinations of notes [8]. They carry rich musical seman- tics and temporal relationships that are rooted in centuries of music theory and practice. These relationships are far from random, often following well-defined harmonic progressions that exhibit long-term dependencies. Modeling these depen- dencies is crucial for accurate chord recognition, but it is challenging task [5]. Standard approaches, such as Hidden Markov Models (HMMs) [9], [10], have historically relied on transition matrices to capture these temporal dynamics, but they struggle to extend beyond short-term dependencies due to their limited capacity to model complex and long-range relationships. Similarly, n-gram models [11] and feedforward neural networks [12] have been explored, but their effective- ness is limited by the relatively small harmonic context they can capture. The advent of deep learning has brought significant ad- vancements to ACR [13], [14], [12], enabling models to learn from large datasets and capture intricate patterns in musical data. Architectures such as convolutional neural networks (CNNs) [6], [15], [16], [17] and recurrent neural networks (RNNs) [13], [18], [19], [20], [21] have been widely adopted, offering the ability to jointly model chord sequence consis- tency, chord duration, and other related features. However, these architectures are not without limitations. CNNs, for instance, are inherently designed to capture local patterns and struggle with long-term dependencies, while RNNs often face issues such as vanishing gradient, which hinder their ability to remember distant temporal information. Such limitations have spurred the exploration of attention mechanisms and transformer-based architectures, which have revolutionized sequence modeling in fields like natural language process- ing [22], [23], speech recognition [24], and music genera- tion [25]. Transformers, characterized by their self-attention mecha- nisms, excel at capturing long-range dependencies and global context without relying on recurrence or convolution. Their ability to dynamically weigh the importance of different parts of an input sequence has proven transformative in various domains. In the context of ACR, such capabilities hold promise arXiv:2502.11840v1 [cs.SD] 17 Feb 2025"
}