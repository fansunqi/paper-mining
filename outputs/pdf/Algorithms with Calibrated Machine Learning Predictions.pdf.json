{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Online algorithms with predictions",
    "Ski rental",
    "Online job scheduling"
  ],
  "datasets": [
    "Citi Bike rentals",
    "Sepsis Survival Minimal Clinical Records"
  ],
  "methods": [
    "Calibration",
    "Histogram Binning",
    "Platt Scaling"
  ],
  "results": [
    "E[CR(Ak\u2217)] \u2264 1 + 2\u03b1+min{E[f(X)] + \u03b1, 2\u221a(f(X) + \u03b1)(1\u2212 f(X) + \u03b1)}",
    "Expected competitive ratio for job scheduling"
  ],
  "title": "Algorithms with Calibrated Machine Learning Predictions.pdf",
  "abstract": "The field of algorithms with predictions incorporates machine learning advice in the design of online algorithms to improve real-world performance. While this theoretical framework often assumes uniform reliability across all predictions, modern machine learning models can now provide instance-level uncertainty estimates. In this paper, we propose calibration as a principled and practical tool to bridge this gap, demonstrating the benefits of calibrated advice through two case studies: the ski rental and online job scheduling problems. For ski rental, we design an algorithm that achieves optimal prediction-dependent performance and prove that, in high-variance settings, calibrated advice offers more effective guidance than alternative methods for uncertainty quantification. For job scheduling, we demonstrate that using a calibrated predictor leads to significant performance improvements over existing methods. Evaluations on real-world data validate our theoretical findings, highlighting the practical impact of calibration for algorithms with predictions. \u2217Department of Computer Science, Stanford University. Email: jhshen@stanford.edu \u2020Department of Management Science & Engineering, Stanford University. Email: vitercik@stanford.edu \u2021Department of Management Science & Engineering, Stanford University. Email: wikum@stanford.edu 1 arXiv:2502.02861v2 [stat.ML] 6 Feb 2025"
}