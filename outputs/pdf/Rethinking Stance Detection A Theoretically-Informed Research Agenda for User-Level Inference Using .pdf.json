{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Stance detection",
    "User-level stance detection",
    "Language models in stance detection"
  ],
  "datasets": [
    "Twitter",
    "SemEval",
    "BIGNEWS",
    "Connected Behavior",
    "X-stance"
  ],
  "methods": [
    "LLMs",
    "Prompting",
    "Fine-tuning",
    "Multi-agent systems",
    "Calibration networks",
    "Knowledge injection"
  ],
  "results": [
    "Improved stance detection performance",
    "Enhanced user-level stance detection",
    "Increased interpretability"
  ],
  "title": "Rethinking Stance Detection A Theoretically-Informed Research Agenda for User-Level Inference Using .pdf",
  "abstract": "Stance detection has emerged as a popular task in natural language processing research, enabled largely by the abundance of target-specific social media data. While there has been considerable research on the development of stance detection models, datasets, and application, we highlight important gaps pertaining to (i) a lack of theoretical conceptualization of stance, and (ii) the treatment of stance at an individual- or user- level, as opposed to message-level. In this paper, we first review the interdisciplinary origins of stance as an individual-level construct to highlight relevant attributes (e.g., psychological features) that might be useful to incorporate in stance detection models. Further, we argue that recent pre-trained and large language models (LLMs) might offer a way to flexibly infer such user-level attributes and/or incorporate them in modelling stance. To better illustrate this, we briefly review and synthesize the emerging corpus of studies on using LLMs for inferring stance, and specifically on incorporating user attributes in such tasks. We conclude by proposing a four-point agenda for pursuing stance detection research that is theoretically informed, inclusive, and practically impactful."
}