{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Prior selection for the precision parameter of Dirichlet Process Mixtures"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Dirichlet process mixture models",
    "Jeffreys' prior",
    "Sample-size-independent priors"
  ],
  "results": [
    "Jeffreys' prior for DPM",
    "Sample-size-independent priors for \u03b1",
    "Comparison of SSD and SSI priors"
  ],
  "title": "Prior Selection for the Precision Parameter of Dirichlet Process Mixtures.pdf",
  "abstract": "Consider a Dirichlet process mixture model (DPM) with random precision parameter \u03b1, inducing Kn clusters over n observations through its latent random partition. Our goal is to specify the prior distribution p (\u03b1 | \u03b7), including its fixed parameter vector \u03b7, in a way that is meaningful. Existing approaches can be broadly categorised into three groups. Those in the first group rely on the linkage between p (\u03b1 | \u03b7) and p (Kn) to draw conclusions on how to best choose \u03b7 to reflect one\u2019s prior knowledge of Kn; we call them sample-size-dependent. Those in the second and third group consist instead of using quasi-degenerate or improper priors, respectively. In this article, we show how all three methods have limitations, especially for large n. We enrich the first group by working out and testing Jeffreys\u2019 prior in the context of the DPM framework, and by evaluating its behaviour. Then we propose an alterna- tive methodology which does not depend on Kn or on the size of the available sample, but rather on the relationship between the largest stick lengths in the stick-breaking construction of the DPM; and which reflects those prior beliefs in p (\u03b1 | \u03b7). We con- clude with an example where existing sample-size-dependent approaches fail, while our sample-size-independent approach continues to be feasible. Keywords: bayesian nonparametrics, Dirichlet process, precision parameter 1. Introduction Typical usages of the Dirichlet process mixture model (DPM) are density and cluster estimation; the former is motivated by the flexibility of the DPM, and the latter by the latent random partition that the model induces on the observed data. In both cases, the precision parameter \u03b1 of the DPM is of great significance, since it influences the \u2217Corresponding author Email addresses: carlo.vicentini@mathstat.net (C. Vicentini), i.h.jermyn@durham.ac.uk (I. H. Jermyn) 1Present address: HSBC Group, London, UK. The views expressed herein are of the author alone and do not necessarily reflect those of HSBC. This research is unconnected to HSBC. Preprint submitted to Elsevier February 4, 2025 arXiv:2502.00864v1 [stat.ME] 2 Feb 2025"
}