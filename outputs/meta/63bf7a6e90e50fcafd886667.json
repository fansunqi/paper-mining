{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Image classification",
    "Model transferability"
  ],
  "datasets": [
    "ImageNet",
    "Camera traps",
    "Satellites",
    "Web-scraped benchmarks"
  ],
  "methods": [
    "Pre-trained models"
  ],
  "results": [
    "No consistent performance improvement with higher ImageNet accuracy",
    "Data augmentation improves performance"
  ],
  "paper_id": "63bf7a6e90e50fcafd886667",
  "title": "Does progress on ImageNet transfer to real-world datasets?",
  "abstract": "  Does progress on ImageNet transfer to real-world datasets? We investigate this question by evaluating ImageNet pre-trained models with varying accuracy (57% - 83%) on six practical image classification datasets. In particular, we study datasets collected with the goal of solving real-world tasks (e.g., classifying images from camera traps or satellites), as opposed to web-scraped benchmarks collected for comparing models. On multiple datasets, models with higher ImageNet accuracy do not consistently yield performance improvements. For certain tasks, interventions such as data augmentation improve performance even when architectures do not. We hope that future benchmarks will include more diverse datasets to encourage a more comprehensive approach to improving learning algorithms. "
}