{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Explainability in machine learning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Causal inference"
  ],
  "results": [
    "Odd pattern in Y's relative direct influence on E",
    "Higher influence in lowest-performing models than mid-performing models, which then decreases in top-performing models"
  ],
  "paper_id": "639a906290e50fcafdefe324",
  "title": "On the Relationship Between Explanation and Prediction: A Causal View",
  "abstract": "  Explainability has become a central requirement for the development, deployment, and adoption of machine learning (ML) models and we are yet to understand what explanation methods can and cannot do. Several factors such as data, model prediction, hyperparameters used in training the model, and random initialization can all influence downstream explanations. While previous work empirically hinted that explanations (E) may have little relationship with the prediction (Y), there is a lack of conclusive study to quantify this relationship. Our work borrows tools from causal inference to systematically assay this relationship. More specifically, we measure the relationship between E and Y by measuring the treatment effect when intervening on their causal ancestors (hyperparameters) (inputs to generate saliency-based Es or Ys). We discover that Y's relative direct influence on E follows an odd pattern; the influence is higher in the lowest-performing models than in mid-performing models, and it then decreases in the top-performing models. We believe our work is a promising first step towards providing better guidance for practitioners who can make more informed decisions in utilizing these explanations by knowing what factors are at play and how they relate to their end task. "
}