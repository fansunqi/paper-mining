{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Strategic interactions in online economic applications",
    "Manipulation of learning agents"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Regret-minimizing learning agents",
    "Meta-game analysis",
    "Equilibria analysis"
  ],
  "results": [
    "Users have incentives to misreport parameters to their agents",
    "Strategic user behavior leads to different outcomes than standard analysis"
  ],
  "paper_id": "61b95d305244ab9dcbf15277",
  "title": "How and Why to Manipulate Your Own Agent: On the Incentives of Users of\n  Learning Agents",
  "abstract": "  The usage of automated learning agents is becoming increasingly prevalent in many online economic applications such as online auctions and automated trading. Motivated by such applications, this paper is dedicated to fundamental modeling and analysis of the strategic situations that the users of automated learning agents are facing. We consider strategic settings where several users engage in a repeated online interaction, assisted by regret-minimizing learning agents that repeatedly play a \"game\" on their behalf. We propose to view the outcomes of the agents' dynamics as inducing a \"meta-game\" between the users. Our main focus is on whether users can benefit in this meta-game from \"manipulating\" their own agents by misreporting their parameters to them. We define a general framework to model and analyze these strategic interactions between users of learning agents for general games and analyze the equilibria induced between the users in three classes of games. We show that, generally, users have incentives to misreport their parameters to their own agents, and that such strategic user behavior can lead to very different outcomes than those anticipated by standard analysis. "
}