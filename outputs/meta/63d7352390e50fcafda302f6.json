{
  "code_links": [
    "None"
  ],
  "tasks": [
    "3D Reconstruction"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Tiny-NeRF",
    "volume representations (voxel maps, point clouds, triangular meshes)"
  ],
  "results": [
    "Tiny-NeRF requires three times less memory space",
    "Tiny-NeRF takes about six times more to compute the model"
  ],
  "paper_id": "63d7352390e50fcafda302f6",
  "title": "A Comparison of Tiny-nerf versus Spatial Representations for 3d\n  Reconstruction",
  "abstract": "  Neural rendering has emerged as a powerful paradigm for synthesizing images, offering many benefits over classical rendering by using neural networks to reconstruct surfaces, represent shapes, and synthesize novel views, either for objects or scenes. In this neural rendering, the environment is encoded into a neural network. We believe that these new representations can be used to codify the scene for a mobile robot. Therefore, in this work, we perform a comparison between a trending neural rendering, called tiny-NeRF, and other volume representations that are commonly used as maps in robotics, such as voxel maps, point clouds, and triangular meshes. The target is to know the advantages and disadvantages of neural representations in the robotics context. The comparison is made in terms of spatial complexity and processing time to obtain a model. Experiments show that tiny-NeRF requires three times less memory space compared to other representations. In terms of processing time, tiny-NeRF takes about six times more to compute the model. "
}