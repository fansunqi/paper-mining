{
  "code_links": [
    "https://youtu.be/yMh_NUNWxho"
  ],
  "tasks": [
    "Model-free continuous control for robot navigation",
    "Deep Reinforcement Learning in cluttered environments",
    "Temporal logic specifications for robot tasks"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Deep policy gradient algorithm",
    "Path planning-guided reward scheme",
    "Sampling-based methods",
    "LTL mission decomposition"
  ],
  "results": [
    "Significantly improved performance (effectiveness, efficiency)",
    "Enhanced exploration in large-scale cluttered environments"
  ],
  "paper_id": "61f753205aee126c0f9c2292",
  "title": "Overcoming Exploration: Deep Reinforcement Learning for Continuous\n  Control in Cluttered Environments from Temporal Logic Specifications",
  "abstract": "  Model-free continuous control for robot navigation tasks using Deep Reinforcement Learning (DRL) that relies on noisy policies for exploration is sensitive to the density of rewards. In practice, robots are usually deployed in cluttered environments, containing many obstacles and narrow passageways. Designing dense effective rewards is challenging, resulting in exploration issues during training. Such a problem becomes even more serious when tasks are described using temporal logic specifications. This work presents a deep policy gradient algorithm for controlling a robot with unknown dynamics operating in a cluttered environment when the task is specified as a Linear Temporal Logic (LTL) formula. To overcome the environmental challenge of exploration during training, we propose a novel path planning-guided reward scheme by integrating sampling-based methods to effectively complete goal-reaching missions. To facilitate LTL satisfaction, our approach decomposes the LTL mission into sub-goal-reaching tasks that are solved in a distributed manner. Our framework is shown to significantly improve performance (effectiveness, efficiency) and exploration of robots tasked with complex missions in large-scale cluttered environments. A video demonstration can be found on YouTube Channel: https://youtu.be/yMh_NUNWxho. "
}