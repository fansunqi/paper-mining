{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Automatic Chest X-ray Report Generation"
  ],
  "datasets": [
    "IU-Xray",
    "MIMIC-CXR"
  ],
  "methods": [
    "Contrastive Attention (CA) model. Compares current input image with normal images to distill contrastive information."
  ],
  "results": [
    "Boosts performance across most metrics",
    "State-of-the-art results on IU-Xray and MIMIC-CXR datasets"
  ],
  "paper_id": "60cab76191e011b329373f9f",
  "title": "Contrastive Attention for Automatic Chest X-ray Report Generation",
  "abstract": "  Recently, chest X-ray report generation, which aims to automatically generate descriptions of given chest X-ray images, has received growing research interests. The key challenge of chest X-ray report generation is to accurately capture and describe the abnormal regions. In most cases, the normal regions dominate the entire chest X-ray image, and the corresponding descriptions of these normal regions dominate the final report. Due to such data bias, learning-based models may fail to attend to abnormal regions. In this work, to effectively capture and describe abnormal regions, we propose the Contrastive Attention (CA) model. Instead of solely focusing on the current input image, the CA model compares the current input image with normal images to distill the contrastive information. The acquired contrastive information can better represent the visual features of abnormal regions. According to the experiments on the public IU-X-ray and MIMIC-CXR datasets, incorporating our CA into several existing models can boost their performance across most metrics. In addition, according to the analysis, the CA model can help existing models better attend to the abnormal regions and provide more accurate descriptions which are crucial for an interpretable diagnosis. Specifically, we achieve the state-of-the-art results on the two public datasets. "
}