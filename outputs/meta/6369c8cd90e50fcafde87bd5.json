{
  "code_links": [
    "https://github.com/JNAIC/PIPMN"
  ],
  "tasks": [
    "Audio classification"
  ],
  "datasets": [
    "UrbanSound8K",
    "GTAZN"
  ],
  "methods": [
    "Paired Inverse Pyramid Structure (PIP)",
    "Paired Inverse Pyramid Structure MLP Network (PIPMN)"
  ],
  "results": [
    "ESC accuracy: 96% on UrbanSound8K",
    "MGC accuracy: 93.2% on GTAZN",
    "1 million parameters"
  ],
  "paper_id": "6369c8cd90e50fcafde87bd5",
  "title": "Effective Audio Classification Network Based on Paired Inverse Pyramid\n  Structure and Dense MLP Block",
  "abstract": "  Recently, massive architectures based on Convolutional Neural Network (CNN) and self-attention mechanisms have become necessary for audio classification. While these techniques are state-of-the-art, these works' effectiveness can only be guaranteed with huge computational costs and parameters, large amounts of data augmentation, transfer from large datasets and some other tricks. By utilizing the lightweight nature of audio, we propose an efficient network structure called Paired Inverse Pyramid Structure (PIP) and a network called Paired Inverse Pyramid Structure MLP Network (PIPMN). The PIPMN reaches 96\\% of Environmental Sound Classification (ESC) accuracy on the UrbanSound8K dataset and 93.2\\% of Music Genre Classification (MGC) on the GTAZN dataset, with only 1 million parameters. Both of the results are achieved without data augmentation or model transfer. Public code is available at: https://github.com/JNAIC/PIPMN "
}