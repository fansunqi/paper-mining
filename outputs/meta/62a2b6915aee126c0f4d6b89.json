{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Signal processing inference",
    "Bayesian signal estimation"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Generative and discriminative learning"
  ],
  "results": [
    "None"
  ],
  "paper_id": "62a2b6915aee126c0f4d6b89",
  "title": "Discriminative and Generative Learning for Linear Estimation of Random\n  Signals [Lecture Notes]",
  "abstract": "  Inference tasks in signal processing are often characterized by the availability of reliable statistical modeling with some missing instance-specific parameters. One conventional approach uses data to estimate these missing parameters and then infers based on the estimated model. Alternatively, data can also be leveraged to directly learn the inference mapping end-to-end. These approaches for combining partially-known statistical models and data in inference are related to the notions of generative and discriminative models used in the machine learning literature, typically considered in the context of classifiers. The goal of this lecture note is to introduce the concepts of generative and discriminative learning for inference with a partially-known statistical model. While machine learning systems often lack the interpretability of traditional signal processing methods, we focus on a simple setting where one can interpret and compare the approaches in a tractable manner that is accessible and relevant to signal processing readers. In particular, we exemplify the approaches for the task of Bayesian signal estimation in a jointly Gaussian setting with the mean-squared error (MSE) objective, i.e., a linear estimation setting. "
}