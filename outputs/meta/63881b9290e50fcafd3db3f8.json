{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Microcontroller Deep Learning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Partial Execution Compiler (Pex)",
    "Structured Pruning",
    "Co-design of Network Architecture and Execution Schedule"
  ],
  "results": [
    "State-of-the-art performance in low SRAM usage regimes",
    "Up to +2.9% accuracy increase",
    "4x memory reduction with partial execution",
    "Up to 10.5x memory reduction with compiler-pruning co-design",
    "Up to +3.9% accuracy increase on Visual Wake Words with higher resolution inputs"
  ],
  "paper_id": "63881b9290e50fcafd3db3f8",
  "title": "Pex: Memory-efficient Microcontroller Deep Learning through Partial\n  Execution",
  "abstract": "  Embedded and IoT devices, largely powered by microcontroller units (MCUs), could be made more intelligent by leveraging on-device deep learning. One of the main challenges of neural network inference on an MCU is the extremely limited amount of read-write on-chip memory (SRAM, < 512 kB). SRAM is consumed by the neural network layer (operator) input and output buffers, which, traditionally, must be in memory (materialised) for an operator to execute. We discuss a novel execution paradigm for microcontroller deep learning, which modifies the execution of neural networks to avoid materialising full buffers in memory, drastically reducing SRAM usage with no computation overhead. This is achieved by exploiting the properties of operators, which can consume/produce a fraction of their input/output at a time. We describe a partial execution compiler, Pex, which produces memory-efficient execution schedules automatically by identifying subgraphs of operators whose execution can be split along the feature (\"channel\") dimension. Memory usage is reduced further by targeting memory bottlenecks with structured pruning, leading to the co-design of the network architecture and its execution schedule. Our evaluation of image and audio classification models: (a) establishes state-of-the-art performance in low SRAM usage regimes for considered tasks with up to +2.9% accuracy increase; (b) finds that a 4x memory reduction is possible by applying partial execution alone, or up to 10.5x when using the compiler-pruning co-design, while maintaining the classification accuracy compared to prior work; (c) uses the recovered SRAM to process higher resolution inputs instead, increasing accuracy by up to +3.9% on Visual Wake Words. "
}