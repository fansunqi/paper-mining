{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Complex reasoning"
  ],
  "datasets": [
    "GSM8K",
    "SVAMP",
    "AQuA",
    "StrategyQA",
    "ARC-challenge"
  ],
  "methods": [
    "Self-consistency decoding strategy",
    "Chain-of-thought prompting"
  ],
  "results": [
    "GSM8K: +17.9%",
    "SVAMP: +11.0%",
    "AQuA: +12.2%",
    "StrategyQA: +6.4%",
    "ARC-challenge: +3.9%"
  ],
  "paper_id": "62393e845aee126c0f1265e1",
  "title": "Self-Consistency Improves Chain of Thought Reasoning in Language Models",
  "abstract": "  Chain-of-thought prompting combined with pre-trained large language models has achieved encouraging results on complex reasoning tasks. In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting. It first samples a diverse set of reasoning paths instead of only taking the greedy one, and then selects the most consistent answer by marginalizing out the sampled reasoning paths. Self-consistency leverages the intuition that a complex reasoning problem typically admits multiple different ways of thinking leading to its unique correct answer. Our extensive empirical evaluation shows that self-consistency boosts the performance of chain-of-thought prompting with a striking margin on a range of popular arithmetic and commonsense reasoning benchmarks, including GSM8K (+17.9%), SVAMP (+11.0%), AQuA (+12.2%), StrategyQA (+6.4%) and ARC-challenge (+3.9%). "
}