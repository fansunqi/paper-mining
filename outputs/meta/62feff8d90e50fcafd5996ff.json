{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Interpretability",
    "Formal verification",
    "Logic gate conversion"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Convolutional Neural Network (CNN) architecture",
    "Learning Truth Table (LTT) blocks"
  ],
  "results": [
    "Comparable interpretability to decision trees",
    "Fast complete/sound formal verification",
    "Scalable logic gate representation"
  ],
  "paper_id": "62feff8d90e50fcafd5996ff",
  "title": "A Scalable, Interpretable, Verifiable & Differentiable Logic Gate\n  Convolutional Neural Network Architecture From Truth Tables",
  "abstract": "  We propose $\\mathcal{T}$ruth $\\mathcal{T}$able net ($\\mathcal{TT}$net), a novel Convolutional Neural Network (CNN) architecture that addresses, by design, the open challenges of interpretability, formal verification, and logic gate conversion. $\\mathcal{TT}$net is built using CNNs' filters that are equivalent to tractable truth tables and that we call Learning Truth Table (LTT) blocks. The dual form of LTT blocks allows the truth tables to be easily trained with gradient descent and makes these CNNs easy to interpret, verify and infer. Specifically, $\\mathcal{TT}$net is a deep CNN model that can be automatically represented, after post-training transformation, as a sum of Boolean decision trees, or as a sum of Disjunctive/Conjunctive Normal Form (DNF/CNF) formulas, or as a compact Boolean logic circuit. We demonstrate the effectiveness and scalability of $\\mathcal{TT}$net on multiple datasets, showing comparable interpretability to decision trees, fast complete/sound formal verification, and scalable logic gate representation, all compared to state-of-the-art methods. We believe this work represents a step towards making CNNs more transparent and trustworthy for real-world critical applications. "
}