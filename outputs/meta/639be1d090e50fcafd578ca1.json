{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Autonomous Lung Ultrasound Imaging",
    "Scan target localization"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Vision-based, data driven method",
    "Human pose estimation model",
    "Regression model",
    "Multiview stereo vision"
  ],
  "results": [
    "Accuracy level of 16.00(9.79) mm for probe positioning",
    "4.44(3.75) degree for probe orientation",
    "Success rate above 80% under an error threshold of 25mm"
  ],
  "paper_id": "639be1d090e50fcafd578ca1",
  "title": "Localizing Scan Targets from Human Pose for Autonomous Lung Ultrasound\n  Imaging",
  "abstract": "  Ultrasound is progressing toward becoming an affordable and versatile solution to medical imaging. With the advent of COVID-19 global pandemic, there is a need to fully automate ultrasound imaging as it requires trained operators in close proximity to patients for a long period of time, therefore increasing risk of infection. In this work, we investigate the important yet seldom-studied problem of scan target localization, under the setting of lung ultrasound imaging. We propose a purely vision-based, data driven method that incorporates learning-based computer vision techniques. We combine a human pose estimation model with a specially designed regression model to predict the lung ultrasound scan targets, and deploy multiview stereo vision to enhance the consistency of 3D target localization. While related works mostly focus on phantom experiments, we collect data from 30 human subjects for testing. Our method attains an accuracy level of 16.00(9.79) mm for probe positioning and 4.44(3.75) degree for probe orientation, with a success rate above 80% under an error threshold of 25mm for all scan targets. Moreover, our approach can serve as a general solution to other types of ultrasound modalities. The code for implementation has been released. "
}