{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Neural Network Quantization for Efficient Inference"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Survey of neural network quantization techniques"
  ],
  "results": [
    "Proposed future directions of research in neural network quantization"
  ],
  "paper_id": "61b80b6d5244ab9dcbf48e40",
  "title": "Neural Network Quantization for Efficient Inference: A Survey",
  "abstract": "  As neural networks have become more powerful, there has been a rising desire to deploy them in the real world; however, the power and accuracy of neural networks is largely due to their depth and complexity, making them difficult to deploy, especially in resource-constrained devices. Neural network quantization has recently arisen to meet this demand of reducing the size and complexity of neural networks by reducing the precision of a network. With smaller and simpler networks, it becomes possible to run neural networks within the constraints of their target hardware. This paper surveys the many neural network quantization techniques that have been developed in the last decade. Based on this survey and comparison of neural network quantization techniques, we propose future directions of research in the area. "
}