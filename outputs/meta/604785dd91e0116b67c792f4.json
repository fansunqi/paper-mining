{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Adversarial Network Traffic Crafting",
    "IoT Security"
  ],
  "datasets": [
    "real public available dataset"
  ],
  "methods": [
    "Sequence Generative Adversarial Networks (SeqGAN)",
    "Policy Gradient",
    "LSTM"
  ],
  "results": [
    "Generated adversarial samples can deceive many existing black-box NIDS"
  ],
  "paper_id": "604785dd91e0116b67c792f4",
  "title": "Packet-Level Adversarial Network Traffic Crafting using Sequence\n  Generative Adversarial Networks",
  "abstract": "  The surge in the internet of things (IoT) devices seriously threatens the current IoT security landscape, which requires a robust network intrusion detection system (NIDS). Despite superior detection accuracy, existing machine learning or deep learning based NIDS are vulnerable to adversarial examples. Recently, generative adversarial networks (GANs) have become a prevailing method in adversarial examples crafting. However, the nature of discrete network traffic at the packet level makes it hard for GAN to craft adversarial traffic as GAN is efficient in generating continuous data like image synthesis. Unlike previous methods that convert discrete network traffic into a grayscale image, this paper gains inspiration from SeqGAN in sequence generation with policy gradient. Based on the structure of SeqGAN, we propose Attack-GAN to generate adversarial network traffic at packet level that complies with domain constraints. Specifically, the adversarial packet generation is formulated into a sequential decision making process. In this case, each byte in a packet is regarded as a token in a sequence. The objective of the generator is to select a token to maximize its expected end reward. To bypass the detection of NIDS, the generated network traffic and benign traffic are classified by a black-box NIDS. The prediction results returned by the NIDS are fed into the discriminator to guide the update of the generator. We generate malicious adversarial traffic based on a real public available dataset with attack functionality unchanged. The experimental results validate that the generated adversarial samples are able to deceive many existing black-box NIDS. "
}