{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Counterfactual explanations"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Robust optimization",
    "Iterative method for calculating robust CEs"
  ],
  "results": [
    "Efficient generation of globally optimal robust CEs",
    "Valid even after slight feature perturbations"
  ],
  "paper_id": "63d340ef90e50fcafd9116a9",
  "title": "Finding Regions of Counterfactual Explanations via Robust Optimization",
  "abstract": "  Counterfactual explanations play an important role in detecting bias and improving the explainability of data-driven classification models. A counterfactual explanation (CE) is a minimal perturbed data point for which the decision of the model changes. Most of the existing methods can only provide one CE, which may not be achievable for the user. In this work we derive an iterative method to calculate robust CEs, i.e. CEs that remain valid even after the features are slightly perturbed. To this end, our method provides a whole region of CEs allowing the user to choose a suitable recourse to obtain a desired outcome. We use algorithmic ideas from robust optimization and prove convergence results for the most common machine learning methods including logistic regression, decision trees, random forests, and neural networks. Our experiments show that our method can efficiently generate globally optimal robust CEs for a variety of common data sets and classification models. "
}