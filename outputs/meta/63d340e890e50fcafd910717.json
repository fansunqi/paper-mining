{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Membership Inference of Diffusion Models"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "loss-based and likelihood-based attacks"
  ],
  "results": [
    "remarkable performance",
    "various factors affecting attack performance",
    "performance evaluation on diffusion models with differential privacy"
  ],
  "paper_id": "63d340e890e50fcafd910717",
  "title": "Membership Inference of Diffusion Models",
  "abstract": "  Recent years have witnessed the tremendous success of diffusion models in data synthesis. However, when diffusion models are applied to sensitive data, they also give rise to severe privacy concerns. In this paper, we systematically present the first study about membership inference attacks against diffusion models, which aims to infer whether a sample was used to train the model. Two attack methods are proposed, namely loss-based and likelihood-based attacks. Our attack methods are evaluated on several state-of-the-art diffusion models, over different datasets in relation to privacy-sensitive data. Extensive experimental evaluations show that our attacks can achieve remarkable performance. Furthermore, we exhaustively investigate various factors which can affect attack performance. Finally, we also evaluate the performance of our attack methods on diffusion models trained with differential privacy. "
}