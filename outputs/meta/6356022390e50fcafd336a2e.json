{
  "code_links": [
    "https://github.com/YukinoWan/kNN-RE"
  ],
  "tasks": [
    "Relation Extraction"
  ],
  "datasets": [
    "ACE05",
    "SciERC",
    "Wiki80",
    "i2b2",
    "Wiki80"
  ],
  "methods": [
    "k nearest neighbors ($k$NN-RE)"
  ],
  "results": [
    "State-of-the-art performances on various supervised RE datasets",
    "Outperforms the best model to date on i2b2 and Wiki80 datasets with DS"
  ],
  "paper_id": "6356022390e50fcafd336a2e",
  "title": "Rescue Implicit and Long-tail Cases: Nearest Neighbor Relation\n  Extraction",
  "abstract": "  Relation extraction (RE) has achieved remarkable progress with the help of pre-trained language models. However, existing RE models are usually incapable of handling two situations: implicit expressions and long-tail relation types, caused by language complexity and data sparsity. In this paper, we introduce a simple enhancement of RE using $k$ nearest neighbors ($k$NN-RE). $k$NN-RE allows the model to consult training relations at test time through a nearest-neighbor search and provides a simple yet effective means to tackle the two issues above. Additionally, we observe that $k$NN-RE serves as an effective way to leverage distant supervision (DS) data for RE. Experimental results show that the proposed $k$NN-RE achieves state-of-the-art performances on a variety of supervised RE datasets, i.e., ACE05, SciERC, and Wiki80, along with outperforming the best model to date on the i2b2 and Wiki80 datasets in the setting of allowing using DS. Our code and models are available at: https://github.com/YukinoWan/kNN-RE. "
}