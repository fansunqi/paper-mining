{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Scholarly Search"
  ],
  "datasets": [
    "ACL dataset"
  ],
  "methods": [
    "BERT-embedding",
    "Citation Network Analysis (CNA)",
    "Pseudo-Relevance Feedback (PRF)"
  ],
  "results": [
    "BERT-embedding provides valuable augmentation to query expansion",
    "Improves search relevance when combined with CNA"
  ],
  "paper_id": "63d340ef90e50fcafd91166c",
  "title": "BERT-Embedding and Citation Network Analysis based Query Expansion\n  Technique for Scholarly Search",
  "abstract": "  The enormous growth of research publications has made it challenging for academic search engines to bring the most relevant papers against the given search query. Numerous solutions have been proposed over the years to improve the effectiveness of academic search, including exploiting query expansion and citation analysis. Query expansion techniques mitigate the mismatch between the language used in a query and indexed documents. However, these techniques can suffer from introducing non-relevant information while expanding the original query. Recently, contextualized model BERT to document retrieval has been quite successful in query expansion. Motivated by such issues and inspired by the success of BERT, this paper proposes a novel approach called QeBERT. QeBERT exploits BERT-based embedding and Citation Network Analysis (CNA) in query expansion for improving scholarly search. Specifically, we use the context-aware BERT-embedding and CNA for query expansion in Pseudo-Relevance Feedback (PRF) fash-ion. Initial experimental results on the ACL dataset show that BERT-embedding can provide a valuable augmentation to query expansion and improve search relevance when combined with CNA. "
}