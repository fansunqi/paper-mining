{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Infrared and Visible Image Fusion"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Diffusion Models",
    "Denoising Network",
    "Multi-channel Gradient Loss",
    "Intensity Loss"
  ],
  "results": [
    "Improved color fidelity compared to state-of-the-art image fusion methods"
  ],
  "paper_id": "63ca069890e50fcafd68317a",
  "title": "Dif-Fusion: Towards High Color Fidelity in Infrared and Visible Image\n  Fusion with Diffusion Models",
  "abstract": "  Color plays an important role in human visual perception, reflecting the spectrum of objects. However, the existing infrared and visible image fusion methods rarely explore how to handle multi-spectral/channel data directly and achieve high color fidelity. This paper addresses the above issue by proposing a novel method with diffusion models, termed as Dif-Fusion, to generate the distribution of the multi-channel input data, which increases the ability of multi-source information aggregation and the fidelity of colors. In specific, instead of converting multi-channel images into single-channel data in existing fusion methods, we create the multi-channel data distribution with a denoising network in a latent space with forward and reverse diffusion process. Then, we use the the denoising network to extract the multi-channel diffusion features with both visible and infrared information. Finally, we feed the multi-channel diffusion features to the multi-channel fusion module to directly generate the three-channel fused image. To retain the texture and intensity information, we propose multi-channel gradient loss and intensity loss. Along with the current evaluation metrics for measuring texture and intensity fidelity, we introduce a new evaluation metric to quantify color fidelity. Extensive experiments indicate that our method is more effective than other state-of-the-art image fusion methods, especially in color fidelity. "
}