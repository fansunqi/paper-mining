{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Biological sample localization in 3D tomographic images"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Self-supervised losses for biological CT",
    "Uncertainty estimation for sample localization"
  ],
  "results": [
    "Less than 1.5% relative error in sample localization",
    "Reduce used storage by a factor of four",
    "One loss works well for pre-training semantic segmentation"
  ],
  "paper_id": "5fa9131591e011e83f74078a",
  "title": "Self-Supervised Learning for Biological Sample Localization in 3D\n  Tomographic Images",
  "abstract": "  In synchrotron-based Computed Tomography (CT) there is a trade-off between spatial resolution, field of view and speed of positioning and alignment of samples. The problem is even more prominent for high-throughput tomography--an automated setup, capable of scanning large batches of samples without human interaction. As a result, in many applications, only 20-30% of the reconstructed volume contains the actual sample. Such data redundancy clutters the storage and increases processing time. Hence, an automated sample localization becomes an important practical problem. In this work, we describe two self-supervised losses designed for biological CT. We further demonstrate how to employ the uncertainty estimation for sample localization. This approach shows the ability to localize a sample with less than 1.5\\% relative error and reduce the used storage by a factor of four. We also show that one of the proposed losses works reasonably well as a pre-training task for the semantic segmentation. "
}