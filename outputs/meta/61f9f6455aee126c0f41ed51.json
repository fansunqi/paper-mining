{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Compressed Video Quality Enhancement"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Deep learning architecture leveraging bitstream metadata",
    "Conditioning model on quantization data"
  ],
  "results": [
    "Improves restoration accuracy compared to prior methods",
    "Competitive with recent deep-learning-based video compression methods on rate-distortion",
    "Higher throughput",
    "Single model handles various compression quality settings"
  ],
  "paper_id": "61f9f6455aee126c0f41ed51",
  "title": "Leveraging Bitstream Metadata for Fast, Accurate, Generalized Compressed\n  Video Quality Enhancement",
  "abstract": "  Video compression is a central feature of the modern internet powering technologies from social media to video conferencing. While video compression continues to mature, for many compression settings, quality loss is still noticeable. These settings nevertheless have important applications to the efficient transmission of videos over bandwidth constrained or otherwise unstable connections. In this work, we develop a deep learning architecture capable of restoring detail to compressed videos which leverages the underlying structure and motion information embedded in the video bitstream. We show that this improves restoration accuracy compared to prior compression correction methods and is competitive when compared with recent deep-learning-based video compression methods on rate-distortion while achieving higher throughput. Furthermore, we condition our model on quantization data which is readily available in the bitstream. This allows our single model to handle a variety of different compression quality settings which required an ensemble of models in prior work. "
}