{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Neural Architecture Search"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Reinforcement Learning",
    "One-shot Training"
  ],
  "results": [
    "None"
  ],
  "paper_id": "63c8b59590e50fcafd90b637",
  "title": "DQNAS: Neural Architecture Search using Reinforcement Learning",
  "abstract": "  Convolutional Neural Networks have been used in a variety of image related applications after their rise in popularity due to ImageNet competition. Convolutional Neural Networks have shown remarkable results in applications including face recognition, moving target detection and tracking, classification of food based on the calorie content and many more. Designing of Convolutional Neural Networks requires experts having a cross domain knowledge and it is laborious, which requires a lot of time for testing different values for different hyperparameter along with the consideration of different configurations of existing architectures. Neural Architecture Search is an automated way of generating Neural Network architectures which saves researchers from all the brute-force testing trouble, but with the drawback of consuming a lot of computational resources for a prolonged period. In this paper, we propose an automated Neural Architecture Search framework DQNAS, guided by the principles of Reinforcement Learning along with One-shot Training which aims to generate neural network architectures that show superior performance and have minimum scalability problem. "
}