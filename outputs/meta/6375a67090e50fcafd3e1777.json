{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Chinese Sexism Detection in Social Media"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Cross-lingual domain-aware semantic specialisation",
    "Word embeddings specialisation"
  ],
  "results": [
    "Average score improvement of 0.033 in intrinsic evaluation",
    "Average score improvement of 0.064 in extrinsic evaluation"
  ],
  "paper_id": "6375a67090e50fcafd3e1777",
  "title": "SexWEs: Domain-Aware Word Embeddings via Cross-lingual Semantic\n  Specialisation for Chinese Sexism Detection in Social Media",
  "abstract": "  The goal of sexism detection is to mitigate negative online content targeting certain gender groups of people. However, the limited availability of labeled sexism-related datasets makes it problematic to identify online sexism for low-resource languages. In this paper, we address the task of automatic sexism detection in social media for one low-resource language -- Chinese. Rather than collecting new sexism data or building cross-lingual transfer learning models, we develop a cross-lingual domain-aware semantic specialisation system in order to make the most of existing data. Semantic specialisation is a technique for retrofitting pre-trained distributional word vectors by integrating external linguistic knowledge (such as lexico-semantic relations) into the specialised feature space. To do this, we leverage semantic resources for sexism from a high-resource language (English) to specialise pre-trained word vectors in the target language (Chinese) to inject domain knowledge. We demonstrate the benefit of our sexist word embeddings (SexWEs) specialised by our framework via intrinsic evaluation of word similarity and extrinsic evaluation of sexism detection. Compared with other specialisation approaches and Chinese baseline word vectors, our SexWEs shows an average score improvement of 0.033 and 0.064 in both intrinsic and extrinsic evaluations, respectively. The ablative results and visualisation of SexWEs also prove the effectiveness of our framework on retrofitting word vectors in low-resource languages. "
}