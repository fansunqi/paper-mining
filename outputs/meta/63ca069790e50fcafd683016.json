{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Parameter estimation from noisy signals",
    "Neural network interpretability"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Weight matrix SVD",
    "Descrambling transform"
  ],
  "results": [
    "SVD emerges as a means for networks to memorize the signal model",
    "Empirical evidence from linear and non-linear settings",
    "Connections between mathematical theory of semantic development and neural network interpretability"
  ],
  "paper_id": "63ca069790e50fcafd683016",
  "title": "Emergence of the SVD as an interpretable factorization in deep learning\n  for inverse problems",
  "abstract": "  We demonstrate the emergence of weight matrix singular value decomposition (SVD) in interpreting neural networks (NNs) for parameter estimation from noisy signals. The SVD appears naturally as a consequence of initial application of a descrambling transform - a recently-developed technique for addressing interpretability in NNs \\cite{amey2021neural}. We find that within the class of noisy parameter estimation problems, the SVD may be the means by which networks memorize the signal model. We substantiate our theoretical findings with empirical evidence from both linear and non-linear settings. Our results also illuminate the connections between a mathematical theory of semantic development \\cite{saxe2019mathematical} and neural network interpretability. "
}