{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Time series forecasting"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Deep autoregressive networks"
  ],
  "results": [
    "Intrinsically interpretable",
    "Comparable performance to state-of-the-art probabilistic time series forecasting methods"
  ],
  "paper_id": "63bb859d90e50fcafd06edfd",
  "title": "DANLIP: Deep Autoregressive Networks for Locally Interpretable\n  Probabilistic Forecasting",
  "abstract": "  Despite the high performance of neural network-based time series forecasting methods, the inherent challenge in explaining their predictions has limited their applicability in certain application areas. Due to the difficulty in identifying causal relationships between the input and output of such black-box methods, they rarely have been adopted in domains such as legal and medical fields in which the reliability and interpretability of the results can be essential. In this paper, we propose \\model, a novel deep learning-based probabilistic time series forecasting architecture that is intrinsically interpretable. We conduct experiments with multiple datasets and performance metrics and empirically show that our model is not only interpretable but also provides comparable performance to state-of-the-art probabilistic time series forecasting methods. Furthermore, we demonstrate that interpreting the parameters of the stochastic processes of interest can provide useful insights into several application areas. "
}