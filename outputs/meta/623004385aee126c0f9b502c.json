{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Study strategy complexity in countably infinite MDPs with real-valued transition rewards"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Analysis of point payoff, mean payoff, and total payoff objectives",
    "Determine necessary and sufficient memory for \u03b5-optimal and optimal strategies"
  ],
  "results": [
    "Complete picture of strategy complexity for different payoff types",
    "Some cases won with memoryless deterministic strategies, others require step counter, reward counter, or both"
  ],
  "paper_id": "623004385aee126c0f9b502c",
  "title": "Strategy Complexity of Point Payoff, Mean Payoff and Total Payoff\n  Objectives in Countable MDPs",
  "abstract": "  We study countably infinite Markov decision processes (MDPs) with real-valued transition rewards. Every infinite run induces the following sequences of payoffs: 1. Point payoff (the sequence of directly seen transition rewards), 2. Mean payoff (the sequence of the sums of all rewards so far, divided by the number of steps), and 3. Total payoff (the sequence of the sums of all rewards so far). For each payoff type, the objective is to maximize the probability that the $\\liminf$ is non-negative. We establish the complete picture of the strategy complexity of these objectives, i.e., how much memory is necessary and sufficient for $\\varepsilon$-optimal (resp. optimal) strategies. Some cases can be won with memoryless deterministic strategies, while others require a step counter, a reward counter, or both. "
}