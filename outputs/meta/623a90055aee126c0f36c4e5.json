{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Self-Supervised Learning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Representation Uncertainty Learning",
    "Variational Inference",
    "VI-SimSiam"
  ],
  "results": [
    "VI-SimSiam can learn representation uncertainty",
    "Relationship between estimated uncertainty and classification accuracy revealed"
  ],
  "paper_id": "623a90055aee126c0f36c4e5",
  "title": "Representation Uncertainty in Self-Supervised Learning as Variational\n  Inference",
  "abstract": "  In this paper, a novel self-supervised learning (SSL) method is proposed, which learns not only representations but also representations uncertainties by considering SSL in terms of variational inference. SSL is a method of learning representation without labels by maximizing the similarity between image representations of different augmented views of the same image. Variational autoencoder (VAE) is an unsupervised representation learning method that trains a probabilistic generative model with variational inference. VAE and SSL can learn representations without labels, but the relationship between VAE and SSL has not been revealed. In this paper, the theoretical relationship between SSL and variational inference is clarified. In addition, variational inference SimSiam (VI-SimSiam) is proposed, which can predict the representation uncertainty by interpreting SimSiam with variational inference and defining the latent space distribution. The experiment qualitatively showed that VISimSiam could learn uncertainty by comparing input images and predicted uncertainties. We also revealed a relationship between estimated uncertainty and classification accuracy. "
}