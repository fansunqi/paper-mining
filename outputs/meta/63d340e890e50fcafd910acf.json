{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Avoiding Malicious Explanations"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "STEALTH",
    "Recursive bi-clustering",
    "Limited queries"
  ],
  "results": [
    "None"
  ],
  "paper_id": "63d340e890e50fcafd910acf",
  "title": "Don't Lie to Me: Avoiding Malicious Explanations with STEALTH",
  "abstract": "  STEALTH is a method for using some AI-generated model, without suffering from malicious attacks (i.e. lying) or associated unfairness issues. After recursively bi-clustering the data, STEALTH system asks the AI model a limited number of queries about class labels. STEALTH asks so few queries (1 per data cluster) that malicious algorithms (a) cannot detect its operation, nor (b) know when to lie. "
}