{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Measuring uncertainty in human visual segmentation"
  ],
  "datasets": [
    "natural images",
    "composite textures"
  ],
  "methods": [
    "multiple pixel-based same--different judgments",
    "model--based reconstruction"
  ],
  "results": [
    "robust to several experimental manipulations",
    "captures the variability of individual participants",
    "image uncertainty affects measured human variability",
    "influences how participants weigh different visual features"
  ],
  "paper_id": "63ca069790e50fcafd682fff",
  "title": "Measuring uncertainty in human visual segmentation",
  "abstract": "  Segmenting visual stimuli into distinct groups of features and visual objects is central to visual function. Classical psychophysical methods have helped uncover many rules of human perceptual segmentation, and recent progress in machine learning has produced successful algorithms. Yet, the computational logic of human segmentation remains unclear, partially because we lack well-controlled paradigms to measure perceptual segmentation maps and compare models quantitatively. Here we propose a new, integrated approach: given an image, we measure multiple pixel-based same--different judgments and perform model--based reconstruction of the underlying segmentation map. The reconstruction is robust to several experimental manipulations and captures the variability of individual participants. We demonstrate the validity of the approach on human segmentation of natural images and composite textures. We show that image uncertainty affects measured human variability, and it influences how participants weigh different visual features. Because any putative segmentation algorithm can be inserted to perform the reconstruction, our paradigm affords quantitative tests of theories of perception as well as new benchmarks for segmentation algorithms. "
}