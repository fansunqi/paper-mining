{
  "code_links": [
    "None"
  ],
  "tasks": [
    "multi-label text classification"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Label Mask multi-label text classification model (LM-MTC)",
    "pre-train language models",
    "label based Masked Language Model (MLM)"
  ],
  "results": [
    "demonstrate the effectiveness of our method"
  ],
  "paper_id": "60d14c7491e011c16f0cb409",
  "title": "Label prompt for multi-label text classification",
  "abstract": "  One of the key problems in multi-label text classification is how to take advantage of the correlation among labels. However, it is very challenging to directly model the correlations among labels in a complex and unknown label space. In this paper, we propose a Label Mask multi-label text classification model (LM-MTC), which is inspired by the idea of cloze questions of language model. LM-MTC is able to capture implicit relationships among labels through the powerful ability of pre-train language models. On the basis, we assign a different token to each potential label, and randomly mask the token with a certain probability to build a label based Masked Language Model (MLM). We train the MTC and MLM together, further improving the generalization ability of the model. A large number of experiments on multiple datasets demonstrate the effectiveness of our method. "
}