{
  "code_links": [
    "None"
  ],
  "tasks": [
    "College student-success prediction",
    "Detecting and mitigating algorithmic bias"
  ],
  "datasets": [
    "Education Longitudinal Study of 2002"
  ],
  "methods": [
    "Machine-learning modeling approaches",
    "Bias-mitigating techniques"
  ],
  "results": [
    "Racially biased results produced by models incorporating commonly used features"
  ],
  "paper_id": "63be28d490e50fcafdf52bf9",
  "title": "Inside the Black Box: Detecting and Mitigating Algorithmic Bias across\n  Racialized Groups in College Student-Success Prediction",
  "abstract": "  Colleges and universities are increasingly turning to algorithms that predict college-student success to inform various decisions, including those related to admissions, budgeting, and student-success interventions. Because predictive algorithms rely on historical data, they capture societal injustices, including racism. A model that includes racial categories may predict that racially minoritized students will have less favorable outcomes. In this study, we explore bias in education data by modeling bachelor's degree attainment using various machine-learning modeling approaches. We also evaluate the utility of leading bias-mitigating techniques in addressing unfairness. Using nationally representative data from the Education Longitudinal Study of 2002, we demonstrate how models incorporating commonly used features to predict college-student success produce racially biased results. "
}