{
  "code_links": [
    "https://github.com/llmir/YoloCurvSeg"
  ],
  "tasks": [
    "Vessel-style Curvilinear Structure Segmentation"
  ],
  "datasets": [
    "OCTA500",
    "CORN",
    "DRIVE",
    "CHASEDB1"
  ],
  "methods": [
    "YoloCurvSeg",
    "background generator",
    "Space Colonization Algorithm",
    "multilayer patch-wise contrastive learning synthesizer"
  ],
  "results": [
    "outperforms state-of-the-art WSL segmentation methods",
    "more than 97% of the fully-supervised performance with only one noisy skeleton annotation"
  ],
  "paper_id": "6397ed4e90e50fcafdf43d8b",
  "title": "YoloCurvSeg: You Only Label One Noisy Skeleton for Vessel-style\n  Curvilinear Structure Segmentation",
  "abstract": "  Weakly-supervised learning (WSL) has been proposed to alleviate the conflict between data annotation cost and model performance through employing sparsely-grained (i.e., point-, box-, scribble-wise) supervision and has shown promising performance, particularly in the image segmentation field. However, it is still a very challenging task due to the limited supervision, especially when only a small number of labeled samples are available. Additionally, almost all existing WSL segmentation methods are designed for star-convex structures which are very different from curvilinear structures such as vessels and nerves. In this paper, we propose a novel sparsely annotated segmentation framework for curvilinear structures, named YoloCurvSeg. A very essential component of YoloCurvSeg is image synthesis. Specifically, a background generator delivers image backgrounds that closely match the real distributions through inpainting dilated skeletons. The extracted backgrounds are then combined with randomly emulated curves generated by a Space Colonization Algorithm-based foreground generator and through a multilayer patch-wise contrastive learning synthesizer. In this way, a synthetic dataset with both images and curve segmentation labels is obtained, at the cost of only one or a few noisy skeleton annotations. Finally, a segmenter is trained with the generated dataset and possibly an unlabeled dataset. The proposed YoloCurvSeg is evaluated on four publicly available datasets (OCTA500, CORN, DRIVE and CHASEDB1) and the results show that YoloCurvSeg outperforms state-of-the-art WSL segmentation methods by large margins. With only one noisy skeleton annotation (respectively 0.14%, 0.03%, 1.40%, and 0.65% of the full annotation), YoloCurvSeg achieves more than 97% of the fully-supervised performance on each dataset. Code and datasets will be released at https://github.com/llmir/YoloCurvSeg. "
}