{
  "code_links": [
    "https://github.com/data-and-decision-lab/self-improving-RL"
  ],
  "tasks": [
    "Autonomous driving safety performance improvement"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Black-box verification methods",
    "Transfer learning"
  ],
  "results": [
    "Reduces the number of vehicle collisions"
  ],
  "paper_id": "63608e5090e50fcafdee10e8",
  "title": "Self-Improving Safety Performance of Reinforcement Learning Based\n  Driving with Black-Box Verification Algorithms",
  "abstract": "  In this work, we propose a self-improving artificial intelligence system to enhance the safety performance of reinforcement learning (RL)-based autonomous driving (AD) agents using black-box verification methods. RL algorithms have become popular in AD applications in recent years. However, the performance of existing RL algorithms heavily depends on the diversity of training scenarios. A lack of safety-critical scenarios during the training phase could result in poor generalization performance in real-world driving applications. We propose a novel framework in which the weaknesses of the training set are explored through black-box verification methods. After discovering AD failure scenarios, the RL agent's training is re-initiated via transfer learning to improve the performance of previously unsafe scenarios. Simulation results demonstrate that our approach efficiently discovers safety failures of action decisions in RL-based adaptive cruise control (ACC) applications and significantly reduces the number of vehicle collisions through iterative applications of our method. The source code is publicly available at https://github.com/data-and-decision-lab/self-improving-RL. "
}