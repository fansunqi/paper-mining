{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Image Classification Performance Improvement"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Amicable Aid",
    "Perturbing Images",
    "Training with Modified Data"
  ],
  "results": [
    "Higher classification confidence",
    "Correct classification of misclassified images",
    "Effective universal amicable perturbations"
  ],
  "paper_id": "61b2c57b5244ab9dcb1d7202",
  "title": "Amicable Aid: Perturbing Images to Improve Classification Performance",
  "abstract": "  While adversarial perturbation of images to attack deep image classification models pose serious security concerns in practice, this paper suggests a novel paradigm where the concept of image perturbation can benefit classification performance, which we call amicable aid. We show that by taking the opposite search direction of perturbation, an image can be modified to yield higher classification confidence and even a misclassified image can be made correctly classified. This can be also achieved with a large amount of perturbation by which the image is made unrecognizable by human eyes. The mechanism of the amicable aid is explained in the viewpoint of the underlying natural image manifold. Furthermore, we investigate the universal amicable aid, i.e., a fixed perturbation can be applied to multiple images to improve their classification results. While it is challenging to find such perturbations, we show that making the decision boundary as perpendicular to the image manifold as possible via training with modified data is effective to obtain a model for which universal amicable perturbations are more easily found. "
}