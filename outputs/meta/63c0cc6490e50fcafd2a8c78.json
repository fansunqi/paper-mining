{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Deep-learning-based image processing in space"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Hardware accelerators (TPUs, GPUs)"
  ],
  "results": [
    "Hardware accelerators (TPUs, GPUs) are necessary to reach the latency requirements",
    "State-of-the-art edge devices with GPUs could have a high power draw, making them unsuitable for deployment on a satellite"
  ],
  "paper_id": "63c0cc6490e50fcafd2a8c78",
  "title": "We are Going to the Space -- Part 1: Which device to deploy in a\n  satellite?",
  "abstract": "  The shrinkage in sizes of components that make up satellites led to wider and low cost availability of satellites. As a result, there has been an advent of smaller organizations having the ability to deploy satellites with a variety of data-intensive applications to run on them. One popular application is image analysis to detect, for example, land, ice, clouds, etc. However, the resource-constrained nature of the devices deployed in satellites creates additional challenges for this resource-intensive application.   In this paper, we investigate the performance of a variety of edge devices for deep-learning-based image processing in space. Our goal is to determine the devices that satisfy the latency and power constraints of satellites while achieving reasonably accurate results. Our results demonstrate that hardware accelerators (TPUs, GPUs) are necessary to reach the latency requirements. On the other hand, state-of-the-art edge devices with GPUs could have a high power draw, making them unsuitable for deployment on a satellite. "
}