{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Mean Field Games with non-separable Hamiltonians"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Deep Galerkin Methods (DGMs)",
    "Neural networks for approximating solutions"
  ],
  "results": [
    "Efficient with up to 300 dimensions",
    "Faster than other approaches",
    "Convergence of neural network approximation proven"
  ],
  "paper_id": "63bcd73090e50fcafdef993f",
  "title": "Deep Learning for Mean Field Games with non-separable Hamiltonians",
  "abstract": "  This paper introduces a new method based on Deep Galerkin Methods (DGMs) for solving high-dimensional stochastic Mean Field Games (MFGs). We achieve this by using two neural networks to approximate the unknown solutions of the MFG system and forward-backward conditions. Our method is efficient, even with a small number of iterations, and is capable of handling up to 300 dimensions with a single layer, which makes it faster than other approaches. In contrast, methods based on Generative Adversarial Networks (GANs) cannot solve MFGs with non-separable Hamiltonians. We demonstrate the effectiveness of our approach by applying it to a traffic flow problem, which was previously solved using the Newton iteration method only in the deterministic case. We compare the results of our method to analytical solutions and previous approaches, showing its efficiency. We also prove the convergence of our neural network approximation with a single hidden layer using the universal approximation theorem. "
}