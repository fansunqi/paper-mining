{
  "code_links": [
    "https://github.com/marksgraham/ddpm-ood"
  ],
  "tasks": [
    "Out-of-distribution detection"
  ],
  "datasets": [
    "standard computer-vision datasets",
    "higher dimension medical datasets"
  ],
  "methods": [
    "Denoising diffusion probabilistic models (DDPMs)"
  ],
  "results": [
    "outperforms reconstruction-based methods",
    "outperforms state-of-the-art generative-based approaches"
  ],
  "paper_id": "637454d590e50fcafdfc6174",
  "title": "Denoising diffusion models for out-of-distribution detection",
  "abstract": "  Out-of-distribution detection is crucial to the safe deployment of machine learning systems. Currently, unsupervised out-of-distribution detection is dominated by generative-based approaches that make use of estimates of the likelihood or other measurements from a generative model. Reconstruction-based methods offer an alternative approach, in which a measure of reconstruction error is used to determine if a sample is out-of-distribution. However, reconstruction-based approaches are less favoured, as they require careful tuning of the model's information bottleneck - such as the size of the latent dimension - to produce good results. In this work, we exploit the view of denoising diffusion probabilistic models (DDPM) as denoising autoencoders where the bottleneck is controlled externally, by means of the amount of noise applied. We propose to use DDPMs to reconstruct an input that has been noised to a range of noise levels, and use the resulting multi-dimensional reconstruction error to classify out-of-distribution inputs. We validate our approach both on standard computer-vision datasets and on higher dimension medical datasets. Our approach outperforms not only reconstruction-based methods, but also state-of-the-art generative-based approaches. Code is available at https://github.com/marksgraham/ddpm-ood. "
}