{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Poster generation"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Visual-textual model",
    "Cascaded auto-encoders",
    "Matching-based method",
    "Weakly- and self-supervised learning"
  ],
  "results": [
    "Outperforms state-of-the-art methods",
    "Improved quality of generated posters"
  ],
  "paper_id": "63bb859d90e50fcafd06ee91",
  "title": "Text2Poster: Laying out Stylized Texts on Retrieved Images",
  "abstract": "  Poster generation is a significant task for a wide range of applications, which is often time-consuming and requires lots of manual editing and artistic experience. In this paper, we propose a novel data-driven framework, called \\textit{Text2Poster}, to automatically generate visually-effective posters from textual information. Imitating the process of manual poster editing, our framework leverages a large-scale pretrained visual-textual model to retrieve background images from given texts, lays out the texts on the images iteratively by cascaded auto-encoders, and finally, stylizes the texts by a matching-based method. We learn the modules of the framework by weakly- and self-supervised learning strategies, mitigating the demand for labeled data. Both objective and subjective experiments demonstrate that our Text2Poster outperforms state-of-the-art methods, including academic research and commercial software, on the quality of generated posters. "
}