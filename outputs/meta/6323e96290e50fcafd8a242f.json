{
  "code_links": [
    "https://github.com/vincentqqb/PriorLane"
  ],
  "tasks": [
    "Lane detection"
  ],
  "datasets": [
    "Zjlab"
  ],
  "methods": [
    "Transformer",
    "PriorLane",
    "Knowledge Embedding Alignment (KEA) module"
  ],
  "results": [
    "2.82% mIoU improvement over SOTA lane detection methods"
  ],
  "paper_id": "6323e96290e50fcafd8a242f",
  "title": "PriorLane: A Prior Knowledge Enhanced Lane Detection Approach Based on\n  Transformer",
  "abstract": "  Lane detection is one of the fundamental modules in self-driving. In this paper we employ a transformer-only method for lane detection, thus it could benefit from the blooming development of fully vision transformer and achieve the state-of-the-art (SOTA) performance on both CULane and TuSimple benchmarks, by fine-tuning the weight fully pre-trained on large datasets. More importantly, this paper proposes a novel and general framework called PriorLane, which is used to enhance the segmentation performance of the fully vision transformer by introducing the low-cost local prior knowledge. Specifically, PriorLane utilizes an encoder-only transformer to fuse the feature extracted by a pre-trained segmentation model with prior knowledge embeddings. Note that a Knowledge Embedding Alignment (KEA) module is adapted to enhance the fusion performance by aligning the knowledge embedding. Extensive experiments on our Zjlab dataset show that PriorLane outperforms SOTA lane detection methods by a 2.82% mIoU when prior knowledge is employed, and the code will be released at: https://github.com/vincentqqb/PriorLane. "
}