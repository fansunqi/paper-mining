{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Uncertainty Quantification for Deep Classifiers"
  ],
  "datasets": [
    "CIFAR10",
    "CIFAR100",
    "Tiny ImageNet"
  ],
  "methods": [
    "UQGAN",
    "Conditional GAN",
    "One-vs-all Image Classifier"
  ],
  "results": [
    "Improves OoD detection and FP detection over state-of-the-art GAN-training based classifiers",
    "No significant effect on calibration error",
    "Significant gain in model accuracy"
  ],
  "paper_id": "61f8a4c45aee126c0fee06a6",
  "title": "UQGAN: A Unified Model for Uncertainty Quantification of Deep\n  Classifiers trained via Conditional GANs",
  "abstract": "  We present an approach to quantifying both aleatoric and epistemic uncertainty for deep neural networks in image classification, based on generative adversarial networks (GANs). While most works in the literature that use GANs to generate out-of-distribution (OoD) examples only focus on the evaluation of OoD detection, we present a GAN based approach to learn a classifier that produces proper uncertainties for OoD examples as well as for false positives (FPs). Instead of shielding the entire in-distribution data with GAN generated OoD examples which is state-of-the-art, we shield each class separately with out-of-class examples generated by a conditional GAN and complement this with a one-vs-all image classifier. In our experiments, in particular on CIFAR10, CIFAR100 and Tiny ImageNet, we improve over the OoD detection and FP detection performance of state-of-the-art GAN-training based classifiers. Furthermore, we also find that the generated GAN examples do not significantly affect the calibration error of our classifier and result in a significant gain in model accuracy. "
}