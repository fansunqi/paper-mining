{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Speech Enhancement"
  ],
  "datasets": [
    "VoiceBank-DEMAND"
  ],
  "methods": [
    "Cold Diffusion"
  ],
  "results": [
    "Improved performance compared to discriminative models and diffusion-based enhancement models"
  ],
  "paper_id": "6368773190e50fcafd675049",
  "title": "Cold Diffusion for Speech Enhancement",
  "abstract": "  Diffusion models have recently shown promising results for difficult enhancement tasks such as the conditional and unconditional restoration of natural images and audio signals. In this work, we explore the possibility of leveraging a recently proposed advanced iterative diffusion model, namely cold diffusion, to recover clean speech signals from noisy signals. The unique mathematical properties of the sampling process from cold diffusion could be utilized to restore high-quality samples from arbitrary degradations. Based on these properties, we propose an improved training algorithm and objective to help the model generalize better during the sampling process. We verify our proposed framework by investigating two model architectures. Experimental results on benchmark speech enhancement dataset VoiceBank-DEMAND demonstrate the strong performance of the proposed approach compared to representative discriminative models and diffusion-based enhancement models. "
}