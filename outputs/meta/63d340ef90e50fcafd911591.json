{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Facial Emotion Recognition"
  ],
  "datasets": [
    "AffectNet"
  ],
  "methods": [
    "Swin Vision Transformers (SwinT)",
    "squeeze and excitation block (SE)",
    "SAM"
  ],
  "results": [
    "F1-score: 0.5420"
  ],
  "paper_id": "63d340ef90e50fcafd911591",
  "title": "Facial Expression Recognition using Squeeze and Excitation-powered Swin\n  Transformers",
  "abstract": "  The recognition of facial emotions is an essential aspect of human communication, allowing individuals to understand emotions conveyed by facial expressions and vocal tones. The field of Facial Emotion Recognition (FER) is of great significance in the areas of computer vision and artificial intelligence, with vast commercial and academic potential in fields such as security, advertising, and entertainment. We propose a FER framework that employs Swin Vision Transformers (SwinT) and squeeze and excitation block (SE) to address vision tasks. The approach uses a transformer model with an attention mechanism, SE, and SAM to improve the efficiency of the model, as transformers often require a large amount of data. Our focus was to create an efficient FER model based on SwinT architecture that can recognize facial emotions using minimal data. We trained our model on a hybrid dataset and evaluated its performance on the AffectNet dataset, achieving an F1-score of 0.5420, which surpassed the winner of the Affective Behavior Analysis in the Wild (ABAW) Competition held at the European Conference on Computer Vision (ECCV) 2022 "
}