{
  "code_links": [
    "https://github.com/mingsun-tse/why-the-state-of-pruning-so-confusing"
  ],
  "tasks": [
    "Neural Network Pruning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Fairness in pruning experiments",
    "Comparison setups",
    "Network trainability"
  ],
  "results": [
    "Clarification of fairness principles",
    "Unveiling pruning mysteries",
    "Suggestions for pruning benchmark calibration"
  ],
  "paper_id": "63c0cc6490e50fcafd2a8e9d",
  "title": "Why is the State of Neural Network Pruning so Confusing? On the\n  Fairness, Comparison Setup, and Trainability in Network Pruning",
  "abstract": "  The state of neural network pruning has been noticed to be unclear and even confusing for a while, largely due to \"a lack of standardized benchmarks and metrics\" [3]. To standardize benchmarks, first, we need to answer: what kind of comparison setup is considered fair? This basic yet crucial question has barely been clarified in the community, unfortunately. Meanwhile, we observe several papers have used (severely) sub-optimal hyper-parameters in pruning experiments, while the reason behind them is also elusive. These sub-optimal hyper-parameters further exacerbate the distorted benchmarks, rendering the state of neural network pruning even more obscure.   Two mysteries in pruning represent such a confusing status: the performance-boosting effect of a larger finetuning learning rate, and the no-value argument of inheriting pretrained weights in filter pruning.   In this work, we attempt to explain the confusing state of network pruning by demystifying the two mysteries. Specifically, (1) we first clarify the fairness principle in pruning experiments and summarize the widely-used comparison setups; (2) then we unveil the two pruning mysteries and point out the central role of network trainability, which has not been well recognized so far; (3) finally, we conclude the paper and give some concrete suggestions regarding how to calibrate the pruning benchmarks in the future. Code: https://github.com/mingsun-tse/why-the-state-of-pruning-so-confusing. "
}