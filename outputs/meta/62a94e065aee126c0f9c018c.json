{
  "code_links": [
    "https://github.com/Vegetebird/GraphMLP"
  ],
  "tasks": [
    "3D Human Pose Estimation"
  ],
  "datasets": [
    "Human3.6M",
    "MPI-INF-3DHP"
  ],
  "methods": [
    "GraphMLP: A graph-reinforced MLP-Like architecture combining MLPs and GCNs"
  ],
  "results": [
    "State-of-the-art performance on Human3.6M and MPI-INF-3DHP"
  ],
  "paper_id": "62a94e065aee126c0f9c018c",
  "title": "GraphMLP: A Graph MLP-Like Architecture for 3D Human Pose Estimation",
  "abstract": "  Modern multi-layer perceptron (MLP) models have shown competitive results in learning visual representations without self-attention. However, existing MLP models are not good at capturing local details and lack prior knowledge of human body configurations, which limits their modeling power for skeletal representation learning. To address these issues, we propose a simple yet effective graph-reinforced MLP-Like architecture, named GraphMLP, that combines MLPs and graph convolutional networks (GCNs) in a global-local-graphical unified architecture for 3D human pose estimation. GraphMLP incorporates the graph structure of human bodies into an MLP model to meet the domain-specific demand of the 3D human pose, while allowing for both local and global spatial interactions. Furthermore, we propose to flexibly and efficiently extend the GraphMLP to the video domain and show that complex temporal dynamics can be effectively modeled in a simple way with negligible computational cost gains in the sequence length. To the best of our knowledge, this is the first MLP-Like architecture for 3D human pose estimation in a single frame and a video sequence. Extensive experiments show that the proposed GraphMLP achieves state-of-the-art performance on two datasets, i.e., Human3.6M and MPI-INF-3DHP. Code and models are available at https://github.com/Vegetebird/GraphMLP. "
}