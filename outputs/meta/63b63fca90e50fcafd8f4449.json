{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Simulating A Quadruped Robot",
    "Emotion detection and understanding",
    "Gait generation",
    "Audio-visual feedback response"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Reinforcement learning",
    "Software engineering",
    "PPO algorithm"
  ],
  "results": [
    "Emotion detection from speech: 63.5% accuracy",
    "Video emotion detection: 99.66% accuracy",
    "Seamless gait across different cadences and variations"
  ],
  "paper_id": "63b63fca90e50fcafd8f4449",
  "title": "e-Inu: Simulating A Quadruped Robot With Emotional Sentience",
  "abstract": "  Quadruped robots are currently used in industrial robotics as mechanical aid to automate several routine tasks. However, presently, the usage of such a robot in a domestic setting is still very much a part of the research. This paper discusses the understanding and virtual simulation of such a robot capable of detecting and understanding human emotions, generating its gait, and responding via sounds and expression on a screen. To this end, we use a combination of reinforcement learning and software engineering concepts to simulate a quadruped robot that can understand emotions, navigate through various terrains and detect sound sources, and respond to emotions using audio-visual feedback. This paper aims to establish the framework of simulating a quadruped robot that is emotionally intelligent and can primarily respond to audio-visual stimuli using motor or audio response. The emotion detection from the speech was not as performant as ERANNs or Zeta Policy learning, still managing an accuracy of 63.5%. The video emotion detection system produced results that are almost at par with the state of the art, with an accuracy of 99.66%. Due to its \"on-policy\" learning process, the PPO algorithm was extremely rapid to learn, allowing the simulated dog to demonstrate a remarkably seamless gait across the different cadences and variations. This enabled the quadruped robot to respond to generated stimuli, allowing us to conclude that it functions as predicted and satisfies the aim of this work. "
}