{
  "code_links": [
    "https://github.com/CuriosAI/dac-dev"
  ],
  "tasks": [
    "Neural network optimization"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Multiple biases in neural network units"
  ],
  "results": [
    "Potential for significant enhancement in neural network model's performance"
  ],
  "paper_id": "63b63fca90e50fcafd8f43d7",
  "title": "Increasing biases can be more efficient than increasing weights",
  "abstract": "We introduce a novel computational unit for neural networks that features\nmultiple biases, challenging the traditional perceptron structure. This unit\nemphasizes the importance of preserving uncorrupted information as it is passed\nfrom one unit to the next, applying activation functions later in the process\nwith specialized biases for each unit. Through both empirical and theoretical\nanalyses, we show that by focusing on increasing biases rather than weights,\nthere is potential for significant enhancement in a neural network model's\nperformance. This approach offers an alternative perspective on optimizing\ninformation flow within neural networks. See source code at\nhttps://github.com/CuriosAI/dac-dev."
}