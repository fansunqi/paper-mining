{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Explainable Image Classification",
    "Automatic Class Relevant Concept Discovery"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "StyleGAN inversion",
    "Wasserstein-1 metric"
  ],
  "results": [
    "Top-1 accuracy on par with CNN classifiers and deep feature learning baselines",
    "Concept-based explanations",
    "Easy debugging at the concept level"
  ],
  "paper_id": "63c8b56b90e50fcafd905f1a",
  "title": "Img2Tab: Automatic Class Relevant Concept Discovery from StyleGAN\n  Features for Explainable Image Classification",
  "abstract": "  Traditional tabular classifiers provide explainable decision-making with interpretable features(concepts). However, using their explainability in vision tasks has been limited due to the pixel representation of images. In this paper, we design Img2Tabs that classify images by concepts to harness the explainability of tabular classifiers. Img2Tabs encode image pixels into tabular features by StyleGAN inversion. Since not all of the resulting features are class-relevant or interpretable due to their generative nature, we expect Img2Tab classifiers to discover class-relevant concepts automatically from the StyleGAN features. Thus, we propose a novel method using the Wasserstein-1 metric to quantify class-relevancy and interpretability simultaneously. Using this method, we investigate whether important features extracted by tabular classifiers are class-relevant concepts. Consequently, we determine the most effective classifier for Img2Tabs in terms of discovering class-relevant concepts automatically from StyleGAN features. In evaluations, we demonstrate concept-based explanations through importance and visualization. Img2Tab achieves top-1 accuracy that is on par with CNN classifiers and deep feature learning baselines. Additionally, we show that users can easily debug Img2Tab classifiers at the concept level to ensure unbiased and fair decision-making without sacrificing accuracy. "
}