{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Multi-agent efficient domain coverage"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Multi-Agent Proximal Policy Optimization Algorithm (MAPPO)",
    "LSTM",
    "self-attention"
  ],
  "results": [
    "Significantly outperforms the state-of-the-art classical control policy"
  ],
  "paper_id": "6371b1a090e50fcafdb2e398",
  "title": "Efficient Domain Coverage for Vehicles with Second-Order Dynamics via\n  Multi-Agent Reinforcement Learning",
  "abstract": "  Collaborative autonomous multi-agent systems covering a specified area have many potential applications, such as UAV search and rescue, forest fire fighting, and real-time high-resolution monitoring. Traditional approaches for such coverage problems involve designing a model-based control policy based on sensor data. However, designing model-based controllers is challenging, and the state-of-the-art classical control policy still exhibits a large degree of sub-optimality. In this paper, we present a reinforcement learning (RL) approach for the multi-agent efficient domain coverage problem involving agents with second-order dynamics. Our approach is based on the Multi-Agent Proximal Policy Optimization Algorithm (MAPPO). Our proposed network architecture includes the incorporation of LSTM and self-attention, which allows the trained policy to adapt to a variable number of agents. Our trained policy significantly outperforms the state-of-the-art classical control policy. We demonstrate our proposed method in a variety of simulated experiments. "
}