{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Neural Compression"
  ],
  "datasets": [
    "Images",
    "Climate Data",
    "3D Shapes and Scenes",
    "Audio",
    "Video"
  ],
  "methods": [
    "Modality-Agnostic Variational Compression",
    "Implicit Neural Representation (INR)"
  ],
  "results": [
    "Improved performance over a large set of diverse modalities",
    "Outperforms codecs like JPEG 2000, MP3, and AVC/HEVC"
  ],
  "paper_id": "63e1c14690e50fcafd2dcda9",
  "title": "Modality-Agnostic Variational Compression of Implicit Neural\n  Representations",
  "abstract": "  We introduce a modality-agnostic neural compression algorithm based on a functional view of data and parameterised as an Implicit Neural Representation (INR). Bridging the gap between latent coding and sparsity, we obtain compact latent representations non-linearly mapped to a soft gating mechanism. This allows the specialisation of a shared INR network to each data item through subnetwork selection. After obtaining a dataset of such latent representations, we directly optimise the rate/distortion trade-off in a modality-agnostic space using neural compression. Variational Compression of Implicit Neural Representations (VC-INR) shows improved performance given the same representational capacity pre quantisation while also outperforming previous quantisation schemes used for other INR techniques. Our experiments demonstrate strong results over a large set of diverse modalities using the same algorithm without any modality-specific inductive biases. We show results on images, climate data, 3D shapes and scenes as well as audio and video, introducing VC-INR as the first INR-based method to outperform codecs as well-known and diverse as JPEG 2000, MP3 and AVC/HEVC on their respective modalities. "
}