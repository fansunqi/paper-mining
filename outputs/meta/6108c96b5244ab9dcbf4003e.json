{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Human-Object Interaction Detection"
  ],
  "datasets": [
    "V-COCO",
    "HICO-DET"
  ],
  "methods": [
    "Guided Transformer Network (GTNet), Self-Attention"
  ],
  "results": [
    "State of the art results on V-COCO and HICO-DET"
  ],
  "paper_id": "6108c96b5244ab9dcbf4003e",
  "title": "GTNet:Guided Transformer Network for Detecting Human-Object Interactions",
  "abstract": "  The human-object interaction (HOI) detection task refers to localizing humans, localizing objects, and predicting the interactions between each human-object pair. HOI is considered one of the fundamental steps in truly understanding complex visual scenes. For detecting HOI, it is important to utilize relative spatial configurations and object semantics to find salient spatial regions of images that highlight the interactions between human object pairs. This issue is addressed by the novel self-attention based guided transformer network, GTNet. GTNet encodes this spatial contextual information in human and object visual features via self-attention while achieving state of the art results on both the V-COCO and HICO-DET datasets. Code will be made available online. "
}