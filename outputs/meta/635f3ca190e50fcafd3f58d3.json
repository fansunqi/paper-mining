{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Adversarial Perturbations Transferability"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Universal Adversarial Directions (UADs)",
    "Principal Component Analysis (PCA)"
  ],
  "results": [
    "Superior transferability of UADs over standard gradient-based UAPs"
  ],
  "paper_id": "635f3ca190e50fcafd3f58d3",
  "title": "Universal Adversarial Directions",
  "abstract": "  Despite their great success in image recognition tasks, deep neural networks (DNNs) have been observed to be susceptible to universal adversarial perturbations (UAPs) which perturb all input samples with a single perturbation vector. However, UAPs often struggle in transferring across DNN architectures and lead to challenging optimization problems. In this work, we study the transferability of UAPs by analyzing equilibrium in the universal adversarial example game between the classifier and UAP adversary players. We show that under mild assumptions the universal adversarial example game lacks a pure Nash equilibrium, indicating UAPs' suboptimal transferability across DNN classifiers. To address this issue, we propose Universal Adversarial Directions (UADs) which only fix a universal direction for adversarial perturbations and allow the perturbations' magnitude to be chosen freely across samples. We prove that the UAD adversarial example game can possess a Nash equilibrium with a pure UAD strategy, implying the potential transferability of UADs. We also connect the UAD optimization problem to the well-known principal component analysis (PCA) and develop an efficient PCA-based algorithm for optimizing UADs. We evaluate UADs over multiple benchmark image datasets. Our numerical results show the superior transferability of UADs over standard gradient-based UAPs. "
}