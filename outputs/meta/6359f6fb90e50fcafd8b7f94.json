{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Simulation-Based Inference"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Synthetic likelihood methods",
    "Conditional energy-based model (EBM)",
    "KL loss minimization"
  ],
  "results": [
    "Outperforms prior art for a fraction of the simulation budget"
  ],
  "paper_id": "6359f6fb90e50fcafd8b7f94",
  "title": "Maximum Likelihood Learning of Unnormalized Models for Simulation-Based\n  Inference",
  "abstract": "  We introduce two synthetic likelihood methods for Simulation-Based Inference (SBI), to conduct either amortized or targeted inference from experimental observations when a high-fidelity simulator is available. Both methods learn a conditional energy-based model (EBM) of the likelihood using synthetic data generated by the simulator, conditioned on parameters drawn from a proposal distribution. The learned likelihood can then be combined with any prior to obtain a posterior estimate, from which samples can be drawn using MCMC. Our methods uniquely combine a flexible Energy-Based Model and the minimization of a KL loss: this is in contrast to other synthetic likelihood methods, which either rely on normalizing flows, or minimize score-based objectives; choices that come with known pitfalls. We demonstrate the properties of both methods on a range of synthetic datasets, and apply them to a neuroscience model of the pyloric network in the crab, where our method outperforms prior art for a fraction of the simulation budget. "
}