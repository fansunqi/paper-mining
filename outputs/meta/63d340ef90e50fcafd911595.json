{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Hyperdimensional computing"
  ],
  "datasets": [
    "MNIST",
    "CIFAR-10"
  ],
  "methods": [
    "novel HDC models with binary hypervectors"
  ],
  "results": [
    "HDC accuracy of 96.88% with a dimension of 32 on MNIST",
    "equivalent or improved accuracy and efficiency compared to state-of-the-art HDC models"
  ],
  "paper_id": "63d340ef90e50fcafd911595",
  "title": "Efficient Hyperdimensional Computing",
  "abstract": "  Hyperdimensional computing (HDC) uses binary vectors of high dimensions to perform classification. Due to its simplicity and massive parallelism, HDC can be highly energy-efficient and well-suited for resource-constrained platforms. However, in trading off orthogonality with efficiency, hypervectors may use tens of thousands of dimensions. In this paper, we will examine the necessity for such high dimensions. In particular, we give a detailed theoretical analysis of the relationship among dimensions of hypervectors, accuracy, and orthogonality. The main conclusion of this study is that a much lower dimension, typically less than 100, can also achieve similar or even higher detecting accuracy compared with other state-of-the-art HDC models. Based on this insight, we propose a suite of novel techniques to build HDC models that use binary hypervectors of dimensions that are orders of magnitude smaller than those found in the state-of-the-art HDC models, yet yield equivalent or even improved accuracy and efficiency. For image classification, we achieved an HDC accuracy of 96.88\\% with a dimension of only 32 on the MNIST dataset. We further explore our methods on more complex datasets like CIFAR-10 and show the limits of HDC computing. "
}