{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Reversible Steganography"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Bayesian Neural Networks",
    "Predictive Modelling",
    "Monte Carlo Sampling",
    "Aleatoric and Epistemic Uncertainties"
  ],
  "results": [
    "Improvement in steganographic rate-distortion performance"
  ],
  "paper_id": "61dba39d5244ab9dcbe04d92",
  "title": "Bayesian Neural Networks for Reversible Steganography",
  "abstract": "  Recent advances in deep learning have led to a paradigm shift in the field of reversible steganography. A fundamental pillar of reversible steganography is predictive modelling which can be realised via deep neural networks. However, non-trivial errors exist in inferences about some out-of-distribution and noisy data. In view of this issue, we propose to consider uncertainty in predictive models based upon a theoretical framework of Bayesian deep learning, thereby creating an adaptive steganographic system. Most modern deep-learning models are regarded as deterministic because they only offer predictions while failing to provide uncertainty measurement. Bayesian neural networks bring a probabilistic perspective to deep learning and can be regarded as self-aware intelligent machinery; that is, a machine that knows its own limitations. To quantify uncertainty, we apply Bayesian statistics to model the predictive distribution and approximate it through Monte Carlo sampling with stochastic forward passes. We further show that predictive uncertainty can be disentangled into aleatoric and epistemic uncertainties and these quantities can be learnt unsupervised. Experimental results demonstrate an improvement delivered by Bayesian uncertainty analysis upon steganographic rate-distortion performance. "
}