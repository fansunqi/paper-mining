{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Federated learning",
    "Coded computing"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Gradient coding",
    "Erasure-coding techniques"
  ],
  "results": [
    "None"
  ],
  "paper_id": "63bcd73690e50fcafdefa3f9",
  "title": "Federated Coded Matrix Inversion",
  "abstract": "  Federated learning (FL) is a decentralized model for training data distributed across client devices. Coded computing (CC) is a method for mitigating straggling workers in a centralized computing network, by using erasure-coding techniques. In this work we propose approximating the inverse of a data matrix, where the data is generated by clients; similar to the FL paradigm, while also being resilient to stragglers. To do so, we propose a CC method based on gradient coding. We modify this method so that the coordinator does not need to have access to the local data, the network we consider is not centralized, and the communications which take place are secure against potential eavesdroppers. "
}