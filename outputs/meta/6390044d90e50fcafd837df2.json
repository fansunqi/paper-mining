{
  "code_links": [
    "None"
  ],
  "tasks": [
    "3D morphable model for complete human heads"
  ],
  "datasets": [
    "over 5200 head scans from 255 different identities"
  ],
  "methods": [
    "hybrid neural fields",
    "neural parametric representation",
    "signed distance field (SDF)",
    "neural deformation field",
    "ensemble of local fields"
  ],
  "results": [
    "outperforms state-of-the-art methods in terms of fitting error and reconstruction quality"
  ],
  "paper_id": "6390044d90e50fcafd837df2",
  "title": "Learning Neural Parametric Head Models",
  "abstract": "  We propose a novel 3D morphable model for complete human heads based on hybrid neural fields. At the core of our model lies a neural parametric representation that disentangles identity and expressions in disjoint latent spaces. To this end, we capture a person's identity in a canonical space as a signed distance field (SDF), and model facial expressions with a neural deformation field. In addition, our representation achieves high-fidelity local detail by introducing an ensemble of local fields centered around facial anchor points. To facilitate generalization, we train our model on a newly-captured dataset of over 5200 head scans from 255 different identities using a custom high-end 3D scanning setup. Our dataset significantly exceeds comparable existing datasets, both with respect to quality and completeness of geometry, averaging around 3.5M mesh faces per scan. Finally, we demonstrate that our approach outperforms state-of-the-art methods in terms of fitting error and reconstruction quality. "
}