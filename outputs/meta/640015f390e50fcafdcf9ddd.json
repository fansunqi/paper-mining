{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Fog Computing performance optimization",
    "Real-time IoT applications",
    "Privacy-aware load balancing"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Reinforcement Learning (RL)",
    "Discrete-event Simulator (DES)"
  ],
  "results": [
    "Outperforms baseline load balancing methods",
    "Ensures privacy of Fog service providers",
    "Better performance in environment representation for RL"
  ],
  "paper_id": "640015f390e50fcafdcf9ddd",
  "title": "Privacy-Aware Load Balancing in Fog Networks: A Reinforcement Learning\n  Approach",
  "abstract": "  In this paper, we propose a load balancing algorithm based on Reinforcement Learning (RL) to optimize the performance of Fog Computing for real-time IoT applications. The algorithm aims to minimize the waiting delay of IoT workloads in dynamic environments with unpredictable traffic demands, using intelligent workload distribution. Unlike previous studies, our solution does not require load and resource information from Fog nodes to preserve the privacy of service providers, who may wish to hide such information to prevent competitors from calculating better pricing strategies. The proposed algorithm is evaluated on a Discrete-event Simulator (DES) to mimic practical deployment in real environments, and its generalization ability is tested on simulations longer than what it was trained on. Our results show that our proposed approach outperforms baseline load balancing methods under different workload generation rates, while ensuring the privacy of Fog service providers. Furthermore, the environment representation we proposed for the RL agent demonstrates better performance compared to the commonly used representations for RL solutions in the literature, which compromise privacy. "
}