{
  "code_links": [
    "https://github.com/junjie18/CMT"
  ],
  "tasks": [
    "3D Object Detection"
  ],
  "datasets": [
    "nuScenes"
  ],
  "methods": [
    "Cross Modal Transformer"
  ],
  "results": [
    "74.1% NDS on nuScenes test set",
    "faster inference speed",
    "robustness even if LiDAR is missing"
  ],
  "paper_id": "63b63fd290e50fcafd8f5a04",
  "title": "Cross Modal Transformer: Towards Fast and Robust 3D Object Detection",
  "abstract": "  In this paper, we propose a robust 3D detector, named Cross Modal Transformer (CMT), for end-to-end 3D multi-modal detection. Without explicit view transformation, CMT takes the image and point clouds tokens as inputs and directly outputs accurate 3D bounding boxes. The spatial alignment of multi-modal tokens is performed by encoding the 3D points into multi-modal features. The core design of CMT is quite simple while its performance is impressive. It achieves 74.1\\% NDS (state-of-the-art with single model) on nuScenes test set while maintaining faster inference speed. Moreover, CMT has a strong robustness even if the LiDAR is missing. Code is released at https://github.com/junjie18/CMT. "
}