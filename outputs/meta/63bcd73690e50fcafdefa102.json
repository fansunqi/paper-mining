{
  "code_links": [
    "None"
  ],
  "tasks": [
    "AI Maintenance"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "AI model inspection framework",
    "levels of AI robustness automation"
  ],
  "results": [
    "robustness assessment",
    "status tracking",
    "risk scanning",
    "model hardening",
    "regulation throughout the AI lifecycle"
  ],
  "paper_id": "63bcd73690e50fcafdefa102",
  "title": "AI Maintenance: A Robustness Perspective",
  "abstract": "  With the advancements in machine learning (ML) methods and compute resources, artificial intelligence (AI) empowered systems are becoming a prevailing technology. However, current AI technology such as deep learning is not flawless. The significantly increased model complexity and data scale incur intensified challenges when lacking trustworthiness and transparency, which could create new risks and negative impacts. In this paper, we carve out AI maintenance from the robustness perspective. We start by introducing some highlighted robustness challenges in the AI lifecycle and motivating AI maintenance by making analogies to car maintenance. We then propose an AI model inspection framework to detect and mitigate robustness risks. We also draw inspiration from vehicle autonomy to define the levels of AI robustness automation. Our proposal for AI maintenance facilitates robustness assessment, status tracking, risk scanning, model hardening, and regulation throughout the AI lifecycle, which is an essential milestone toward building sustainable and trustworthy AI ecosystems. "
}