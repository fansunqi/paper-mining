{
  "code_links": [
    "https://github.com/razvancaramalau/MoBYv2AL"
  ],
  "tasks": [
    "Image classification"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "MoBYv2AL: Self-supervised Active Learning for Image Classification"
  ],
  "results": [
    "State-of-the-art results compared to recent AL methods"
  ],
  "paper_id": "63b63fd290e50fcafd8f5c62",
  "title": "MoBYv2AL: Self-supervised Active Learning for Image Classification",
  "abstract": "  Active learning(AL) has recently gained popularity for deep learning(DL) models. This is due to efficient and informative sampling, especially when the learner requires large-scale labelled datasets. Commonly, the sampling and training happen in stages while more batches are added. One main bottleneck in this strategy is the narrow representation learned by the model that affects the overall AL selection.   We present MoBYv2AL, a novel self-supervised active learning framework for image classification. Our contribution lies in lifting MoBY, one of the most successful self-supervised learning algorithms, to the AL pipeline. Thus, we add the downstream task-aware objective function and optimize it jointly with contrastive loss. Further, we derive a data-distribution selection function from labelling the new examples. Finally, we test and study our pipeline robustness and performance for image classification tasks. We successfully achieved state-of-the-art results when compared to recent AL methods. Code available: https://github.com/razvancaramalau/MoBYv2AL "
}