{
  "code_links": [
    "None"
  ],
  "tasks": [
    "EEG pattern interpretation",
    "Brain injury diagnosis"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Interpretable deep learning model"
  ],
  "results": [
    "Better performance than black box model",
    "First global overview of ictal-interictal-injury continuum brainwave patterns"
  ],
  "paper_id": "636dbe6890e50fcafd79a7d0",
  "title": "Interpretable Machine Learning System to EEG Patterns on the\n  Ictal-Interictal-Injury Continuum",
  "abstract": "  In intensive care units (ICUs), critically ill patients are monitored with electroencephalograms (EEGs) to prevent serious brain injury. The number of patients who can be monitored is constrained by the availability of trained physicians to read EEGs, and EEG interpretation can be subjective and prone to inter-observer variability. Automated deep learning systems for EEG could reduce human bias and accelerate the diagnostic process. However, black box deep learning models are untrustworthy, difficult to troubleshoot, and lack accountability in real-world applications, leading to a lack of trust and adoption by clinicians. To address these challenges, we propose a novel interpretable deep learning model that not only predicts the presence of harmful brainwave patterns but also provides high-quality case-based explanations of its decisions. Our model performs better than the corresponding black box model, despite being constrained to be interpretable. The learned 2D embedded space provides the first global overview of the structure of ictal-interictal-injury continuum brainwave patterns. The ability to understand how our model arrived at its decisions will not only help clinicians to diagnose and treat harmful brain activities more accurately but also increase their trust and adoption of machine learning models in clinical practice; this could be an integral component of the ICU neurologists' standard workflow. "
}