{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Causal AI"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Causal Representation Learning (CRL)",
    "redefined do-DAG"
  ],
  "results": [
    "None"
  ],
  "paper_id": "6375a67090e50fcafd3e1862",
  "title": "Realization of Causal Representation Learning and Redefined DAG for\n  Causal AI",
  "abstract": "  DAG(Directed Acyclic Graph) from causal inference does not differentiate causal effects and correlated changes. And the general effect of a population is usually approximated by averaging correlations over all individuals. Since AI(Artificial Intelligence) enables large-scale structure modeling on big data, the complex hidden confoundings have made these approximation errors no longer ignorable but snowballed to considerable modeling bias - Such Causal Representation Bias (CRB) leads to many problems: ungeneralizable causal models, unrevealed individual-level features, hardly utilized causal knowledge in DL(Deep Learning), etc. In short, DAG must be redefined to enable a new framework for causal AI.   The observational time series in statistics can only represent correlated changes, while the DL-based autoencoder can represent them as individualized feature changes in latent space to estimate the causal effects directly. In this paper, we introduce the redefined do-DAG to visualize CRB, propose a generic solution Causal Representation Learning (CRL) framework, along with a novel architecture for its realization, and experimentally verify the feasibility. "
}