{
  "code_links": [
    "https://github.com/ml-postech/Skeleton-anonymization/"
  ],
  "tasks": [
    "Skeleton-based action recognition",
    "Privacy protection in skeleton datasets"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Anonymization framework based on adversarial learning",
    "Classifiers for private information categorization"
  ],
  "results": [
    "Gender classifier accuracy: 87%",
    "Re-identification classifier accuracy: 80%",
    "Reduced privacy leakage with marginal effects on action recognition performance"
  ],
  "paper_id": "61a6e8995244ab9dcb50f4cf",
  "title": "Anonymization for Skeleton Action Recognition",
  "abstract": "  Skeleton-based action recognition attracts practitioners and researchers due to the lightweight, compact nature of datasets. Compared with RGB-video-based action recognition, skeleton-based action recognition is a safer way to protect the privacy of subjects while having competitive recognition performance. However, due to improvements in skeleton recognition algorithms as well as motion and depth sensors, more details of motion characteristics can be preserved in the skeleton dataset, leading to potential privacy leakage. We first train classifiers to categorize private information from skeleton trajectories to investigate the potential privacy leakage from skeleton datasets. Our preliminary experiments show that the gender classifier achieves 87% accuracy on average, and the re-identification classifier achieves 80% accuracy on average with three baseline models: Shift-GCN, MS-G3D, and 2s-AGCN. We propose an anonymization framework based on adversarial learning to protect potential privacy leakage from the skeleton dataset. Experimental results show that an anonymized dataset can reduce the risk of privacy leakage while having marginal effects on action recognition performance even with simple anonymizer architectures. The code used in our experiments is available at https://github.com/ml-postech/Skeleton-anonymization/ "
}