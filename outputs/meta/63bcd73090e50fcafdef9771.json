{
  "code_links": [
    "https://lama-www.github.io/"
  ],
  "tasks": [
    "Synthesizing Human-Scene Interactions"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Reinforcement Learning",
    "Motion Matching Algorithm",
    "Manifold Learning"
  ],
  "results": [
    "Outperforms existing approaches in various challenging scenarios"
  ],
  "paper_id": "63bcd73090e50fcafdef9771",
  "title": "Locomotion-Action-Manipulation: Synthesizing Human-Scene Interactions in\n  Complex 3D Environments",
  "abstract": "  Synthesizing interaction-involved human motions has been challenging due to the high complexity of 3D environments and the diversity of possible human behaviors within. We present LAMA, Locomotion-Action-MAnipulation, to synthesize natural and plausible long term human movements in complex indoor environments. The key motivation of LAMA is to build a unified framework to encompass a series of motions commonly observable in our daily lives, including locomotion, interactions with 3D scenes, and manipulations of 3D objects. LAMA is based on a reinforcement learning framework coupled with a motion matching algorithm to synthesize locomotion and scene interaction seamlessly under common constraints and collision avoidance handling. LAMA also exploits a motion editing framework via manifold learning to cover possible variations in interaction and manipulation motions. We quantitatively and qualitatively demonstrate that LAMA outperforms existing approaches in various challenging scenarios. Project webpage: https://lama-www.github.io/ . "
}