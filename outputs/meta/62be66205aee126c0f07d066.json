{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Learning nonparametric ordinary differential equations from noisy data"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Reproducing Kernel Hilbert Spaces (RKHS)",
    "penalty method",
    "Representer theorem",
    "Euler approximations"
  ],
  "results": [
    "generalization bound for the L2 distance",
    "experimental comparisons with the state-of-the-art"
  ],
  "paper_id": "62be66205aee126c0f07d066",
  "title": "Learning nonparametric ordinary differential equations from noisy data",
  "abstract": "  Learning nonparametric systems of Ordinary Differential Equations (ODEs) dot x = f(t,x) from noisy data is an emerging machine learning topic. We use the well-developed theory of Reproducing Kernel Hilbert Spaces (RKHS) to define candidates for f for which the solution of the ODE exists and is unique. Learning f consists of solving a constrained optimization problem in an RKHS. We propose a penalty method that iteratively uses the Representer theorem and Euler approximations to provide a numerical solution. We prove a generalization bound for the L2 distance between x and its estimator and provide experimental comparisons with the state-of-the-art. "
}