{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Moral justification of fairness-aware machine learning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Framework for moral reasoning about fairness metrics",
    "Analysis of fairness metrics suitability",
    "Exploration of moral arguments for fair-ml algorithms"
  ],
  "results": [
    "Specific circumstances where metrics correspond to fair distribution",
    "Enforcing fairness metrics may not result in fair outcomes and can have side effects",
    "Call for holistic evaluation of fair-ml algorithms beyond optimization objectives"
  ],
  "paper_id": "620f0e735aee126c0fec477d",
  "title": "Does the End Justify the Means? On the Moral Justification of\n  Fairness-Aware Machine Learning",
  "abstract": "  Fairness-aware machine learning (fair-ml) techniques are algorithmic interventions designed to ensure that individuals who are affected by the predictions of a machine learning model are treated fairly, typically measured in terms of a quantitative fairness metric. Despite the multitude of fairness metrics and fair-ml algorithms, there is still little guidance on the suitability of different approaches in practice. In this paper, we present a framework for moral reasoning about the justification of fairness metrics and explore the moral implications of the use of fair-ml algorithms that optimize for them. In particular, we argue that whether a distribution of outcomes is fair, depends not only on the cause of inequalities but also on what moral claims decision subjects have to receive a particular benefit or avoid a burden. We use our framework to analyze the suitability of two fairness metrics under different circumstances. Subsequently, we explore moral arguments that support or reject the use of the fair-ml algorithm introduced by Hardt et al. (2016). We argue that under very specific circumstances, particular metrics correspond to a fair distribution of burdens and benefits. However, we also illustrate that enforcing a fairness metric by means of a fair-ml algorithm may not result in the fair distribution of outcomes and can have several undesirable side effects. We end with a call for a more holistic evaluation of fair-ml algorithms, beyond their direct optimization objectives. "
}