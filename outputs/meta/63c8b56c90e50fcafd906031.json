{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Multi-channel continuous speech separation",
    "Automatic speech recognition (ASR) robustness"
  ],
  "datasets": [
    "LibriCSS"
  ],
  "methods": [
    "Multi-resolution location-based training (LBT)"
  ],
  "results": [
    "Multi-resolution LBT consistently outperforms other competitive methods"
  ],
  "paper_id": "63c8b56c90e50fcafd906031",
  "title": "Multi-resolution location-based training for multi-channel continuous\n  speech separation",
  "abstract": "  The performance of automatic speech recognition (ASR) systems severely degrades when multi-talker speech overlap occurs. In meeting environments, speech separation is typically performed to improve the robustness of ASR systems. Recently, location-based training (LBT) was proposed as a new training criterion for multi-channel talker-independent speaker separation. Assuming fixed array geometry, LBT outperforms widely-used permutation-invariant training in fully overlapped utterances and matched reverberant conditions. This paper extends LBT to conversational multi-channel speaker separation. We introduce multi-resolution LBT to estimate the complex spectrograms from low to high time and frequency resolutions. With multi-resolution LBT, convolutional kernels are assigned consistently based on speaker locations in physical space. Evaluation results show that multi-resolution LBT consistently outperforms other competitive methods on the recorded LibriCSS corpus. "
}