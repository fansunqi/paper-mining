{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Great Ape Behavioural Action Recognition"
  ],
  "datasets": [
    "PanAf-500"
  ],
  "methods": [
    "Triple-stream Deep Metric Learning",
    "DensePose-C chimpanzee body part segmentation",
    "Feature fusion techniques",
    "Long-tail recognition approaches"
  ],
  "results": [
    "Top-1 accuracy improvement of ~12% over previous results",
    "Average per class accuracy improvement of ~23% compared to the literature"
  ],
  "paper_id": "63bb859d90e50fcafd06f0db",
  "title": "Triple-stream Deep Metric Learning of Great Ape Behavioural Actions",
  "abstract": "  We propose the first metric learning system for the recognition of great ape behavioural actions. Our proposed triple stream embedding architecture works on camera trap videos taken directly in the wild and demonstrates that the utilisation of an explicit DensePose-C chimpanzee body part segmentation stream effectively complements traditional RGB appearance and optical flow streams. We evaluate system variants with different feature fusion techniques and long-tail recognition approaches. Results and ablations show performance improvements of ~12% in top-1 accuracy over previous results achieved on the PanAf-500 dataset containing 180,000 manually annotated frames across nine behavioural actions. Furthermore, we provide a qualitative analysis of our findings and augment the metric learning system with long-tail recognition techniques showing that average per class accuracy -- critical in the domain -- can be improved by ~23% compared to the literature on that dataset. Finally, since our embedding spaces are constructed as metric, we provide first data-driven visualisations of the great ape behavioural action spaces revealing emerging geometry and topology. We hope that the work sparks further interest in this vital application area of computer vision for the benefit of endangered great apes. "
}