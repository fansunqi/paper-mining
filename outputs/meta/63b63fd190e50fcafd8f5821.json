{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Compressed Video Quality Assessment"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "visual saliency model",
    "self-attention based TimeSFormer",
    "SSTAM"
  ],
  "results": [
    "outperforms state-of-the-art metrics"
  ],
  "paper_id": "63b63fd190e50fcafd8f5821",
  "title": "Saliency-Aware Spatio-Temporal Artifact Detection for Compressed Video\n  Quality Assessment",
  "abstract": "  Compressed videos often exhibit visually annoying artifacts, known as Perceivable Encoding Artifacts (PEAs), which dramatically degrade video visual quality. Subjective and objective measures capable of identifying and quantifying various types of PEAs are critical in improving visual quality. In this paper, we investigate the influence of four spatial PEAs (i.e. blurring, blocking, bleeding, and ringing) and two temporal PEAs (i.e. flickering and floating) on video quality. For spatial artifacts, we propose a visual saliency model with a low computational cost and higher consistency with human visual perception. In terms of temporal artifacts, self-attention based TimeSFormer is improved to detect temporal artifacts. Based on the six types of PEAs, a quality metric called Saliency-Aware Spatio-Temporal Artifacts Measurement (SSTAM) is proposed. Experimental results demonstrate that the proposed method outperforms state-of-the-art metrics. We believe that SSTAM will be beneficial for optimizing video coding techniques. "
}