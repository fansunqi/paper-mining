{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Multi-Style Image Captioning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Style-aware contrastive learning",
    "Style-aware visual encoder",
    "Style-aware triplet contrast objective",
    "Object-based retrieval",
    "RoI-based retrieval",
    "Triplet-based retrieval",
    "Dynamic trade-off function"
  ],
  "results": [
    "State-of-the-art performance",
    "Extensive analysis to verify effectiveness"
  ],
  "paper_id": "63d7352290e50fcafda30228",
  "title": "Style-Aware Contrastive Learning for Multi-Style Image Captioning",
  "abstract": "  Existing multi-style image captioning methods show promising results in generating a caption with accurate visual content and desired linguistic style. However, existing methods overlook the relationship between linguistic style and visual content. To overcome this drawback, we propose style-aware contrastive learning for multi-style image captioning. First, we present a style-aware visual encoder with contrastive learning to mine potential visual content relevant to style. Moreover, we propose a style-aware triplet contrast objective to distinguish whether the image, style and caption matched. To provide positive and negative samples for contrastive learning, we present three retrieval schemes: object-based retrieval, RoI-based retrieval and triplet-based retrieval, and design a dynamic trade-off function to calculate retrieval scores. Experimental results demonstrate that our approach achieves state-of-the-art performance. In addition, we conduct an extensive analysis to verify the effectiveness of our method. "
}