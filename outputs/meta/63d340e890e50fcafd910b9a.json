{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Dialogue Summarization"
  ],
  "datasets": [
    "DialogSum",
    "SAMSum"
  ],
  "methods": [
    "Natural Language Inference (NLI) models"
  ],
  "results": [
    "Balancing coverage and faithfulness",
    "Automatic metrics and human evaluations"
  ],
  "paper_id": "63d340e890e50fcafd910b9a",
  "title": "SWING: Balancing Coverage and Faithfulness for Dialogue Summarization",
  "abstract": "  Missing information is a common issue of dialogue summarization where some information in the reference summaries is not covered in the generated summaries. To address this issue, we propose to utilize natural language inference (NLI) models to improve coverage while avoiding introducing factual inconsistencies. Specifically, we use NLI to compute fine-grained training signals to encourage the model to generate content in the reference summaries that have not been covered, as well as to distinguish between factually consistent and inconsistent generated sentences. Experiments on the DialogSum and SAMSum datasets confirm the effectiveness of the proposed approach in balancing coverage and faithfulness, validated with automatic metrics and human evaluations. Additionally, we compute the correlation between commonly used automatic metrics with human judgments in terms of three different dimensions regarding coverage and factual consistency to provide insight into the most suitable metric for evaluating dialogue summaries. "
}