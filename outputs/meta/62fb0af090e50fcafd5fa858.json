{
  "code_links": [
    "https://github.com/Jathurshan0330/Cross-Modal-Transformer"
  ],
  "tasks": [
    "Sleep stage classification"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Cross-modal transformer",
    "Multi-scale one-dimensional convolutional neural network"
  ],
  "results": [
    "Outperforms state-of-the-art methods",
    "Reduces number of parameters and training time"
  ],
  "paper_id": "62fb0af090e50fcafd5fa858",
  "title": "Towards Interpretable Sleep Stage Classification Using Cross-Modal\n  Transformers",
  "abstract": "  Accurate sleep stage classification is significant for sleep health assessment. In recent years, several machine-learning based sleep staging algorithms have been developed, and in particular, deep-learning based algorithms have achieved performance on par with human annotation. Despite the improved performance, a limitation of most deep-learning based algorithms is their black-box behavior, which has limited their use in clinical settings. Here, we propose a cross-modal transformer, which is a transformer-based method for sleep stage classification. The proposed cross-modal transformer consists of a novel cross-modal transformer encoder architecture along with a multi-scale one-dimensional convolutional neural network for automatic representation learning. Our method outperforms the state-of-the-art methods and eliminates the black-box behavior of deep-learning models by utilizing the interpretability aspect of the attention modules. Furthermore, our method provides considerable reductions in the number of parameters and training time compared to the state-of-the-art methods. Our code is available at https://github.com/Jathurshan0330/Cross-Modal-Transformer. "
}