{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Buildings segmentation from aerial imagery"
  ],
  "datasets": [
    "Open Cities AI",
    "Multi-Scale Building"
  ],
  "methods": [
    "Scale-invariant Neural Network (Sci-Net)",
    "UNet hierarchical representation",
    "Dense Atrous Spatial Pyramid Pooling"
  ],
  "results": [
    "Sci-Net significantly outperforms state of the art models",
    "Steady improvement margin across different spatial resolutions"
  ],
  "paper_id": "6191cfa05244ab9dcb16bf0c",
  "title": "Sci-Net: Scale Invariant Model for Buildings Segmentation from Aerial\n  Imagery",
  "abstract": "  Buildings' segmentation is a fundamental task in the field of earth observation and aerial imagery analysis. Most existing deep learning-based methods in the literature can be applied to a fixed or narrow-range spatial resolution imagery. In practical scenarios, users deal with a broad spectrum of image resolutions. Thus, a given aerial image often needs to be re-sampled to match the spatial resolution of the dataset used to train the deep learning model, which results in a degradation in segmentation performance. To overcome this challenge, we propose, in this manuscript, Scale-invariant Neural Network (Sci-Net) architecture that segments buildings from wide-range spatial resolution aerial images. Specifically, our approach leverages UNet hierarchical representation and Dense Atrous Spatial Pyramid Pooling to extract fine-grained multi-scale representations. Sci-Net significantly outperforms state of the art models on the Open Cities AI and the Multi-Scale Building datasets with a steady improvement margin across different spatial resolutions. "
}