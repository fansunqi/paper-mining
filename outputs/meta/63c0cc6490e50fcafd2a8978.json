{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Gomoku Reinforcement Learning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Switchable Lightweight Anti-symmetric Processing (SLAP)",
    "CNN",
    "AlphaGo Zero/AlphaZero"
  ],
  "results": [
    "SLAP improved the convergence speed of CNN learning by 83%",
    "Reduced the number of training samples by a factor of 8",
    "Achieved similar winning rate against the same evaluator"
  ],
  "paper_id": "63c0cc6490e50fcafd2a8978",
  "title": "Switchable Lightweight Anti-symmetric Processing (SLAP) with CNN\n  Outspeeds Data Augmentation by Smaller Sample -- Application in Gomoku\n  Reinforcement Learning",
  "abstract": "  To replace data augmentation, this paper proposed a method called SLAP to intensify experience to speed up machine learning and reduce the sample size. SLAP is a model-independent protocol/function to produce the same output given different transformation variants. SLAP improved the convergence speed of convolutional neural network learning by 83% in the experiments with Gomoku game states, with only one eighth of the sample size compared with data augmentation. In reinforcement learning for Gomoku, using AlphaGo Zero/AlphaZero algorithm with data augmentation as baseline, SLAP reduced the number of training samples by a factor of 8 and achieved similar winning rate against the same evaluator, but it was not yet evident that it could speed up reinforcement learning. The benefits should at least apply to domains that are invariant to symmetry or certain transformations. As future work, SLAP may aid more explainable learning and transfer learning for domains that are not invariant to symmetry, as a small step towards artificial general intelligence. "
}