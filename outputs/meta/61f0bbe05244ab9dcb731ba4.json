{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Learning optimal fair classification trees"
  ],
  "datasets": [
    "popular datasets"
  ],
  "methods": [
    "mixed integer optimization (MIO) framework",
    "decision complexity measure"
  ],
  "results": [
    "price of interpretability: 4.2 percentage points in out-of-sample accuracy",
    "almost full parity in fairness"
  ],
  "paper_id": "61f0bbe05244ab9dcb731ba4",
  "title": "Learning Optimal Fair Classification Trees: Trade-offs Between\n  Interpretability, Fairness, and Accuracy",
  "abstract": "  The increasing use of machine learning in high-stakes domains -- where people's livelihoods are impacted -- creates an urgent need for interpretable, fair, and highly accurate algorithms. With these needs in mind, we propose a mixed integer optimization (MIO) framework for learning optimal classification trees -- one of the most interpretable models -- that can be augmented with arbitrary fairness constraints. In order to better quantify the \"price of interpretability\", we also propose a new measure of model interpretability called decision complexity that allows for comparisons across different classes of machine learning models. We benchmark our method against state-of-the-art approaches for fair classification on popular datasets; in doing so, we conduct one of the first comprehensive analyses of the trade-offs between interpretability, fairness, and predictive accuracy. Given a fixed disparity threshold, our method has a price of interpretability of about 4.2 percentage points in terms of out-of-sample accuracy compared to the best performing, complex models. However, our method consistently finds decisions with almost full parity, while other methods rarely do. "
}