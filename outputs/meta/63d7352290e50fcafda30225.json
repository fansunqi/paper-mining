{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Unsupervised Anomaly Detection"
  ],
  "datasets": [
    "Synthetic time-series data set",
    "Synthetic imaging data set generated from MNIST",
    "Metal milling data set",
    "Data set taken from a particle accelerator"
  ],
  "methods": [
    "CoAD"
  ],
  "results": [
    "None"
  ],
  "paper_id": "63d7352290e50fcafda30225",
  "title": "Coincident Learning for Unsupervised Anomaly Detection",
  "abstract": "  Anomaly detection is an important task for complex systems (e.g., industrial facilities, manufacturing, large-scale science experiments), where failures in a sub-system can lead to low yield, faulty products, or even damage to components. While complex systems often have a wealth of data, labeled anomalies are typically rare (or even nonexistent) and expensive to acquire. In this paper, we introduce a new method, called CoAD, for training anomaly detection models on unlabeled data, based on the expectation that anomalous behavior in one sub-system will produce coincident anomalies in downstream sub-systems and products. Given data split into two streams $s$ and $q$ (i.e., subsystem diagnostics and final product quality), we define an unsupervised metric, $\\hat{F}_\\beta$, out of analogy to the supervised classification $F_\\beta$ statistic, which quantifies the performance of the independent anomaly detection algorithms on s and q based on their coincidence rate. We demonstrate our method in four cases: a synthetic time-series data set, a synthetic imaging data set generated from MNIST, a metal milling data set, and a data set taken from a particle accelerator. "
}