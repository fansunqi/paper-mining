{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Graph contrastive learning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Counterfactual mechanism",
    "CGC"
  ],
  "results": [
    "Satisfying results compared to traditional unsupervised graph learning methods and SOTA graph contrastive learning methods"
  ],
  "paper_id": "62c2a9595aee126c0fcf0b05",
  "title": "Generating Counterfactual Hard Negative Samples for Graph Contrastive\n  Learning",
  "abstract": "  Graph contrastive learning has emerged as a powerful tool for unsupervised graph representation learning. The key to the success of graph contrastive learning is to acquire high-quality positive and negative samples as contrasting pairs for the purpose of learning underlying structural semantics of the input graph. Recent works usually sample negative samples from the same training batch with the positive samples, or from an external irrelevant graph. However, a significant limitation lies in such strategies, which is the unavoidable problem of sampling false negative samples. In this paper, we propose a novel method to utilize \\textbf{C}ounterfactual mechanism to generate artificial hard negative samples for \\textbf{G}raph \\textbf{C}ontrastive learning, namely \\textbf{CGC}, which has a different perspective compared to those sampling-based strategies. We utilize counterfactual mechanism to produce hard negative samples, which ensures that the generated samples are similar to, but have labels that different from the positive sample. The proposed method achieves satisfying results on several datasets compared to some traditional unsupervised graph learning methods and some SOTA graph contrastive learning methods. We also conduct some supplementary experiments to give an extensive illustration of the proposed method, including the performances of CGC with different hard negative samples and evaluations for hard negative samples generated with different similarity measurements. "
}