{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Image and video compression"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Entropy coding parameter optimization",
    "Low-precision quantization"
  ],
  "results": [
    "4~bits precision",
    "8~bits practically no loss"
  ],
  "paper_id": "63d340de90e50fcafd90f750",
  "title": "Optimized learned entropy coding parameters for practical neural-based\n  image and video compression",
  "abstract": "  Neural-based image and video codecs are significantly more power-efficient when weights and activations are quantized to low-precision integers. While there are general-purpose techniques for reducing quantization effects, large losses can occur when specific entropy coding properties are not considered. This work analyzes how entropy coding is affected by parameter quantizations, and provides a method to minimize losses. It is shown that, by using a certain type of coding parameters to be learned, uniform quantization becomes practically optimal, also simplifying the minimization of code memory requirements. The mathematical properties of the new representation are presented, and its effectiveness is demonstrated by coding experiments, showing that good results can be obtained with precision as low as 4~bits per network output, and practically no loss with 8~bits. "
}