{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Model Reduction of Parametric Time-Dependent Problems"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Two-stages Deep Learning Architecture"
  ],
  "results": [
    "97% reduction in computational time"
  ],
  "paper_id": "63d340e890e50fcafd9106ed",
  "title": "A two stages Deep Learning Architecture for Model Reduction of\n  Parametric Time-Dependent Problems",
  "abstract": "  Parametric time-dependent systems are of a crucial importance in modeling real phenomena, often characterized by non-linear behaviors too. Those solutions are typically difficult to generalize in a sufficiently wide parameter space while counting on limited computational resources available. As such, we present a general two-stages deep learning framework able to perform that generalization with low computational effort in time. It consists in a separated training of two pipe-lined predictive models. At first, a certain number of independent neural networks are trained with data-sets taken from different subsets of the parameter space. Successively, a second predictive model is specialized to properly combine the first-stage guesses and compute the right predictions. Promising results are obtained applying the framework to incompressible Navier-Stokes equations in a cavity (Rayleigh-Bernard cavity), obtaining a 97% reduction in the computational time comparing with its numerical resolution for a new value of the Grashof number. "
}