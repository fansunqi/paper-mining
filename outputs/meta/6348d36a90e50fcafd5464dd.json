{
  "code_links": [
    "https://github.com/guldoganozgur/ei_fairness"
  ],
  "tasks": [
    "Fair classifier design",
    "Long-term fairness in machine learning"
  ],
  "datasets": [
    "Synthetic datasets",
    "Real datasets"
  ],
  "methods": [
    "Equal Improvability (EI) metric",
    "EI-regularized optimization problems"
  ],
  "results": [
    "Demonstrates the advantages of EI metric in achieving long-term fairness"
  ],
  "paper_id": "6348d36a90e50fcafd5464dd",
  "title": "Equal Improvability: A New Fairness Notion Considering the Long-term\n  Impact",
  "abstract": "  Devising a fair classifier that does not discriminate against different groups is an important problem in machine learning. Although researchers have proposed various ways of defining group fairness, most of them only focused on the immediate fairness, ignoring the long-term impact of a fair classifier under the dynamic scenario where each individual can improve its feature over time. Such dynamic scenarios happen in real world, e.g., college admission and credit loaning, where each rejected sample makes effort to change its features to get accepted afterwards. In this dynamic setting, the long-term fairness should equalize the samples' feature distribution across different groups after the rejected samples make some effort to improve. In order to promote long-term fairness, we propose a new fairness notion called Equal Improvability (EI), which equalizes the potential acceptance rate of the rejected samples across different groups assuming a bounded level of effort will be spent by each rejected sample. We analyze the properties of EI and its connections with existing fairness notions. To find a classifier that satisfies the EI requirement, we propose and study three different approaches that solve EI-regularized optimization problems. Through experiments on both synthetic and real datasets, we demonstrate that the proposed EI-regularized algorithms encourage us to find a fair classifier in terms of EI. Finally, we provide experimental results on dynamic scenarios which highlight the advantages of our EI metric in achieving the long-term fairness. Codes are available in a GitHub repository, see https://github.com/guldoganozgur/ei_fairness. "
}