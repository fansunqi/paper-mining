{
  "code_links": [
    "None"
  ],
  "tasks": [
    "3D Object Detection"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "VINet: Global Pre-Processing and Lightweight Feature Extraction",
    "Two-Stream Fusion",
    "Central Feature Backbone and 3D Detection Head"
  ],
  "results": [
    "84% system-level computational cost reduction",
    "94% system-level communication cost reduction",
    "Improved 3D detection accuracy"
  ],
  "paper_id": "639a906390e50fcafdefe4a4",
  "title": "VINet: Lightweight, Scalable, and Heterogeneous Cooperative Perception\n  for 3D Object Detection",
  "abstract": "  Utilizing the latest advances in Artificial Intelligence (AI), the computer vision community is now witnessing an unprecedented evolution in all kinds of perception tasks, particularly in object detection. Based on multiple spatially separated perception nodes, Cooperative Perception (CP) has emerged to significantly advance the perception of automated driving. However, current cooperative object detection methods mainly focus on ego-vehicle efficiency without considering the practical issues of system-wide costs. In this paper, we introduce VINet, a unified deep learning-based CP network for scalable, lightweight, and heterogeneous cooperative 3D object detection. VINet is the first CP method designed from the standpoint of large-scale system-level implementation and can be divided into three main phases: 1) Global Pre-Processing and Lightweight Feature Extraction which prepare the data into global style and extract features for cooperation in a lightweight manner; 2) Two-Stream Fusion which fuses the features from scalable and heterogeneous perception nodes; and 3) Central Feature Backbone and 3D Detection Head which further process the fused features and generate cooperative detection results. An open-source data experimental platform is designed and developed for CP dataset acquisition and model evaluation. The experimental analysis shows that VINet can reduce 84% system-level computational cost and 94% system-level communication cost while improving the 3D detection accuracy. "
}