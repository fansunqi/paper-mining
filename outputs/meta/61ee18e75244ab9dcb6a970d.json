{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Privacy-utility trade-off design"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Functional Representation Lemma extension",
    "Strong Functional Representation Lemma extension",
    "Privacy mechanism for data disclosure"
  ],
  "results": [
    "Improved upper and lower bounds for privacy-utility trade-off",
    "Relaxed independence condition allowing certain leakage"
  ],
  "paper_id": "61ee18e75244ab9dcb6a970d",
  "title": "Bounds for Privacy-Utility Trade-off with Non-zero Leakage",
  "abstract": "  The design of privacy mechanisms for two scenarios is studied where the private data is hidden or observable. In the first scenario, an agent observes useful data $Y$, which is correlated with private data $X$, and wants to disclose the useful information to a user. A privacy mechanism is employed to generate data $U$ that maximizes the revealed information about $Y$ while satisfying a privacy criterion. In the second scenario, the agent has additionally access to the private data. To this end, the Functional Representation Lemma and Strong Functional Representation Lemma are extended relaxing the independence condition and thereby allowing a certain leakage. Lower bounds on privacy-utility trade-off are derived for the second scenario as well as upper bounds for both scenarios. In particular, for the case where no leakage is allowed, our upper and lower bounds improve previous bounds. "
}