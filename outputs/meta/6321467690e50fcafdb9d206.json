{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Recommendation systems"
  ],
  "datasets": [
    "MovieLens"
  ],
  "methods": [
    "Collaborative Filtering (CF) Multi-armed Bandit (B) with Attributes (A)"
  ],
  "results": [
    "Improvement on cumulative average rewards relative to the most powerful extant baseline methods"
  ],
  "paper_id": "6321467690e50fcafdb9d206",
  "title": "A Scalable Recommendation Engine for New Users and Items",
  "abstract": "  In many digital contexts such as online news and e-tailing with many new users and items, recommendation systems face several challenges: i) how to make initial recommendations to users with little or no response history (i.e., cold-start problem), ii) how to learn user preferences on items (test and learn), and iii) how to scale across many users and items with myriad demographics and attributes. While many recommendation systems accommodate aspects of these challenges, few if any address all. This paper introduces a Collaborative Filtering (CF) Multi-armed Bandit (B) with Attributes (A) recommendation system (CFB-A) to jointly accommodate all of these considerations. Empirical applications including an offline test on MovieLens data, synthetic data simulations, and an online grocery experiment indicate the CFB-A leads to substantial improvement on cumulative average rewards (e.g., total money or time spent, clicks, purchased quantities, average ratings, etc.) relative to the most powerful extant baseline methods. "
}