{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Remote control tasks with dynamic feature compression"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Ensemble Vector Quantized Variational Autoencoder (VQ-VAE)",
    "Deep Reinforcement Learning (DRL)"
  ],
  "results": [
    "Significant performance increase over traditional approaches"
  ],
  "paper_id": "63c8b56b90e50fcafd905b6b",
  "title": "Semantic and Effective Communication for Remote Control Tasks with\n  Dynamic Feature Compression",
  "abstract": "  The coordination of robotic swarms and the remote wireless control of industrial systems are among the major use cases for 5G and beyond systems: in these cases, the massive amounts of sensory information that needs to be shared over the wireless medium can overload even high-capacity connections. Consequently, solving the effective communication problem by optimizing the transmission strategy to discard irrelevant information can provide a significant advantage, but is often a very complex task. In this work, we consider a prototypal system in which an observer must communicate its sensory data to an actor controlling a task (e.g., a mobile robot in a factory). We then model it as a remote Partially Observable Markov Decision Process (POMDP), considering the effect of adopting semantic and effective communication-oriented solutions on the overall system performance. We split the communication problem by considering an ensemble Vector Quantized Variational Autoencoder (VQ-VAE) encoding, and train a Deep Reinforcement Learning (DRL) agent to dynamically adapt the quantization level, considering both the current state of the environment and the memory of past messages. We tested the proposed approach on the well-known CartPole reference control problem, obtaining a significant performance increase over traditional approaches "
}