{
  "code_links": [
    "https://github.com/huaaaliu/RGBX_Semantic_Segmentation"
  ],
  "tasks": [
    "RGB-X Semantic Segmentation"
  ],
  "datasets": [
    "RGB-Depth benchmarks",
    "RGB-Thermal",
    "RGB-Polarization",
    "RGB-LiDAR",
    "EventScape"
  ],
  "methods": [
    "CMX (Cross-Modal Fusion)",
    "Cross-Modal Feature Rectification Module (CM-FRM)",
    "Feature Fusion Module (FFM)",
    "Cross-attention mechanism"
  ],
  "results": [
    "State-of-the-art performances on five RGB-Depth benchmarks",
    "State-of-the-art on RGB-Thermal, RGB-Polarization, RGB-LiDAR",
    "New state-of-the-art on RGB-Event semantic segmentation benchmark"
  ],
  "paper_id": "62296c7b5aee126c0f57d7e0",
  "title": "CMX: Cross-Modal Fusion for RGB-X Semantic Segmentation with\n  Transformers",
  "abstract": "  Scene understanding based on image segmentation is a crucial component for autonomous vehicles. Pixel-wise semantic segmentation of RGB images can be advanced by exploiting informative features from the supplementary modality (X-modality). In this work, we propose CMX, a transformer-based cross-modal fusion framework for RGB-X semantic segmentation. To generalize to different sensing modalities encompassing various supplements and uncertainties, we consider that comprehensive cross-modal interactions should be provided. CMX is built with two streams to extract features from RGB images and the X-modality. In each feature extraction stage, we design a Cross-Modal Feature Rectification Module (CM-FRM) to calibrate the feature of the current modality by combining the feature from the other modality, in spatial- and channel-wise dimensions. With rectified feature pairs, we deploy a Feature Fusion Module (FFM) to mix them for the final semantic prediction. FFM is constructed with a cross-attention mechanism, which enables exchange of long-range contexts, enhancing bi-modal features globally. Extensive experiments show that CMX generalizes to diverse multi-modal combinations, achieving state-of-the-art performances on five RGB-Depth benchmarks, as well as RGB-Thermal, RGB-Polarization, and RGB-LiDAR datasets. Besides, to investigate the generalizability to dense-sparse data fusion, we establish an RGB-Event semantic segmentation benchmark based on the EventScape dataset, on which CMX sets the new state-of-the-art. The source code of CMX is publicly available at https://github.com/huaaaliu/RGBX_Semantic_Segmentation. "
}