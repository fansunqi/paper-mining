{
  "code_links": [
    "https://nope-nerf.active.vision/"
  ],
  "tasks": [
    "Neural Radiance Field (NeRF) training without pre-computed camera poses"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Incorporating undistorted monocular depth priors",
    "Novel loss functions for pose estimation"
  ],
  "results": [
    "Handles challenging camera trajectories",
    "Outperforms existing methods in novel view rendering quality and pose estimation accuracy"
  ],
  "paper_id": "639a906390e50fcafdefe744",
  "title": "NoPe-NeRF: Optimising Neural Radiance Field with No Pose Prior",
  "abstract": "  Training a Neural Radiance Field (NeRF) without pre-computed camera poses is challenging. Recent advances in this direction demonstrate the possibility of jointly optimising a NeRF and camera poses in forward-facing scenes. However, these methods still face difficulties during dramatic camera movement. We tackle this challenging problem by incorporating undistorted monocular depth priors. These priors are generated by correcting scale and shift parameters during training, with which we are then able to constrain the relative poses between consecutive frames. This constraint is achieved using our proposed novel loss functions. Experiments on real-world indoor and outdoor scenes show that our method can handle challenging camera trajectories and outperforms existing methods in terms of novel view rendering quality and pose estimation accuracy. Our project page is https://nope-nerf.active.vision. "
}