{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Monaural Noisy Reverberant Speech Separation"
  ],
  "datasets": [
    "WHAMR"
  ],
  "methods": [
    "Deformable Temporal Convolutional Networks"
  ],
  "results": [
    "11.1 dB average scale-invariant signal-to-distortion ratio (SISDR) improvement",
    "1.3M parameters model with comparable separation performance to larger models"
  ],
  "paper_id": "635b486f90e50fcafd330c50",
  "title": "Deformable Temporal Convolutional Networks for Monaural Noisy\n  Reverberant Speech Separation",
  "abstract": "  Speech separation models are used for isolating individual speakers in many speech processing applications. Deep learning models have been shown to lead to state-of-the-art (SOTA) results on a number of speech separation benchmarks. One such class of models known as temporal convolutional networks (TCNs) has shown promising results for speech separation tasks. A limitation of these models is that they have a fixed receptive field (RF). Recent research in speech dereverberation has shown that the optimal RF of a TCN varies with the reverberation characteristics of the speech signal. In this work deformable convolution is proposed as a solution to allow TCN models to have dynamic RFs that can adapt to various reverberation times for reverberant speech separation. The proposed models are capable of achieving an 11.1 dB average scale-invariant signalto-distortion ratio (SISDR) improvement over the input signal on the WHAMR benchmark. A relatively small deformable TCN model of 1.3M parameters is proposed which gives comparable separation performance to larger and more computationally complex models. "
}