{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Estimating grouping loss of modern neural networks"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Proposed estimator for grouping loss"
  ],
  "results": [
    "Modern neural networks exhibit grouping loss",
    "Importance of pre-production validation highlighted"
  ],
  "paper_id": "63608e4f90e50fcafdee0efd",
  "title": "Beyond calibration: estimating the grouping loss of modern neural\n  networks",
  "abstract": "  The ability to ensure that a classifier gives reliable confidence scores is essential to ensure informed decision-making. To this end, recent work has focused on miscalibration, i.e., the over or under confidence of model scores. Yet calibration is not enough: even a perfectly calibrated classifier with the best possible accuracy can have confidence scores that are far from the true posterior probabilities. This is due to the grouping loss, created by samples with the same confidence scores but different true posterior probabilities. Proper scoring rule theory shows that given the calibration loss, the missing piece to characterize individual errors is the grouping loss. While there are many estimators of the calibration loss, none exists for the grouping loss in standard settings. Here, we propose an estimator to approximate the grouping loss. We show that modern neural network architectures in vision and NLP exhibit grouping loss, notably in distribution shifts settings, which highlights the importance of pre-production validation. "
}