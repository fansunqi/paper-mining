{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Model Interpretation"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Causal Abstraction",
    "Interventions on model-internal states",
    "Approximate causal abstraction",
    "Marginalization, variable-merge, value-merge",
    "Formalization of XAI methods"
  ],
  "results": [
    "Generalization of causal abstraction",
    "Multi-source interchange interventions",
    "Constructive causal abstraction decomposition",
    "Formalization of LIME, causal effect estimation, causal mediation analysis, iterated nullspace projection, and circuit-based explanations"
  ],
  "paper_id": "63c0cc6390e50fcafd2a892a",
  "title": "Causal Abstraction for Faithful Model Interpretation",
  "abstract": "  A faithful and interpretable explanation of an AI model's behavior and internal structure is a high-level explanation that is human-intelligible but also consistent with the known, but often opaque low-level causal details of the model. We argue that the theory of causal abstraction provides the mathematical foundations for the desired kinds of model explanations. In causal abstraction analysis, we use interventions on model-internal states to rigorously assess whether an interpretable high-level causal model is a faithful description of an AI model. Our contributions in this area are: (1) We generalize causal abstraction to cyclic causal structures and typed high-level variables. (2) We show how multi-source interchange interventions can be used to conduct causal abstraction analyses. (3) We define a notion of approximate causal abstraction that allows us to assess the degree to which a high-level causal model is a causal abstraction of a lower-level one. (4) We prove constructive causal abstraction can be decomposed into three operations we refer to as marginalization, variable-merge, and value-merge. (5) We formalize the XAI methods of LIME, causal effect estimation, causal mediation analysis, iterated nullspace projection, and circuit-based explanations as special cases of causal abstraction analysis. "
}