{
  "code_links": [
    "https://github.com/venkatasg/interpersonal-bias"
  ],
  "tasks": [
    "Modeling Generalized Intergroup Bias and Emotion"
  ],
  "datasets": [
    "English tweets by US Congress members annotated for interpersonal emotion"
  ],
  "methods": [
    "Neural models for predicting interpersonal group relationship (IGR)"
  ],
  "results": [
    "Neural models perform much better than humans at identifying IGR",
    "Shared encoding between IGR and interpersonal perceived emotion enabled performance gains"
  ],
  "paper_id": "632297f690e50fcafdc88ac4",
  "title": "How people talk about each other: Modeling Generalized Intergroup Bias\n  and Emotion",
  "abstract": "  Current studies of bias in NLP rely mainly on identifying (unwanted or negative) bias towards a specific demographic group. While this has led to progress recognizing and mitigating negative bias, and having a clear notion of the targeted group is necessary, it is not always practical. In this work we extrapolate to a broader notion of bias, rooted in social science and psychology literature. We move towards predicting interpersonal group relationship (IGR) - modeling the relationship between the speaker and the target in an utterance - using fine-grained interpersonal emotions as an anchor. We build and release a dataset of English tweets by US Congress members annotated for interpersonal emotion -- the first of its kind, and 'found supervision' for IGR labels; our analyses show that subtle emotional signals are indicative of different biases. While humans can perform better than chance at identifying IGR given an utterance, we show that neural models perform much better; furthermore, a shared encoding between IGR and interpersonal perceived emotion enabled performance gains in both tasks. Data and code for this paper are available at https://github.com/venkatasg/interpersonal-bias "
}