{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Long-term Semantic Scene Change Prediction"
  ],
  "datasets": [
    "3RScan"
  ],
  "methods": [
    "3D Variable Scene Graph (VSG)",
    "DeltaVSG"
  ],
  "results": [
    "Accuracy: 77.1%",
    "Recall: 72.3%",
    "Speeds up task completion by 66.0%"
  ],
  "paper_id": "6327dda790e50fcafd67e1cd",
  "title": "3D VSG: Long-term Semantic Scene Change Prediction through 3D Variable\n  Scene Graphs",
  "abstract": "  Numerous applications require robots to operate in environments shared with other agents, such as humans or other robots. However, such shared scenes are typically subject to different kinds of long-term semantic scene changes. The ability to model and predict such changes is thus crucial for robot autonomy. In this work, we formalize the task of semantic scene variability estimation and identify three main varieties of semantic scene change: changes in the position of an object, its semantic state, or the composition of a scene as a whole. To represent this variability, we propose the Variable Scene Graph (VSG), which augments existing 3D Scene Graph (SG) representations with the variability attribute, representing the likelihood of discrete long-term change events. We present a novel method, DeltaVSG, to estimate the variability of VSGs in a supervised fashion. We evaluate our method on the 3RScan long-term dataset, showing notable improvements in this novel task over existing approaches. Our method DeltaVSG achieves an accuracy of 77.1% and a recall of 72.3%, often mimicking human intuition about how indoor scenes change over time. We further show the utility of VSG prediction in the task of active robotic change detection, speeding up task completion by 66.0% compared to a scene-change-unaware planner. We make our code available as open-source. "
}