{
  "code_links": [
    "https://github.com/mzy94/JCLRNT"
  ],
  "tasks": [
    "Road network and trajectory representation learning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Jointly Contrastive Representation Learning",
    "Domain-specific augmentations",
    "Cross-scale contrast",
    "Novel positive sampling",
    "Adaptive weighting strategies"
  ],
  "results": [
    "Improved performance and effectiveness on four downstream tasks"
  ],
  "paper_id": "632297f490e50fcafdc87df7",
  "title": "Jointly Contrastive Representation Learning on Road Network and\n  Trajectory",
  "abstract": "  Road network and trajectory representation learning are essential for traffic systems since the learned representation can be directly used in various downstream tasks (e.g., traffic speed inference, and travel time estimation). However, most existing methods only contrast within the same scale, i.e., treating road network and trajectory separately, which ignores valuable inter-relations. In this paper, we aim to propose a unified framework that jointly learns the road network and trajectory representations end-to-end. We design domain-specific augmentations for road-road contrast and trajectory-trajectory contrast separately, i.e., road segment with its contextual neighbors and trajectory with its detour replaced and dropped alternatives, respectively. On top of that, we further introduce the road-trajectory cross-scale contrast to bridge the two scales by maximizing the total mutual information. Unlike the existing cross-scale contrastive learning methods on graphs that only contrast a graph and its belonging nodes, the contrast between road segment and trajectory is elaborately tailored via novel positive sampling and adaptive weighting strategies. We conduct prudent experiments based on two real-world datasets with four downstream tasks, demonstrating improved performance and effectiveness. The code is available at https://github.com/mzy94/JCLRNT. "
}