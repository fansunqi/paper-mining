{
  "code_links": [
    "https://github.com/lingl_space/maskrcnn_keypoint_refined"
  ],
  "tasks": [
    "Human Pose Estimation"
  ],
  "datasets": [
    "COCO val2017"
  ],
  "methods": [
    "Mask-RCNN",
    "Global Context Module"
  ],
  "results": [
    "AP of 68.1 on COCO val2017",
    "2.6 higher AP than Mask RCNN",
    "Performance gap narrowed compared to SimpleBaseline",
    "Faster inference speed (77 ms vs. 168 ms)"
  ],
  "paper_id": "63c0cc6490e50fcafd2a8b7b",
  "title": "Towards High Performance One-Stage Human Pose Estimation",
  "abstract": "  Making top-down human pose estimation method present both good performance and high efficiency is appealing. Mask RCNN can largely improve the efficiency by conducting person detection and pose estimation in a single framework, as the features provided by the backbone are able to be shared by the two tasks. However, the performance is not as good as traditional two-stage methods. In this paper, we aim to largely advance the human pose estimation results of Mask-RCNN and still keep the efficiency. Specifically, we make improvements on the whole process of pose estimation, which contains feature extraction and keypoint detection. The part of feature extraction is ensured to get enough and valuable information of pose. Then, we introduce a Global Context Module into the keypoints detection branch to enlarge the receptive field, as it is crucial to successful human pose estimation. On the COCO val2017 set, our model using the ResNet-50 backbone achieves an AP of 68.1, which is 2.6 higher than Mask RCNN (AP of 65.5). Compared to the classic two-stage top-down method SimpleBaseline, our model largely narrows the performance gap (68.1 AP vs. 68.9 AP) with a much faster inference speed (77 ms vs. 168 ms), demonstrating the effectiveness of the proposed method. Code is available at: https://github.com/lingl_space/maskrcnn_keypoint_refined. "
}