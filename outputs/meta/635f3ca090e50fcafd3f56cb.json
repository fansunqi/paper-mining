{
  "code_links": [
    "https://github.com/zhang-tuo-pdf/FedAudio"
  ],
  "tasks": [
    "Audio tasks"
  ],
  "datasets": [
    "Four representative and commonly used audio datasets"
  ],
  "methods": [
    "Federated learning"
  ],
  "results": [
    "None"
  ],
  "paper_id": "635f3ca090e50fcafd3f56cb",
  "title": "FedAudio: A Federated Learning Benchmark for Audio Tasks",
  "abstract": "  Federated learning (FL) has gained substantial attention in recent years due to the data privacy concerns related to the pervasiveness of consumer devices that continuously collect data from users. While a number of FL benchmarks have been developed to facilitate FL research, none of them include audio data and audio-related tasks. In this paper, we fill this critical gap by introducing a new FL benchmark for audio tasks which we refer to as FedAudio. FedAudio includes four representative and commonly used audio datasets from three important audio tasks that are well aligned with FL use cases. In particular, a unique contribution of FedAudio is the introduction of data noises and label errors to the datasets to emulate challenges when deploying FL systems in real-world settings. FedAudio also includes the benchmark results of the datasets and a PyTorch library with the objective of facilitating researchers to fairly compare their algorithms. We hope FedAudio could act as a catalyst to inspire new FL research for audio tasks and thus benefit the acoustic and speech research community. The datasets and benchmark results can be accessed at https://github.com/zhang-tuo-pdf/FedAudio. "
}