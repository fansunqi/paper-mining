{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Inverse Reinforcement Learning of Bayesian Stopping Time Problems"
  ],
  "datasets": [
    "YouTube dataset"
  ],
  "methods": [
    "Necessary and Sufficient Conditions for IRL",
    "Bayesian Revealed Preferences",
    "IRL Detection Algorithm"
  ],
  "results": [
    "High accuracy in predicting user engagement in online multimedia platforms",
    "Finite sample bounds on error probabilities for IRL detection algorithm"
  ],
  "paper_id": "5f059f0a91e011c57e3e8de5",
  "title": "Necessary and Sufficient Conditions for Inverse Reinforcement Learning\n  of Bayesian Stopping Time Problems",
  "abstract": "  This paper presents an inverse reinforcement learning~(IRL) framework for Bayesian stopping time problems. By observing the actions of a Bayesian decision maker, we provide a necessary and sufficient condition to identify if these actions are consistent with optimizing a cost function. In a Bayesian (partially observed) setting, the inverse learner can at best identify optimality wrt the observed strategies. Our IRL algorithm identifies optimality and then constructs set-valued estimates of the cost function.To achieve this IRL objective, we use novel ideas from Bayesian revealed preferences stemming from microeconomics. We illustrate the proposed IRL scheme using two important examples of stopping time problems, namely, sequential hypothesis testing and Bayesian search. As a real-world example, we illustrate using a YouTube dataset comprising metadata from 190000 videos how the proposed IRL method predicts user engagement in online multimedia platforms with high accuracy. Finally, for finite datasets, we propose an IRL detection algorithm and give finite sample bounds on its error probabilities. "
}