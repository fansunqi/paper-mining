{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Neural information processing",
    "Deep learning limitations",
    "Context-sensitive neural processing"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Local processors",
    "Agreement maximization",
    "Context-sensitive neurons"
  ],
  "results": [
    "Effective and efficient neural information processing",
    "Reduced neural activity for large data processing"
  ],
  "paper_id": "62d4cf315aee126c0fa9acf9",
  "title": "Context-sensitive neocortical neurons transform the effectiveness and\n  efficiency of neural information processing",
  "abstract": "  Deep learning (DL) has big-data processing capabilities that are as good, or even better, than those of humans in many real-world domains, but at the cost of high energy requirements that may be unsustainable in some applications and of errors, that, though infrequent, can be large. We hypothesise that a fundamental weakness of DL lies in its intrinsic dependence on integrate-and-fire point neurons that maximise information transmission irrespective of whether it is relevant in the current context or not. This leads to unnecessary neural firing and to the feedforward transmission of conflicting messages, which makes learning difficult and processing energy inefficient. Here we show how to circumvent these limitations by mimicking the capabilities of context-sensitive neocortical neurons that receive input from diverse sources as a context to amplify and attenuate the transmission of relevant and irrelevant information, respectively. We demonstrate that a deep network composed of such local processors seeks to maximise agreement between the active neurons, thus restricting the transmission of conflicting information to higher levels and reducing the neural activity required to process large amounts of heterogeneous real-world data. As shown to be far more effective and efficient than current forms of DL, this two-point neuron study offers a possible step-change in transforming the cellular foundations of deep network architectures. "
}