{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Neural Regression"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Histogram loss",
    "Autoregressive regression"
  ],
  "results": [
    "None"
  ],
  "paper_id": "6373036090e50fcafd0a06dd",
  "title": "Neural Regression For Scale-Varying Targets",
  "abstract": "  In this work, we demonstrate that a major limitation of regression using a mean-squared error loss is its sensitivity to the scale of its targets. This makes learning settings consisting of target's whose values take on varying scales challenging. A recently-proposed alternative loss function, known as histogram loss, avoids this issue. However, its computational cost grows linearly with the number of buckets in the histogram, which renders prediction with real-valued targets intractable. To address this issue, we propose a novel approach to training deep learning models on real-valued regression targets, autoregressive regression, which learns a high-fidelity distribution by utilizing an autoregressive target decomposition. We demonstrate that this training objective allows us to solve regression tasks involving targets with different scales. "
}