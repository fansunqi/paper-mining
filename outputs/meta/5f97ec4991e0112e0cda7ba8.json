{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Event Coreference Resolution"
  ],
  "datasets": [
    "cross-document event coreference benchmarks",
    "within-document event coreference benchmarks"
  ],
  "methods": [
    "Pairwise Representation Learning (PairwiseRL)",
    "jointly encode a pair of text snippets",
    "structured representation of text snippet"
  ],
  "results": [
    "PairwiseRL outperforms prior state-of-the-art event coreference systems"
  ],
  "paper_id": "5f97ec4991e0112e0cda7ba8",
  "title": "Pairwise Representation Learning for Event Coreference",
  "abstract": "  Natural Language Processing tasks such as resolving the coreference of events require understanding the relations between two text snippets. These tasks are typically formulated as (binary) classification problems over independently induced representations of the text snippets. In this work, we develop a Pairwise Representation Learning (PairwiseRL) scheme for the event mention pairs, in which we jointly encode a pair of text snippets so that the representation of each mention in the pair is induced in the context of the other one. Furthermore, our representation supports a finer, structured representation of the text snippet to facilitate encoding events and their arguments. We show that PairwiseRL, despite its simplicity, outperforms the prior state-of-the-art event coreference systems on both cross-document and within-document event coreference benchmarks. We also conduct in-depth analysis in terms of the improvement and the limitation of pairwise representation so as to provide insights for future work. "
}