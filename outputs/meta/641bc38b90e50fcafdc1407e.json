{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Domain Generalization"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Dual-Contrastive Learning (DCL)",
    "Causal Fusion Attention (CFA)",
    "Similarity-based Hard-pair Mining (SHM)"
  ],
  "results": [
    "Outperforms state-of-the-art algorithms on three DG datasets",
    "Can serve as a plug-and-play module without usage of domain labels"
  ],
  "paper_id": "641bc38b90e50fcafdc1407e",
  "title": "Causality-based Dual-Contrastive Learning Framework for Domain\n  Generalization",
  "abstract": "  Domain Generalization (DG) is essentially a sub-branch of out-of-distribution generalization, which trains models from multiple source domains and generalizes to unseen target domains. Recently, some domain generalization algorithms have emerged, but most of them were designed with non-transferable complex architecture. Additionally, contrastive learning has become a promising solution for simplicity and efficiency in DG. However, existing contrastive learning neglected domain shifts that caused severe model confusions. In this paper, we propose a Dual-Contrastive Learning (DCL) module on feature and prototype contrast. Moreover, we design a novel Causal Fusion Attention (CFA) module to fuse diverse views of a single image to attain prototype. Furthermore, we introduce a Similarity-based Hard-pair Mining (SHM) strategy to leverage information on diversity shift. Extensive experiments show that our method outperforms state-of-the-art algorithms on three DG datasets. The proposed algorithm can also serve as a plug-and-play module without usage of domain labels. "
}