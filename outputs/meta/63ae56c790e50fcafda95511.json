{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Semantic segmentation",
    "Emergency response during catastrophic events"
  ],
  "datasets": [
    "Flood-Net"
  ],
  "methods": [
    "Real-time UNet based model",
    "Deployed on Jetson AGX Xavier module"
  ],
  "results": [
    "Comparing performance of real-time vs. non-real-time semantic segmentation models",
    "Benchmarking on special classes like flooded buildings vs. non-flooded buildings"
  ],
  "paper_id": "63ae56c790e50fcafda95511",
  "title": "Efficient Semantic Segmentation on Edge Devices",
  "abstract": "  Semantic segmentation works on the computer vision algorithm for assigning each pixel of an image into a class. The task of semantic segmentation should be performed with both accuracy and efficiency. Most of the existing deep FCNs yield to heavy computations and these networks are very power hungry, unsuitable for real-time applications on portable devices. This project analyzes current semantic segmentation models to explore the feasibility of applying these models for emergency response during catastrophic events. We compare the performance of real-time semantic segmentation models with non-real-time counterparts constrained by aerial images under oppositional settings. Furthermore, we train several models on the Flood-Net dataset, containing UAV images captured after Hurricane Harvey, and benchmark their execution on special classes such as flooded buildings vs. non-flooded buildings or flooded roads vs. non-flooded roads. In this project, we developed a real-time UNet based model and deployed that network on Jetson AGX Xavier module. "
}