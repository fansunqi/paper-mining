{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Revisiting actor-critic algorithm"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Two time-scale stochastic approximation",
    "Value function on faster time-scale",
    "Policy on slower time-scale",
    "Critic-actor algorithm"
  ],
  "results": [
    "Critic-actor algorithm performs on par with actor-critic in terms of accuracy and computational effort"
  ],
  "paper_id": "6344dede90e50fcafd24d32c",
  "title": "Actor-Critic or Critic-Actor? A Tale of Two Time Scales",
  "abstract": "  We revisit the standard formulation of tabular actor-critic algorithm as a two time-scale stochastic approximation with value function computed on a faster time-scale and policy computed on a slower time-scale. This emulates policy iteration. We begin by observing that reversal of the time scales will in fact emulate value iteration and is a legitimate algorithm. We provide a proof of convergence and compare the two empirically with and without function approximation (with both linear and nonlinear function approximators) and observe that our proposed critic-actor algorithm performs on par with actor-critic in terms of both accuracy and computational effort. "
}