{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Understanding deep neural networks' behavior",
    "Enhancing the explainability of DNNs"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Negative Flux Aggregation (NeFLAG)",
    "Divergence and flux"
  ],
  "results": [
    "Superior performance in generating more faithful attribution maps than the competing methods"
  ],
  "paper_id": "63c8b59590e50fcafd90b8aa",
  "title": "Negative Flux Aggregation to Estimate Feature Attributions",
  "abstract": "  There are increasing demands for understanding deep neural networks' (DNNs) behavior spurred by growing security and/or transparency concerns. Due to multi-layer nonlinearity of the deep neural network architectures, explaining DNN predictions still remains as an open problem, preventing us from gaining a deeper understanding of the mechanisms. To enhance the explainability of DNNs, we estimate the input feature's attributions to the prediction task using divergence and flux. Inspired by the divergence theorem in vector analysis, we develop a novel Negative Flux Aggregation (NeFLAG) formulation and an efficient approximation algorithm to estimate attribution map. Unlike the previous techniques, ours doesn't rely on fitting a surrogate model nor need any path integration of gradients. Both qualitative and quantitative experiments demonstrate a superior performance of NeFLAG in generating more faithful attribution maps than the competing methods. "
}