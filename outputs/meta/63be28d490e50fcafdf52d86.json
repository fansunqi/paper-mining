{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Convex/concave min-max problems"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Clairvoyant Extra Gradient",
    "Proximal Point method",
    "Contraction Maps"
  ],
  "results": [
    "Near-optimal convergence rates",
    "Near-optimal time-average convergence for general domains",
    "Last-iterate convergence in the unconstrained case"
  ],
  "paper_id": "63be28d490e50fcafdf52d86",
  "title": "Min-Max Optimization Made Simple: Approximating the Proximal Point\n  Method via Contraction Maps",
  "abstract": "  In this paper we present a first-order method that admits near-optimal convergence rates for convex/concave min-max problems while requiring a simple and intuitive analysis. Similarly to the seminal work of Nemirovski and the recent approach of Piliouras et al. in normal form games, our work is based on the fact that the update rule of the Proximal Point method (PP) can be approximated up to accuracy $\\epsilon$ with only $O(\\log 1/\\epsilon)$ additional gradient-calls through the iterations of a contraction map. Then combining the analysis of (PP) method with an error-propagation analysis we establish that the resulting first order method, called Clairvoyant Extra Gradient, admits near-optimal time-average convergence for general domains and last-iterate convergence in the unconstrained case. "
}