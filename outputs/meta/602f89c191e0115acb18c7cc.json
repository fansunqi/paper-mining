{
  "code_links": "None",
  "tasks": [
    "\u7814\u7a76\u7ef3\u5b50\u5728\u6a21\u4eff\u5b66\u4e60\u4e2d\u7684\u8fd0\u7528"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "\u5bf9\u7ef3\u5b50\u8fdb\u884c\u5206\u7c7b\uff0c\u5e76\u5206\u6790\u5176\u7279\u70b9"
  ],
  "results": [
    "\u53d1\u73b0\u7ef3\u5b50\u7684\u79cd\u7c7b\u548c\u7279\u70b9\u5bf9\u6a21\u4eff\u5b66\u4e60\u7684\u6548\u679c\u6709\u663e\u8457\u5f71\u54cd"
  ],
  "paper_id": "602f89c191e0115acb18c7cc",
  "title": "On the Sample Complexity of Stability Constrained Imitation Learning",
  "abstract": "  We study the following question in the context of imitation learning for continuous control: how are the underlying stability properties of an expert policy reflected in the sample-complexity of an imitation learning task? We provide the first results showing that a surprisingly granular connection can be made between the underlying expert system's incremental gain stability, a novel measure of robust convergence between pairs of system trajectories, and the dependency on the task horizon $T$ of the resulting generalization bounds. In particular, we propose and analyze incremental gain stability constrained versions of behavior cloning and a DAgger-like algorithm, and show that the resulting sample-complexity bounds naturally reflect the underlying stability properties of the expert system. As a special case, we delineate a class of systems for which the number of trajectories needed to achieve $\\varepsilon$-suboptimality is sublinear in the task horizon $T$, and do so without requiring (strong) convexity of the loss function in the policy parameters. Finally, we conduct numerical experiments demonstrating the validity of our insights on both a simple nonlinear system for which the underlying stability properties can be easily tuned, and on a high-dimensional quadrupedal robotic simulation. "
}