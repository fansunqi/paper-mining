{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Stochastic Online Convex Optimization",
    "Probabilistic Time Series Forecasting"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Online Newton Steps",
    "Scale-Free Bernstein Online Aggregation"
  ],
  "results": [
    "Fast-rate stochastic regret bounds",
    "Any-time valid bounds under stochastic exp-concavity assumption"
  ],
  "paper_id": "6019342a91e0110e3bb2bf0c",
  "title": "Stochastic Online Convex Optimization. Application to probabilistic time\n  series forecasting",
  "abstract": "  We introduce a general framework of stochastic online convex optimization to obtain fast-rate stochastic regret bounds. We prove that algorithms such as online newton steps and a scale-free 10 version of Bernstein online aggregation achieve best-known rates in unbounded stochastic settings. We apply our approach to calibrate parametric probabilistic forecasters of non-stationary sub-gaussian time series. Our fast-rate stochastic regret bounds are any-time valid. Our proofs combine self-bounded and Poissonnian inequalities for martingales and sub-gaussian random variables, respectively, under a stochastic exp-concavity assumption. "
}