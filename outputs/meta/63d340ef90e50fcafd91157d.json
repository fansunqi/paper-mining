{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Causal Reasoning of Entities and Events"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "CREPE",
    "Programming language representation",
    "Code-based prompting",
    "Chain-of-thought prompting"
  ],
  "results": [
    "F1 score: .35 (language models)",
    "F1 score: .59 (code-based prompting)",
    "F1 score: .67 (intermediate reasoning steps)"
  ],
  "paper_id": "63d340ef90e50fcafd91157d",
  "title": "Causal Reasoning of Entities and Events in Procedural Texts",
  "abstract": "  Entities and events are crucial to natural language reasoning and common in procedural texts. Existing work has focused either exclusively on entity state tracking (e.g., whether a pan is hot) or on event reasoning (e.g., whether one would burn themselves by touching the pan), while these two tasks are often causally related. We propose CREPE, the first benchmark on causal reasoning of event plausibility and entity states. We show that most language models, including GPT-3, perform close to chance at .35 F1, lagging far behind human at .87 F1. We boost model performance to .59 F1 by creatively representing events as programming languages while prompting language models pretrained on code. By injecting the causal relations between entities and events as intermediate reasoning steps in our representation, we further boost the performance to .67 F1. Our findings indicate not only the challenge that CREPE brings for language models, but also the efficacy of code-like prompting combined with chain-of-thought prompting for multihop event reasoning. "
}