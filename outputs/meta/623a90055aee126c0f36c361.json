{
  "code_links": [
    "https://github.com/JC-202/CAGNN"
  ],
  "tasks": [
    "Graph node classification"
  ],
  "datasets": [
    "nine well-known benchmark datasets"
  ],
  "methods": [
    "Conv-Agnostic GNN framework (CAGNNs)",
    "von Neumann entropy metric",
    "shared mixer module for neighbor effect evaluation"
  ],
  "results": [
    "average performance gain of 9.81% compared with GIN",
    "average performance gain of 25.81% compared with GAT",
    "average performance gain of 20.61% compared with GCN",
    "significant improvement on heterophily graphs"
  ],
  "paper_id": "623a90055aee126c0f36c361",
  "title": "Exploiting Neighbor Effect: Conv-Agnostic GNNs Framework for Graphs with\n  Heterophily",
  "abstract": "  Due to the homophily assumption in graph convolution networks (GNNs), a common consensus in the graph node classification task is that GNNs perform well on homophilic graphs but may fail on heterophilic graphs with many inter-class edges. However, the previous inter-class edges perspective and related homo-ratio metrics cannot well explain the GNNs performance under some heterophilic datasets, which implies that not all the inter-class edges are harmful to GNNs. In this work, we propose a new metric based on von Neumann entropy to re-examine the heterophily problem of GNNs and investigate the feature aggregation of inter-class edges from an entire neighbor identifiable perspective. Moreover, we propose a simple yet effective Conv-Agnostic GNN framework (CAGNNs) to enhance the performance of most GNNs on heterophily datasets by learning the neighbor effect for each node. Specifically, we first decouple the feature of each node into the discriminative feature for downstream tasks and the aggregation feature for graph convolution. Then, we propose a shared mixer module to adaptively evaluate the neighbor effect of each node to incorporate the neighbor information. The proposed framework can be regarded as a plug-in component and is compatible with most GNNs. The experimental results over nine well-known benchmark datasets indicate that our framework can significantly improve performance, especially for the heterophily graphs. The average performance gain is 9.81%, 25.81%, and 20.61% compared with GIN, GAT, and GCN, respectively. Extensive ablation studies and robustness analysis further verify the effectiveness, robustness, and interpretability of our framework. Code is available at https://github.com/JC-202/CAGNN. "
}