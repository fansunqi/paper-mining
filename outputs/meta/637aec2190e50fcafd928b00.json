{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Dysphonic Voice Detection"
  ],
  "datasets": [
    "clean and three variations of deteriorated in-corpus and cross-corpus datasets"
  ],
  "methods": [
    "Deep learning framework",
    "Contrastive loss",
    "Classification loss",
    "Data warping methods"
  ],
  "results": [
    "High in-corpus and cross-corpus classification accuracy",
    "Good embeddings sensitive to voice quality",
    "Robust across different corpora",
    "Outperforms baseline methods"
  ],
  "paper_id": "637aec2190e50fcafd928b00",
  "title": "Robust Vocal Quality Feature Embeddings for Dysphonic Voice Detection",
  "abstract": "  Approximately 1.2% of the world's population has impaired voice production. As a result, automatic dysphonic voice detection has attracted considerable academic and clinical interest. However, existing methods for automated voice assessment often fail to generalize outside the training conditions or to other related applications. In this paper, we propose a deep learning framework for generating acoustic feature embeddings sensitive to vocal quality and robust across different corpora. A contrastive loss is combined with a classification loss to train our deep learning model jointly. Data warping methods are used on input voice samples to improve the robustness of our method. Empirical results demonstrate that our method not only achieves high in-corpus and cross-corpus classification accuracy but also generates good embeddings sensitive to voice quality and robust across different corpora. We also compare our results against three baseline methods on clean and three variations of deteriorated in-corpus and cross-corpus datasets and demonstrate that the proposed model consistently outperforms the baseline methods. "
}