{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Human-like Autonomous Driving"
  ],
  "datasets": [
    "Real-world urban driving dataset"
  ],
  "methods": [
    "Predictive behavior planning framework",
    "Behavior generation module",
    "Conditional motion prediction network",
    "Scoring module using maximum entropy inverse reinforcement learning (IRL)"
  ],
  "results": [
    "Conditional prediction model predicts distinct and reasonable future trajectories",
    "IRL-based scoring module selects plans close to human driving",
    "Framework outperforms baseline methods in similarity to human driving trajectories",
    "Conditional prediction model improves prediction and planning performance",
    "Learning scoring module crucial for aligning evaluations with human drivers"
  ],
  "paper_id": "63a1750e90e50fcafd1f3d36",
  "title": "Conditional Predictive Behavior Planning with Inverse Reinforcement\n  Learning for Human-like Autonomous Driving",
  "abstract": "  Making safe and human-like decisions is an essential capability of autonomous driving systems, and learning-based behavior planning presents a promising pathway toward achieving this objective. Distinguished from existing learning-based methods that directly output decisions, this work introduces a predictive behavior planning framework that learns to predict and evaluate from human driving data. This framework consists of three components: a behavior generation module that produces a diverse set of candidate behaviors in the form of trajectory proposals, a conditional motion prediction network that predicts future trajectories of other agents based on each proposal, and a scoring module that evaluates the candidate plans using maximum entropy inverse reinforcement learning (IRL). We validate the proposed framework on a large-scale real-world urban driving dataset through comprehensive experiments. The results show that the conditional prediction model can predict distinct and reasonable future trajectories given different trajectory proposals and the IRL-based scoring module can select plans that are close to human driving. The proposed framework outperforms other baseline methods in terms of similarity to human driving trajectories. Additionally, we find that the conditional prediction model improves both prediction and planning performance compared to the non-conditional model. Lastly, we note that learning the scoring module is crucial for aligning the evaluations with human drivers. "
}