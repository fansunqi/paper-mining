{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Neighborhood definition",
    "Graph construction"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Non-negative kernel regression (NNK)",
    "Sparse signal approximation"
  ],
  "results": [
    "Robustness of NNK for neighborhood and graph construction",
    "Adaptability to data properties",
    "Superior performance in local neighborhood and graph-based machine learning tasks"
  ],
  "paper_id": "5daed3493a55ac025c26e569",
  "title": "Neighborhood and Graph Constructions using Non-Negative Kernel\n  Regression",
  "abstract": "  Data-driven neighborhood definitions and graph constructions are often used in machine learning and signal processing applications. k-nearest neighbor~(kNN) and $\\epsilon$-neighborhood methods are among the most common methods used for neighborhood selection, due to their computational simplicity. However, the choice of parameters associated with these methods, such as k and $\\epsilon$, is still ad hoc. We make two main contributions in this paper. First, we present an alternative view of neighborhood selection, where we show that neighborhood construction is equivalent to a sparse signal approximation problem. Second, we propose an algorithm, non-negative kernel regression~(NNK), for obtaining neighborhoods that lead to better sparse representation. NNK draws similarities to the orthogonal matching pursuit approach to signal representation and possesses desirable geometric and theoretical properties. Experiments demonstrate (i) the robustness of the NNK algorithm for neighborhood and graph construction, (ii) its ability to adapt the number of neighbors to the data properties, and (iii) its superior performance in local neighborhood and graph-based machine learning tasks. "
}