{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Certified adversarial robustness for image classification",
    "Certified safety in continuous control"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Neural ODEs",
    "Forward invariance certification framework"
  ],
  "results": [
    "Superior adversarial robustness guarantees compared to prior work"
  ],
  "paper_id": "63608e5190e50fcafdee138d",
  "title": "FI-ODE: Certified and Robust Forward Invariance in Neural ODEs",
  "abstract": "  Forward invariance is a long-studied property in control theory that is used to certify that a dynamical system stays within some pre-specified set of states for all time, and also admits robustness guarantees (e.g., the certificate holds under perturbations). We propose a general framework for training and provably certifying robust forward invariance in Neural ODEs. We apply this framework in two settings: certified adversarial robustness for image classification, and certified safety in continuous control. Notably, our method empirically produces superior adversarial robustness guarantees compared to prior work on certifiably robust Neural ODEs (including implicit-depth models). "
}