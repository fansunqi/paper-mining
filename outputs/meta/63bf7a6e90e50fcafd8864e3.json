{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Video Salient Document Detection"
  ],
  "datasets": [
    "MIDV-500"
  ],
  "methods": [
    "dilated depth-wise separable convolution",
    "Approximation Rank Pooling"
  ],
  "results": [
    "outperforms state-of-the-art approaches in both time and robustness measures"
  ],
  "paper_id": "63bf7a6e90e50fcafd8864e3",
  "title": "VS-Net: Multiscale Spatiotemporal Features for Lightweight Video Salient\n  Document Detection",
  "abstract": "  Video Salient Document Detection (VSDD) is an essential task of practical computer vision, which aims to highlight visually salient document regions in video frames. Previous techniques for VSDD focus on learning features without considering the cooperation among and across the appearance and motion cues and thus fail to perform in practical scenarios. Moreover, most of the previous techniques demand high computational resources, which limits the usage of such systems in resource-constrained settings. To handle these issues, we propose VS-Net, which captures multi-scale spatiotemporal information with the help of dilated depth-wise separable convolution and Approximation Rank Pooling. VS-Net extracts the key features locally from each frame across embedding sub-spaces and forwards the features between adjacent and parallel nodes, enhancing model performance globally. Our model generates saliency maps considering both the background and foreground simultaneously, making it perform better in challenging scenarios. The immense experiments regulated on the benchmark MIDV-500 dataset show that the VS-Net model outperforms state-of-the-art approaches in both time and robustness measures. "
}