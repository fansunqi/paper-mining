{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Forecasting cryptocurrency returns"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "BERT classifiers",
    "Weak supervision"
  ],
  "results": [
    "Finetuning using weak labels enhances predictive value of text-based features",
    "Raises forecast accuracy in predicting cryptocurrency returns"
  ],
  "paper_id": "62563f8a5aee126c0f6f3d44",
  "title": "Forecasting Cryptocurrency Returns from Sentiment Signals: An Analysis\n  of BERT Classifiers and Weak Supervision",
  "abstract": "  Anticipating price developments in financial markets is a topic of continued interest in forecasting. Funneled by advancements in deep learning and natural language processing (NLP) together with the availability of vast amounts of textual data in form of news articles, social media postings, etc., an increasing number of studies incorporate text-based predictors in forecasting models. We contribute to this literature by introducing weak learning, a recently proposed NLP approach to address the problem that text data is unlabeled. Without a dependent variable, it is not possible to finetune pretrained NLP models on a custom corpus. We confirm that finetuning using weak labels enhances the predictive value of text-based features and raises forecast accuracy in the context of predicting cryptocurrency returns. More fundamentally, the modeling paradigm we present, weak labeling domain-specific text and finetuning pretrained NLP models, is universally applicable in (financial) forecasting and unlocks new ways to leverage text data. "
}