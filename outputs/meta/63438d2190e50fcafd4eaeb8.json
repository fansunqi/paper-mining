{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Semantic Parsing"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Seq2seq models",
    "Fertility step",
    "Reordering step"
  ],
  "results": [
    "Outperforms seq2seq models on compositional splits",
    "Favourable comparison to other compositional generalisation models"
  ],
  "paper_id": "63438d2190e50fcafd4eaeb8",
  "title": "Compositional Generalisation with Structured Reordering and Fertility\n  Layers",
  "abstract": "  Seq2seq models have been shown to struggle with compositional generalisation, i.e. generalising to new and potentially more complex structures than seen during training. Taking inspiration from grammar-based models that excel at compositional generalisation, we present a flexible end-to-end differentiable neural model that composes two structural operations: a fertility step, which we introduce in this work, and a reordering step based on previous work (Wang et al., 2021). To ensure differentiability, we use the expected value of each step. Our model outperforms seq2seq models by a wide margin on challenging compositional splits of realistic semantic parsing tasks that require generalisation to longer examples. It also compares favourably to other models targeting compositional generalisation. "
}