{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Exploiting domain knowledge in NLP",
    "Improving interpretability of NLP models"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Memory enhancement of transformer models using unstructured knowledge",
    "Natural language explanations"
  ],
  "results": [
    "Produces relevant explanations without losing in performance"
  ],
  "paper_id": "615a709c5244ab9dcb3a7138",
  "title": "Combining Transformers with Natural Language Explanations",
  "abstract": "  Transformers changed modern NLP in many ways. However, like many other neural architectures, they are still weak on exploiting domain knowledge and on interpretability. Unfortunately, the exploitation of external, structured knowledge is notoriously prone to a knowledge acquisition bottleneck. We thus propose a memory enhancement of transformer models that makes use of unstructured knowledge. That, expressed in plain text, can be used to carry out classification tasks and as a source of explanations for the model output. An experimental evaluation conducted on two challenging datasets demonstrates that our approach produces relevant explanations without losing in performance. "
}