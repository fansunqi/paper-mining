{
  "code_links": [
    "https://github.com/Coder-Yu/SELFRec"
  ],
  "tasks": [
    "Recommendation"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "XSimGCL",
    "Contrastive learning",
    "Noise-based embedding augmentation"
  ],
  "results": [
    "Outperforms graph augmentation-based counterparts",
    "Smoothly adjusts the uniformity of learned representations",
    "Improves recommendation accuracy and training efficiency"
  ],
  "paper_id": "63180bf590e50fcafded784e",
  "title": "XSimGCL: Towards Extremely Simple Graph Contrastive Learning for\n  Recommendation",
  "abstract": "  Contrastive learning (CL) has recently been demonstrated critical in improving recommendation performance. The underlying principle of CL-based recommendation models is to ensure the consistency between representations derived from different graph augmentations of the user-item bipartite graph. This self-supervised approach allows for the extraction of general features from raw data, thereby mitigating the issue of data sparsity. Despite the effectiveness of this paradigm, the factors contributing to its performance gains have yet to be fully understood. This paper provides novel insights into the impact of CL on recommendation. Our findings indicate that CL enables the model to learn more evenly distributed user and item representations, which alleviates the prevalent popularity bias and promoting long-tail items. Our analysis also suggests that the graph augmentations, previously considered essential, are relatively unreliable and of limited significance in CL-based recommendation. Based on these findings, we put forward an eXtremely Simple Graph Contrastive Learning method (XSimGCL) for recommendation, which discards the ineffective graph augmentations and instead employs a simple yet effective noise-based embedding augmentation to generate views for CL. A comprehensive experimental study on four large and highly sparse benchmark datasets demonstrates that, though the proposed method is extremely simple, it can smoothly adjust the uniformity of learned representations and outperforms its graph augmentation-based counterparts by a large margin in both recommendation accuracy and training efficiency. The code and used datasets are released at https://github.com/Coder-Yu/SELFRec. "
}