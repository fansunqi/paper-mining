{
  "code_links": [
    "https://github.com/liuzywen/RGBTCC"
  ],
  "tasks": [
    "Crowd counting"
  ],
  "datasets": [
    "RGBT-CC"
  ],
  "methods": [
    "Transformer",
    "count-guided multi-modal fusion",
    "modal-guided count enhancement"
  ],
  "results": [
    "Refreshes state-of-the-art results on RGBT-CC dataset"
  ],
  "paper_id": "63bcd73690e50fcafdefa0e0",
  "title": "RGB-T Multi-Modal Crowd Counting Based on Transformer",
  "abstract": "  Crowd counting aims to estimate the number of persons in a scene. Most state-of-the-art crowd counting methods based on color images can't work well in poor illumination conditions due to invisible objects. With the widespread use of infrared cameras, crowd counting based on color and thermal images is studied. Existing methods only achieve multi-modal fusion without count objective constraint. To better excavate multi-modal information, we use count-guided multi-modal fusion and modal-guided count enhancement to achieve the impressive performance. The proposed count-guided multi-modal fusion module utilizes a multi-scale token transformer to interact two-modal information under the guidance of count information and perceive different scales from the token perspective. The proposed modal-guided count enhancement module employs multi-scale deformable transformer decoder structure to enhance one modality feature and count information by the other modality. Experiment in public RGBT-CC dataset shows that our method refreshes the state-of-the-art results. https://github.com/liuzywen/RGBTCC "
}