{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Deep dictionary learning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Variational autoencoder-based nonnegative matrix factorisation"
  ],
  "results": [
    "VAE-NMF performs better in learning the latent nonnegative dictionaries compared with state-of-the-art methods"
  ],
  "paper_id": "63c8b59590e50fcafd90ba83",
  "title": "A variational autoencoder-based nonnegative matrix factorisation model\n  for deep dictionary learning",
  "abstract": "  Construction of dictionaries using nonnegative matrix factorisation (NMF) has extensive applications in signal processing and machine learning. With the advances in deep learning, training compact and robust dictionaries using deep neural networks, i.e., dictionaries of deep features, has been proposed. In this study, we propose a probabilistic generative model which employs a variational autoencoder (VAE) to perform nonnegative dictionary learning. In contrast to the existing VAE models, we cast the model under a statistical framework with latent variables obeying a Gamma distribution and design a new loss function to guarantee the nonnegative dictionaries. We adopt an acceptance-rejection sampling reparameterization trick to update the latent variables iteratively. We apply the dictionaries learned from VAE-NMF to two signal processing tasks, i.e., enhancement of speech and extraction of muscle synergies. Experimental results demonstrate that VAE-NMF performs better in learning the latent nonnegative dictionaries in comparison with state-of-the-art methods. "
}