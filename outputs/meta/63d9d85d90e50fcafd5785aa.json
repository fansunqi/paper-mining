{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Machine translation quality estimation (QE)"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Metric estimation (ME)"
  ],
  "results": [
    "$\rho$=60% for BLEU",
    "$\rho$=51% for other metrics",
    "$\rho$=23% for TER pre-training",
    "$\rho$=20% for scratch training"
  ],
  "paper_id": "63d9d85d90e50fcafd5785aa",
  "title": "Poor Man's Quality Estimation: Predicting Reference-Based MT Metrics\n  Without the Reference",
  "abstract": "  Machine translation quality estimation (QE) predicts human judgements of a translation hypothesis without seeing the reference. State-of-the-art QE systems based on pretrained language models have been achieving remarkable correlations with human judgements yet they are computationally heavy and require human annotations, which are slow and expensive to create. To address these limitations, we define the problem of metric estimation (ME) where one predicts the automated metric scores also without the reference. We show that even without access to the reference, our model can estimate automated metrics ($\\rho$=60% for BLEU, $\\rho$=51% for other metrics) at the sentence-level. Because automated metrics correlate with human judgements, we can leverage the ME task for pre-training a QE model. For the QE task, we find that pre-training on TER is better ($\\rho$=23%) than training for scratch ($\\rho$=20%). "
}