{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Spatially-Varying Multiframe Blind Deconvolution",
    "Imaging Through Turbulence"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "TurbuGAN",
    "Adversarial Sensing Framework",
    "Discriminator Network",
    "Pretrained Generative Networks"
  ],
  "results": [
    "Self-supervised and self-calibrating",
    "No paired training data required",
    "Adapts to turbulence distribution",
    "Generalizes from tens to thousands of measurements",
    "Validated on simulated and experimentally captured images"
  ],
  "paper_id": "623004315aee126c0f9b3872",
  "title": "TurbuGAN: An Adversarial Learning Approach to Spatially-Varying\n  Multiframe Blind Deconvolution with Applications to Imaging Through\n  Turbulence",
  "abstract": "  We present a self-supervised and self-calibrating multi-shot approach to imaging through atmospheric turbulence, called TurbuGAN. Our approach requires no paired training data, adapts itself to the distribution of the turbulence, leverages domain-specific data priors, and can generalize from tens to thousands of measurements. We achieve such functionality through an adversarial sensing framework adapted from CryoGAN, which uses a discriminator network to match the distributions of captured and simulated measurements. Our framework builds on CryoGAN by (1) generalizing the forward measurement model to incorporate physically accurate and computationally efficient models for light propagation through anisoplanatic turbulence, (2) enabling adaptation to slightly misspecified forward models, and (3) leveraging domain-specific prior knowledge using pretrained generative networks, when available. We validate TurbuGAN on both computationally simulated and experimentally captured images distorted with anisoplanatic turbulence. "
}