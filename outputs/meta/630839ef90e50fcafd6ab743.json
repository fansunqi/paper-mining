{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Spiking neural networks",
    "Hardware reservoir computing for human-computer interaction"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Neuron module",
    "Synapse module",
    "Weight modules",
    "Inverter-based comparator",
    "Leakage current-driven design"
  ],
  "results": [
    "Area of 127 \u03bcm\u00b2 for neuron and 231 \u03bcm\u00b2 for synapse",
    "Millisecond time constants",
    "Temporal signal communication function",
    "Learning function demonstration"
  ],
  "paper_id": "630839ef90e50fcafd6ab743",
  "title": "CMOS-based area-and-power-efficient neuron and synapse circuits for\n  time-domain analog spiking neural networks",
  "abstract": "  Conventional neural structures tend to communicate through analog quantities such as currents or voltages, however, as CMOS devices shrink and supply voltages decrease, the dynamic range of voltage/current-domain analog circuits becomes narrower, the available margin becomes smaller, and noise immunity decreases. More than that, the use of operational amplifiers (op-amps) and continuous-time or clocked comparators in conventional designs leads to high energy consumption and large chip area, which would be detrimental to building spiking neural networks. In view of this, we propose a neural structure for generating and transmitting time-domain signals, including a neuron module, a synapse module, and two weight modules. The proposed neural structure is driven by a leakage current of MOS transistors and uses an inverter-based comparator to realize a firing function, thus providing higher energy and area efficiency compared to conventional designs. The proposed neural structure is fabricated using TSMC 65 nm CMOS technology. The proposed neuron and synapse occupy the area of 127 {\\mu}m^{ 2} and 231 {\\mu}m^{ 2}, respectively, while achieving millisecond time constants. Actual chip measurements show that the proposed structure implements the temporal signal communication function with millisecond time constants, which is a critical step toward hardware reservoir computing for human-computer interaction. Simulation results of the spiking-neural network for reservoir computing with the behavioral model of the proposed neural structure demonstrate the learning function. "
}