{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Explainable AI",
    "Counterfactual Explanations"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Stochastic learning-based framework",
    "Generation and feature selection module"
  ],
  "results": [
    "Actionable and plausible counterfactuals",
    "More diverse than existing methods",
    "More efficient than closest baselines"
  ],
  "paper_id": "6333bb7e90e50fcafdb4c4a7",
  "title": "Stochastic Optimization for Counterfactual Explanations",
  "abstract": "  Explainable AI offers insights into what factors drive a certain prediction of a black-box AI system. One popular interpreting approach is through counterfactual explanations, which go beyond why a system arrives at a certain decision to further provide suggestions on what a user can do to alter the original outcome. A counterfactual example must possess plenty of desiderata. These constraints exist at trade-offs between one and another presenting radical challenges to existing works. We here propose a stochastic learning-based framework that effectively balances the counterfactual trade-offs. The framework consists of a generation and a feature selection module with complementary roles: the former aims to model the distribution of valid counterfactuals whereas the latter serves to enforce additional constraints in a way that allows for differentiable training and amortized optimization. We demonstrate the effectiveness of our method in generating actionable and plausible counterfactuals that are more diverse than the existing methods and particularly more efficient than closest baselines. "
}