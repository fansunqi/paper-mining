{
  "code_links": [
    "https://github.com/AI-in-Hospitals/Patient-Instructions"
  ],
  "tasks": [
    "Generating Accurate and Faithful Discharge Instructions"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Re3Writer"
  ],
  "results": [
    "BLEU-4: up to 20% improvement",
    "ROUGE-L: up to 11% improvement",
    "METEOR: up to 19% improvement"
  ],
  "paper_id": "635753cc90e50fcafdddde19",
  "title": "Generating Accurate and Faithful Discharge Instructions: Task, Dataset,\n  and Model",
  "abstract": "  The \"Patient Instruction\" (PI), known as \"Discharge Instruction\", which contains critical instructional information provided both to carers and to the patient at the time of discharge, is essential for the patient to manage their condition outside hospital. An accurate and easy-to-follow PI can improve the self-management of patients which can in turn reduce hospital readmission rates. However, writing an appropriate PI can be extremely time-consuming for physicians, and is subject to being incomplete or error-prone for (potentially overworked) physicians. Therefore, we propose a new task that can provide an objective means of avoiding incompleteness, while reducing clinical workload: the automatic generation of the PI, which is imagined as being a document that the clinician can review, modify, and approve as necessary (rather than taking the human \"out of the loop\"). We build a benchmark clinical dataset and propose the Re3Writer, which imitates the working patterns of physicians to first retrieve related working experience from historical PIs written by physicians, then reason related medical knowledge. Finally, it refines the retrieved working experience and reasoned medical knowledge to extract useful information, which is used to generate the PI for previously-unseen patient according to their health records during hospitalization. Our experiments show that, using our method, the performance of five different models can be substantially boosted across all metrics, with up to 20%, 11%, and 19% relative improvements in BLEU-4, ROUGE-L, and METEOR, respectively. Meanwhile, we show results from human evaluations to measure the effectiveness in terms of its usefulness for clinical practice. The code is available at https://github.com/AI-in-Hospitals/Patient-Instructions "
}