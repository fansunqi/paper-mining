{
  "code_links": [
    "None"
  ],
  "tasks": [
    "3D Detection",
    "Unsupervised Multi-Target Domain Adaptation"
  ],
  "datasets": [
    "public datasets",
    "novel high-resolution lidar"
  ],
  "methods": [
    "SEE framework",
    "geometry interpolation",
    "scan pattern normalization"
  ],
  "results": [
    "state-of-the-art results",
    "industry applications demonstrated"
  ],
  "paper_id": "619715f95244ab9dcb18552e",
  "title": "See Eye to Eye: A Lidar-Agnostic 3D Detection Framework for Unsupervised\n  Multi-Target Domain Adaptation",
  "abstract": "  Sampling discrepancies between different manufacturers and models of lidar sensors result in inconsistent representations of objects. This leads to performance degradation when 3D detectors trained for one lidar are tested on other types of lidars. Remarkable progress in lidar manufacturing has brought about advances in mechanical, solid-state, and recently, adjustable scan pattern lidars. For the latter, existing works often require fine-tuning the model each time scan patterns are adjusted, which is infeasible. We explicitly deal with the sampling discrepancy by proposing a novel unsupervised multi-target domain adaptation framework, SEE, for transferring the performance of state-of-the-art 3D detectors across both fixed and flexible scan pattern lidars without requiring fine-tuning of models by end-users. Our approach interpolates the underlying geometry and normalizes the scan pattern of objects from different lidars before passing them to the detection network. We demonstrate the effectiveness of SEE on public datasets, achieving state-of-the-art results, and additionally provide quantitative results on a novel high-resolution lidar to prove the industry applications of our framework. "
}