{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Graph Neural Networks Explanation"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "EiX-GNN",
    "explainee concept assimibility"
  ],
  "results": [
    "Strong results in fairness and compactness"
  ],
  "paper_id": "62a165475aee126c0f509a94",
  "title": "EiX-GNN : Concept-level eigencentrality explainer for graph neural\n  networks",
  "abstract": "  Nowadays, deep prediction models, especially graph neural networks, have a majorplace in critical applications. In such context, those models need to be highlyinterpretable or being explainable by humans, and at the societal scope, this understandingmay also be feasible for humans that do not have a strong prior knowledgein models and contexts that need to be explained. In the literature, explainingis a human knowledge transfer process regarding a phenomenon between an explainerand an explainee. We propose EiX-GNN (Eigencentrality eXplainer forGraph Neural Networks) a new powerful method for explaining graph neural networksthat encodes computationally this social explainer-to-explainee dependenceunderlying in the explanation process. To handle this dependency, we introducethe notion of explainee concept assimibility which allows explainer to adapt itsexplanation to explainee background or expectation. We lead a qualitative studyto illustrate our explainee concept assimibility notion on real-world data as wellas a qualitative study that compares, according to objective metrics established inthe literature, fairness and compactness of our method with respect to performingstate-of-the-art methods. It turns out that our method achieves strong results inboth aspects. "
}