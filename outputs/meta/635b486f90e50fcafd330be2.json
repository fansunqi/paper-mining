{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Audio inverse problems"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "CQT-Diff",
    "Neural diffusion model",
    "Constant-Q Transform"
  ],
  "results": [
    "Outperforms compared baselines in audio bandwidth extension",
    "Competitive performance against modern baselines in audio inpainting and declipping"
  ],
  "paper_id": "635b486f90e50fcafd330be2",
  "title": "Solving Audio Inverse Problems with a Diffusion Model",
  "abstract": "  This paper presents CQT-Diff, a data-driven generative audio model that can, once trained, be used for solving various different audio inverse problems in a problem-agnostic setting. CQT-Diff is a neural diffusion model with an architecture that is carefully constructed to exploit pitch-equivariant symmetries in music. This is achieved by preconditioning the model with an invertible Constant-Q Transform (CQT), whose logarithmically-spaced frequency axis represents pitch equivariance as translation equivariance. The proposed method is evaluated with objective and subjective metrics in three different and varied tasks: audio bandwidth extension, inpainting, and declipping. The results show that CQT-Diff outperforms the compared baselines and ablations in audio bandwidth extension and, without retraining, delivers competitive performance against modern baselines in audio inpainting and declipping. This work represents the first diffusion-based general framework for solving inverse problems in audio processing. "
}