{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Deep Reinforcement Learning Based Production Scheduling"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "schlably: A Python Framework"
  ],
  "results": [
    "None"
  ],
  "paper_id": "63bf7a6990e50fcafd885a41",
  "title": "schlably: A Python Framework for Deep Reinforcement Learning Based\n  Scheduling Experiments",
  "abstract": "Research on deep reinforcement learning (DRL) based production scheduling\n(PS) has gained a lot of attention in recent years, primarily due to the high\ndemand for optimizing scheduling problems in diverse industry settings.\nNumerous studies are carried out and published as stand-alone experiments that\noften vary only slightly with respect to problem setups and solution\napproaches. The programmatic core of these experiments is typically very\nsimilar. Despite this fact, no standardized and resilient framework for\nexperimentation on PS problems with DRL algorithms could be established so far.\nIn this paper, we introduce schlably, a Python-based framework that provides\nresearchers a comprehensive toolset to facilitate the development of PS\nsolution strategies based on DRL. schlably eliminates the redundant overhead\nwork that the creation of a sturdy and flexible backbone requires and increases\nthe comparability and reusability of conducted research work."
}