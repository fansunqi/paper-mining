{
  "code_links": [
    "https://github.com/facebookresearch/amortized-optimization-tutorial"
  ],
  "tasks": [
    "Optimization in repeated problem instances"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Amortized optimization",
    "Learning to predict solutions"
  ],
  "results": [
    "Solves optimization problems many orders of magnitude faster than traditional methods"
  ],
  "paper_id": "61f9f64a5aee126c0f41f52b",
  "title": "Tutorial on amortized optimization",
  "abstract": "  Optimization is a ubiquitous modeling tool and is often deployed in settings which repeatedly solve similar instances of the same problem. Amortized optimization methods use learning to predict the solutions to problems in these settings, exploiting the shared structure between similar problem instances. These methods have been crucial in variational inference and reinforcement learning and are capable of solving optimization problems many orders of magnitudes times faster than traditional optimization methods that do not use amortization. This tutorial presents an introduction to the amortized optimization foundations behind these advancements and overviews their applications in variational inference, sparse coding, gradient-based meta-learning, control, reinforcement learning, convex optimization, optimal transport, and deep equilibrium networks. The source code for this tutorial is available at https://github.com/facebookresearch/amortized-optimization-tutorial. "
}