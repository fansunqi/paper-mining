{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Facial expression recognition in the wild"
  ],
  "datasets": [
    "AffectNet",
    "FER+",
    "RAF-DB"
  ],
  "methods": [
    "Diversifying features extracted by CNN layers",
    "Attention-based model",
    "Ensemble-based model"
  ],
  "results": [
    "State-of-the-art performance of 89.99% on RAF-DB",
    "89.34% on FER+",
    "Competitive accuracy of 60.02% on AffectNet"
  ],
  "paper_id": "634f6ae490e50fcafdcb634f",
  "title": "Learning Diversified Feature Representations for Facial Expression\n  Recognition in the Wild",
  "abstract": "  Diversity of the features extracted by deep neural networks is important for enhancing the model generalization ability and accordingly its performance in different learning tasks. Facial expression recognition in the wild has attracted interest in recent years due to the challenges existing in this area for extracting discriminative and informative features from occluded images in real-world scenarios. In this paper, we propose a mechanism to diversify the features extracted by CNN layers of state-of-the-art facial expression recognition architectures for enhancing the model capacity in learning discriminative features. To evaluate the effectiveness of the proposed approach, we incorporate this mechanism in two state-of-the-art models to (i) diversify local/global features in an attention-based model and (ii) diversify features extracted by different learners in an ensemble-based model. Experimental results on three well-known facial expression recognition in-the-wild datasets, AffectNet, FER+, and RAF-DB, show the effectiveness of our method, achieving the state-of-the-art performance of 89.99% on RAF-DB, 89.34% on FER+ and the competitive accuracy of 60.02% on AffectNet dataset. "
}