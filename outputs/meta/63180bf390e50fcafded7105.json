{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Object Detection",
    "Adversarial Attacks"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Fabricating bounding boxes for nonexistent objects"
  ],
  "results": [
    "Success rate of about 90% within about 20 iterations"
  ],
  "paper_id": "63180bf390e50fcafded7105",
  "title": "Adversarial Detection: Attacking Object Detection in Real Time",
  "abstract": "  Intelligent robots rely on object detection models to perceive the environment. Following advances in deep learning security it has been revealed that object detection models are vulnerable to adversarial attacks. However, prior research primarily focuses on attacking static images or offline videos. Therefore, it is still unclear if such attacks could jeopardize real-world robotic applications in dynamic environments. This paper bridges this gap by presenting the first real-time online attack against object detection models. We devise three attacks that fabricate bounding boxes for nonexistent objects at desired locations. The attacks achieve a success rate of about 90\\% within about 20 iterations. The demo video is available at https://youtu.be/zJZ1aNlXsMU. "
}