{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Estimating the Sizes of Binary Error-Correcting Constrained Codes"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Fourier analysis of Boolean functions",
    "Delsarte's linear program"
  ],
  "results": [
    "Explicit values or efficient algorithms for counting constrained codewords",
    "LP-based upper bounds beat the generalized sphere packing bounds"
  ],
  "paper_id": "63c0cc6490e50fcafd2a8db4",
  "title": "Estimating the Sizes of Binary Error-Correcting Constrained Codes",
  "abstract": "  In this paper, we study binary constrained codes that are resilient to bit-flip errors and erasures. In our first approach, we compute the sizes of constrained subcodes of linear codes. Since there exist well-known linear codes that achieve vanishing probabilities of error over the binary symmetric channel (which causes bit-flip errors) and the binary erasure channel, constrained subcodes of such linear codes are also resilient to random bit-flip errors and erasures. We employ a simple identity from the Fourier analysis of Boolean functions, which transforms the problem of counting constrained codewords of linear codes to a question about the structure of the dual code. We illustrate the utility of our method in providing explicit values or efficient algorithms for our counting problem, by showing that the Fourier transform of the indicator function of the constraint is computable, for different constraints. Our second approach is to obtain good upper bounds, using an extension of Delsarte's linear program (LP), on the largest sizes of constrained codes that can correct a fixed number of combinatorial errors or erasures. We observe that the numerical values of our LP-based upper bounds beat the generalized sphere packing bounds of Fazeli, Vardy, and Yaakobi (2015). "
}