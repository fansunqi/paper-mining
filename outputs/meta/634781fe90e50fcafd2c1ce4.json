{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Multi-agent reinforcement learning",
    "Agent based modelling"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Phantom - A RL-driven multi-agent framework"
  ],
  "results": [
    "None"
  ],
  "paper_id": "634781fe90e50fcafd2c1ce4",
  "title": "Phantom - A RL-driven multi-agent framework to model complex systems",
  "abstract": "  Agent based modelling (ABM) is a computational approach to modelling complex systems by specifying the behaviour of autonomous decision-making components or agents in the system and allowing the system dynamics to emerge from their interactions. Recent advances in the field of Multi-agent reinforcement learning (MARL) have made it feasible to study the equilibrium of complex environments where multiple agents learn simultaneously. However, most ABM frameworks are not RL-native, in that they do not offer concepts and interfaces that are compatible with the use of MARL to learn agent behaviours. In this paper, we introduce a new open-source framework, Phantom, to bridge the gap between ABM and MARL. Phantom is an RL-driven framework for agent-based modelling of complex multi-agent systems including, but not limited to economic systems and markets. The framework aims to provide the tools to simplify the ABM specification in a MARL-compatible way - including features to encode dynamic partial observability, agent utility functions, heterogeneity in agent preferences or types, and constraints on the order in which agents can act (e.g. Stackelberg games, or more complex turn-taking environments). In this paper, we present these features, their design rationale and present two new environments leveraging the framework. "
}