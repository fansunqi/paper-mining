{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Functional Generation",
    "Continuous Image Generation",
    "Neural Interpolation"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "FunkNN",
    "Convolutional Network",
    "Patch-based Design"
  ],
  "results": [
    "High-quality continuous images",
    "Strong out-of-distribution performance",
    "Exact spatial derivatives"
  ],
  "paper_id": "63b24b1f90e50fcafdd36f93",
  "title": "FunkNN: Neural Interpolation for Functional Generation",
  "abstract": "  Can we build continuous generative models which generalize across scales, can be evaluated at any coordinate, admit calculation of exact derivatives, and are conceptually simple? Existing MLP-based architectures generate worse samples than the grid-based generators with favorable convolutional inductive biases. Models that focus on generating images at different scales do better, but employ complex architectures not designed for continuous evaluation of images and derivatives. We take a signal-processing perspective and treat continuous image generation as interpolation from samples. Indeed, correctly sampled discrete images contain all information about the low spatial frequencies. The question is then how to extrapolate the spectrum in a data-driven way while meeting the above design criteria. Our answer is FunkNN -- a new convolutional network which learns how to reconstruct continuous images at arbitrary coordinates and can be applied to any image dataset. Combined with a discrete generative model it becomes a functional generator which can act as a prior in continuous ill-posed inverse problems. We show that FunkNN generates high-quality continuous images and exhibits strong out-of-distribution performance thanks to its patch-based design. We further showcase its performance in several stylized inverse problems with exact spatial derivatives. "
}