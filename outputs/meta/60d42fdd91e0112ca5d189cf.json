{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Multimodal Speech Emotion Recognition"
  ],
  "datasets": [
    "IEMOCAP",
    "LSSED"
  ],
  "methods": [
    "Key-Sparse Transformer"
  ],
  "results": [
    "Achieves better performance than the state-of-the-art approaches"
  ],
  "paper_id": "60d42fdd91e0112ca5d189cf",
  "title": "Key-Sparse Transformer for Multimodal Speech Emotion Recognition",
  "abstract": "  Speech emotion recognition is a challenging research topic that plays a critical role in human-computer interaction. Multimodal inputs further improve the performance as more emotional information is used. However, existing studies learn all the information in the sample while only a small portion of it is about emotion. The redundant information will become noises and limit the system performance. In this paper, a key-sparse Transformer is proposed for efficient emotion recognition by focusing more on emotion related information. The proposed method is evaluated on the IEMOCAP and LSSED. Experimental results show that the proposed method achieves better performance than the state-of-the-art approaches. "
}