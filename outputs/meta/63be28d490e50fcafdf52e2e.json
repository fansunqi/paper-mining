{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Instance Segmentation"
  ],
  "datasets": [
    "COCO"
  ],
  "methods": [
    "Vision Transformers",
    "Mask Auto-Labeler (MAL)"
  ],
  "results": [
    "Mask quality gap significantly reduced",
    "Performance of instance segmentation models nearly matches fully supervised counterparts",
    "Best model achieves 44.1% mAP on COCO instance segmentation"
  ],
  "paper_id": "63be28d490e50fcafdf52e2e",
  "title": "Vision Transformers Are Good Mask Auto-Labelers",
  "abstract": "  We propose Mask Auto-Labeler (MAL), a high-quality Transformer-based mask auto-labeling framework for instance segmentation using only box annotations. MAL takes box-cropped images as inputs and conditionally generates their mask pseudo-labels.We show that Vision Transformers are good mask auto-labelers. Our method significantly reduces the gap between auto-labeling and human annotation regarding mask quality. Instance segmentation models trained using the MAL-generated masks can nearly match the performance of their fully-supervised counterparts, retaining up to 97.4\\% performance of fully supervised models. The best model achieves 44.1\\% mAP on COCO instance segmentation (test-dev 2017), outperforming state-of-the-art box-supervised methods by significant margins. Qualitative results indicate that masks produced by MAL are, in some cases, even better than human annotations. "
}