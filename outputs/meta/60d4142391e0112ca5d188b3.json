{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Identifying alignment problems in forecasting platforms"
  ],
  "datasets": [
    "Good Judgment Open",
    "CSET-Foretell",
    "Metaculus"
  ],
  "methods": [
    "Classification of problems as reward specification or principal-agent",
    "Proposed solutions for identified problems"
  ],
  "results": [
    "None"
  ],
  "paper_id": "60d4142391e0112ca5d188b3",
  "title": "Alignment Problems With Current Forecasting Platforms",
  "abstract": "  We present alignment problems in current forecasting platforms, such as Good Judgment Open, CSET-Foretell or Metaculus. We classify those problems as either reward specification problems or principal-agent problems, and we propose solutions. For instance, the scoring rule used by Good Judgment Open is not proper, and Metaculus tournaments disincentivize sharing information and incentivize distorting one's true probabilities to maximize the chances of placing in the top few positions which earn a monetary reward. We also point out some partial similarities between the problem of aligning forecasters and the problem of aligning artificial intelligence systems. "
}