{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Audio Telepresence"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Model-matching Principle",
    "Multichannel Inverse Filtering (MIF)",
    "Multichannel Deep Filtering (MDF)",
    "Localization-beamforming-HRTF filtering (LBH)"
  ],
  "results": [
    "Objective and subjective tests comparing the proposed system with two baselines"
  ],
  "paper_id": "63520de890e50fcafd60f31e",
  "title": "Model-matching Principle Applied to the Design of an Array-based\n  All-neural Binaural Rendering System for Audio Telepresence",
  "abstract": "  Telepresence aims to create an immersive but virtual experience of the audio and visual scene at the far end for users at the near end. In this contribution, we propose an array-based binaural rendering system that converts the array microphone signals into the head-related transfer function (HRTF) filtered output signals for headphone-rendering. The proposed approach is formulated in light of a model-matching principle (MMP) and is capable of delivering more immersive experience than the conventional localization-beamforming-HRTF filtering (LBH) approach. The MMP-based rendering system can be realized via multichannel inverse filtering (MIF) and multichannel deep filtering (MDF). In this study, we adopted the MDF approach and used the LBH as well as MIF as the baselines. The all-neural system jointly captures the spatial information (spatial rendering), preserves ambient sound (enhancement), and reduces noise (enhancement) before generating binaural outputs. Objective and subjective tests are employed to compare the proposed telepresence system with two baselines. "
}