{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Autoencoder Implementation",
    "Data Compression",
    "Image Classification",
    "Image Noise Reduction",
    "Image Coloring"
  ],
  "datasets": [
    "MNIST"
  ],
  "methods": [
    "Convolutional Autoencoder",
    "FPGA Implementation",
    "GPU-based Implementation"
  ],
  "results": [
    "80% accuracy",
    "Throughput: 21.12 GOP/s",
    "Power Consumption: 5.93 W",
    "Energy Efficiency",
    "Design Flexibility"
  ],
  "paper_id": "63c8b59590e50fcafd90b8f9",
  "title": "An Energy-Efficient Reconfigurable Autoencoder Implementation on FPGA",
  "abstract": "  Autoencoders are unsupervised neural networks that are used to process and compress input data and then reconstruct the data back to the original data size. This allows autoencoders to be used for different processing applications such as data compression, image classification, image noise reduction, and image coloring. Hardware-wise, re-configurable architectures like Field Programmable Gate Arrays (FPGAs) have been used for accelerating computations from several domains because of their unique combination of flexibility, performance, and power efficiency. In this paper, we look at the different autoencoders available and use the convolutional autoencoder in both FPGA and GPU-based implementations to process noisy static MNIST images. We compare the different results achieved with the FPGA and GPU-based implementations and then discuss the pros and cons of each implementation. The evaluation of the proposed design achieved 80%accuracy and our experimental results show that the proposed accelerator achieves a throughput of 21.12 Giga-Operations Per Second (GOP/s) with a 5.93 W on-chip power consumption at 100 MHz. The comparison results with off-the-shelf devices and recent state-of-the-art implementations illustrate that the proposed accelerator has obvious advantages in terms of energy efficiency and design flexibility. We also discuss future work that can be done with the use of our proposed accelerator. "
}