{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Detect erroneous inputs in neural networks"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Linear SVM classifier using hidden and softmax feature vectors of pre-trained neural networks"
  ],
  "results": [
    "Faulty data types exhibit linearly separable activation properties from correct examples",
    "Ability to reject bad inputs with no extra training or overhead"
  ],
  "paper_id": "5e5cd97391e011498fe971f8",
  "title": "Utilizing Network Properties to Detect Erroneous Inputs",
  "abstract": "  Neural networks are vulnerable to a wide range of erroneous inputs such as adversarial, corrupted, out-of-distribution, and misclassified examples. In this work, we train a linear SVM classifier to detect these four types of erroneous data using hidden and softmax feature vectors of pre-trained neural networks. Our results indicate that these faulty data types generally exhibit linearly separable activation properties from correct examples, giving us the ability to reject bad inputs with no extra training or overhead. We experimentally validate our findings across a diverse range of datasets, domains, pre-trained models, and adversarial attacks. "
}