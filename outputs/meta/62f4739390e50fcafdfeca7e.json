{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Survival Analysis"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "KL-divergence Based Deep Learning"
  ],
  "results": [
    "Better performance and higher robustness compared with previous works"
  ],
  "paper_id": "62f4739390e50fcafdfeca7e",
  "title": "KL-divergence Based Deep Learning for Discrete Time Model",
  "abstract": "  Neural Network (Deep Learning) is a modern model in Artificial Intelligence and it has been exploited in Survival Analysis. Although several improvements have been shown by previous works, training an excellent deep learning model requires a huge amount of data, which may not hold in practice. To address this challenge, we develop a Kullback-Leibler-based (KL) deep learning procedure to integrate external survival prediction models with newly collected time-to-event data. Time-dependent KL discrimination information is utilized to measure the discrepancy between the external and internal data. This is the first work considering using prior information to deal with short data problem in Survival Analysis for deep learning. Simulation and real data results show that the proposed model achieves better performance and higher robustness compared with previous works. "
}