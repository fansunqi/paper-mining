{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Context-aware robot control"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Gesture episodes",
    "Context of the situation",
    "Common sense"
  ],
  "results": [
    "Simulated table-top manipulation setting",
    "Deterministic experiments with simulated users",
    "System handles personal preferences"
  ],
  "paper_id": "63d340e890e50fcafd9106bc",
  "title": "Context-aware robot control using gesture episodes",
  "abstract": "  Collaborative robots became a popular tool for increasing productivity in partly automated manufacturing plants. Intuitive robot teaching methods are required to quickly and flexibly adapt the robot programs to new tasks. Gestures have an essential role in human communication. However, in human-robot-interaction scenarios, gesture-based user interfaces are so far used rarely, and if they employ a one-to-one mapping of gestures to robot control variables. In this paper, we propose a method that infers the user's intent based on gesture episodes, the context of the situation, and common sense. The approach is evaluated in a simulated table-top manipulation setting. We conduct deterministic experiments with simulated users and show that the system can even handle personal preferences of each user. "
}