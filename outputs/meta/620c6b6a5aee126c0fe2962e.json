{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Defenses against adversarial attacks in ML-based malware detection"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "StratDef: strategic defense system based on moving target defense approach"
  ],
  "results": [
    "StratDef performs better than other defenses even under peak adversarial threat",
    "StratDef outperforms adversarially-trained models"
  ],
  "paper_id": "620c6b6a5aee126c0fe2962e",
  "title": "StratDef: Strategic Defense Against Adversarial Attacks in ML-based\n  Malware Detection",
  "abstract": "  Over the years, most research towards defenses against adversarial attacks on machine learning models has been in the image recognition domain. The ML-based malware detection domain has received less attention despite its importance. Moreover, most work exploring these defenses has focused on several methods but with no strategy when applying them. In this paper, we introduce StratDef, which is a strategic defense system based on a moving target defense approach. We overcome challenges related to the systematic construction, selection, and strategic use of models to maximize adversarial robustness. StratDef dynamically and strategically chooses the best models to increase the uncertainty for the attacker while minimizing critical aspects in the adversarial ML domain, like attack transferability. We provide the first comprehensive evaluation of defenses against adversarial attacks on machine learning for malware detection, where our threat model explores different levels of threat, attacker knowledge, capabilities, and attack intensities. We show that StratDef performs better than other defenses even when facing the peak adversarial threat. We also show that, of the existing defenses, only a few adversarially-trained models provide substantially better protection than just using vanilla models but are still outperformed by StratDef. "
}