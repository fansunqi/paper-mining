{
  "code_links": [
    "None"
  ],
  "tasks": [
    "No-Regret Learning in General Games"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Optimistic Hedge"
  ],
  "results": [
    "${\\rm poly}(\\log T)$ regret in multi-player general-sum games",
    "Exponentially improves $O({T}^{1/2})$ regret of standard no-regret learners",
    "Improves $O(T^{1/4})$ regret of no-regret learners with recency bias",
    "Improves ${O}(T^{1/6})$ bound for Optimistic Hedge in two-player games",
    "Converges to coarse correlated equilibrium at a rate of $\\tilde{O}\\left(\\frac 1T\\right)$"
  ],
  "paper_id": "611b703e5244ab9dcbc20edf",
  "title": "Near-Optimal No-Regret Learning in General Games",
  "abstract": "  We show that Optimistic Hedge -- a common variant of multiplicative-weights-updates with recency bias -- attains ${\\rm poly}(\\log T)$ regret in multi-player general-sum games. In particular, when every player of the game uses Optimistic Hedge to iteratively update her strategy in response to the history of play so far, then after $T$ rounds of interaction, each player experiences total regret that is ${\\rm poly}(\\log T)$. Our bound improves, exponentially, the $O({T}^{1/2})$ regret attainable by standard no-regret learners in games, the $O(T^{1/4})$ regret attainable by no-regret learners with recency bias (Syrgkanis et al., 2015), and the ${O}(T^{1/6})$ bound that was recently shown for Optimistic Hedge in the special case of two-player games (Chen & Pen, 2020). A corollary of our bound is that Optimistic Hedge converges to coarse correlated equilibrium in general games at a rate of $\\tilde{O}\\left(\\frac 1T\\right)$. "
}