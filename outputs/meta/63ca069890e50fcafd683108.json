{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Misinformation Detection"
  ],
  "datasets": [
    "new-normal misinformation data"
  ],
  "methods": [
    "semantic masking",
    "contrastive smoothing",
    "intra-proxy smoothness regularization"
  ],
  "results": [
    "over 30% improvement over existing approaches",
    "minimal concession (1 to 5%) of accuracy compared to oracles"
  ],
  "paper_id": "63ca069890e50fcafd683108",
  "title": "Continuously Reliable Detection of New-Normal Misinformation: Semantic\n  Masking and Contrastive Smoothing in High-Density Latent Regions",
  "abstract": "  Toxic misinformation campaigns have caused significant societal harm, e.g., affecting elections and COVID-19 information awareness. Unfortunately, despite successes of (gold standard) retrospective studies of misinformation that confirmed their harmful effects after the fact, they arrive too late for timely intervention and reduction of such harm. By design, misinformation evades retrospective classifiers by exploiting two properties we call new-normal: (1) never-seen-before novelty that cause inescapable generalization challenges for previous classifiers, and (2) massive but short campaigns that end before they can be manually annotated for new classifier training. To tackle these challenges, we propose UFIT, which combines two techniques: semantic masking of strong signal keywords to reduce overfitting, and intra-proxy smoothness regularization of high-density regions in the latent space to improve reliability and maintain accuracy. Evaluation of UFIT on public new-normal misinformation data shows over 30% improvement over existing approaches on future (and unseen) campaigns. To the best of our knowledge, UFIT is the first successful effort to achieve such high level of generalization on new-normal misinformation data with minimal concession (1 to 5%) of accuracy compared to oracles trained with full knowledge of all campaigns. "
}