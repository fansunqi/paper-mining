{
  "code_links": [
    "open-source code"
  ],
  "tasks": [
    "Deep Batch Active Learning for Regression"
  ],
  "datasets": [
    "15 large tabular regression data sets"
  ],
  "methods": [
    "Framework for constructing active learning methods",
    "Base kernels, kernel transformations, selection methods",
    "Sketched finite-width Neural Tangent Kernels",
    "Novel clustering method"
  ],
  "results": [
    "Outperforms state-of-the-art on benchmark",
    "Scales to large data sets",
    "Works out-of-the-box without adjusting network architecture or training code"
  ],
  "paper_id": "6233f88d5aee126c0f94b634",
  "title": "A Framework and Benchmark for Deep Batch Active Learning for Regression",
  "abstract": "  The acquisition of labels for supervised learning can be expensive. In order to improve the sample-efficiency of neural network regression, we study active learning methods that adaptively select batches of unlabeled data for labeling. We present a framework for constructing such methods out of (network-dependent) base kernels, kernel transformations and selection methods. Our framework encompasses many existing Bayesian methods based on Gaussian Process approximations of neural networks as well as non-Bayesian methods. Additionally, we propose to replace the commonly used last-layer features with sketched finite-width Neural Tangent Kernels, and to combine them with a novel clustering method. To evaluate different methods, we introduce an open-source benchmark consisting of 15 large tabular regression data sets. Our proposed method outperforms the state-of-the-art on our benchmark, scales to large data sets, and works out-of-the-box without adjusting the network architecture or training code. We provide open-source code that includes efficient implementations of all kernels, kernel transformations, and selection methods, and can be used for reproducing our results. "
}