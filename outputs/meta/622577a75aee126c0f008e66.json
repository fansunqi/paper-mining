{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Out-of-Distribution Detection"
  ],
  "datasets": [
    "CIFAR-100",
    "TinyImagenet-crop"
  ],
  "methods": [
    "Reconstruction Autoencoder-Based Methods",
    "Quadruplet Domain Translation",
    "Semantic Reconstruction",
    "Data Certainty Decomposition",
    "Normalized L2 Distance"
  ],
  "results": [
    "FPR@95%TPR of CIFAR-100 vs. TinyImagenet-crop on Wide-ResNet is 0.2%",
    "State-of-the-art performance on various benchmarks",
    "No additional data, hard-to-implement structure, time-consuming pipeline, and no harm to classification accuracy of known classes"
  ],
  "paper_id": "622577a75aee126c0f008e66",
  "title": "Rethinking Reconstruction Autoencoder-Based Out-of-Distribution\n  Detection",
  "abstract": "  In some scenarios, classifier requires detecting out-of-distribution samples far from its training data. With desirable characteristics, reconstruction autoencoder-based methods deal with this problem by using input reconstruction error as a metric of novelty vs. normality. We formulate the essence of such approach as a quadruplet domain translation with an intrinsic bias to only query for a proxy of conditional data uncertainty. Accordingly, an improvement direction is formalized as maximumly compressing the autoencoder's latent space while ensuring its reconstructive power for acting as a described domain translator. From it, strategies are introduced including semantic reconstruction, data certainty decomposition and normalized L2 distance to substantially improve original methods, which together establish state-of-the-art performance on various benchmarks, e.g., the FPR@95%TPR of CIFAR-100 vs. TinyImagenet-crop on Wide-ResNet is 0.2%. Importantly, our method works without any additional data, hard-to-implement structure, time-consuming pipeline, and even harming the classification accuracy of known classes. "
}