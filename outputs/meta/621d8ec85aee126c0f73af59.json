{
  "code_links": [
    "None"
  ],
  "tasks": [
    "GNN Evasion Attacks"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Projective Ranking-based GNN Evasion Attacks",
    "Formulate perturbation space and evaluation framework",
    "Rank and assess attack benefits based on mutual information",
    "Project strategy to minimize cost under dynamic budget settings"
  ],
  "results": [
    "High attack performance",
    "Effective transferability",
    "Various attack patterns in adversarial sample generation"
  ],
  "paper_id": "621d8ec85aee126c0f73af59",
  "title": "Projective Ranking-based GNN Evasion Attacks",
  "abstract": "  Graph neural networks (GNNs) offer promising learning methods for graph-related tasks. However, GNNs are at risk of adversarial attacks. Two primary limitations of the current evasion attack methods are highlighted: (1) The current GradArgmax ignores the \"long-term\" benefit of the perturbation. It is faced with zero-gradient and invalid benefit estimates in certain situations. (2) In the reinforcement learning-based attack methods, the learned attack strategies might not be transferable when the attack budget changes. To this end, we first formulate the perturbation space and propose an evaluation framework and the projective ranking method. We aim to learn a powerful attack strategy then adapt it as little as possible to generate adversarial samples under dynamic budget settings. In our method, based on mutual information, we rank and assess the attack benefits of each perturbation for an effective attack strategy. By projecting the strategy, our method dramatically minimizes the cost of learning a new attack strategy when the attack budget changes. In the comparative assessment with GradArgmax and RL-S2V, the results show our method owns high attack performance and effective transferability. The visualization of our method also reveals various attack patterns in the generation of adversarial samples. "
}