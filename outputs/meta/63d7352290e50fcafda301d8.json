{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Video Decomposition",
    "Prediction",
    "Object-Centric Representation Learning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Time-Conditioned Generative Model",
    "Transformer",
    "Slot Attention",
    "Gaussian Processes"
  ],
  "results": [
    "Video decomposition",
    "Complete object shape reconstruction",
    "Novel viewpoint prediction without viewpoint annotations"
  ],
  "paper_id": "63d7352290e50fcafda301d8",
  "title": "Time-Conditioned Generative Modeling of Object-Centric Representations\n  for Video Decomposition and Prediction",
  "abstract": "  When perceiving the world from multiple viewpoints, humans have the ability to reason about the complete objects in a compositional manner even when the object is completely occluded from partial viewpoints. Meanwhile, humans can imagine the novel views after observing multiple viewpoints. The remarkable recent advance in multi-view object-centric learning leaves some problems: 1) the partially or completely occluded shape of objects can not be well reconstructed. 2) the novel viewpoint prediction depends on expensive viewpoint annotations rather than implicit view rules. This makes the agent fail to perform like humans. In this paper, we introduce a time-conditioned generative model for videos. To reconstruct the complete shape of the object accurately, we enhance the disentanglement between different latent representations: view latent representations are jointly inferred based on the Transformer and then cooperate with the sequential extension of Slot Attention to learn object-centric representations. The model also achieves the new ability: Gaussian processes are employed as priors of view latent variables for generation and novel-view prediction without viewpoint annotations. Experiments on multiple specifically designed synthetic datasets have shown that the proposed model can 1) make the video decomposition, 2) reconstruct the complete shapes of objects, and 3) make the novel viewpoint prediction without viewpoint annotations. "
}