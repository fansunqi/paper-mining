{
  "code_links": [
    "https://github.com/rover-xingyu/PROCA"
  ],
  "tasks": [
    "Place recognition"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Disentangled Representations"
  ],
  "results": [
    "Our model outperforms the state-of-the-art methods"
  ],
  "paper_id": "637c3dd690e50fcafd77ccbb",
  "title": "Place Recognition under Occlusion and Changing Appearance via\n  Disentangled Representations",
  "abstract": "  Place recognition is a critical and challenging task for mobile robots, aiming to retrieve an image captured at the same place as a query image from a database. Existing methods tend to fail while robots move autonomously under occlusion (e.g., car, bus, truck) and changing appearance (e.g., illumination changes, seasonal variation). Because they encode the image into only one code, entangling place features with appearance and occlusion features. To overcome this limitation, we propose PROCA, an unsupervised approach to decompose the image representation into three codes: a place code used as a descriptor to retrieve images, an appearance code that captures appearance properties, and an occlusion code that encodes occlusion content. Extensive experiments show that our model outperforms the state-of-the-art methods. Our code and data are available at https://github.com/rover-xingyu/PROCA. "
}