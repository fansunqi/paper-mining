{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Unsupervised domain adaptive person re-identification"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Synthesis Model Bank (SMB)",
    "convolutional neural networks (CNN)",
    "Mahalanobis matrices",
    "GAN-based image synthesis"
  ],
  "results": [
    "The proposed SMB outperforms other synthesis methods on several re-ID benchmarks"
  ],
  "paper_id": "63d340de90e50fcafd90f834",
  "title": "Illumination Variation Correction Using Image Synthesis For Unsupervised\n  Domain Adaptive Person Re-Identification",
  "abstract": "  Unsupervised domain adaptive (UDA) person re-identification (re-ID) aims to learn identity information from labeled images in source domains and apply it to unlabeled images in a target domain. One major issue with many unsupervised re-identification methods is that they do not perform well relative to large domain variations such as illumination, viewpoint, and occlusions. In this paper, we propose a Synthesis Model Bank (SMB) to deal with illumination variation in unsupervised person re-ID. The proposed SMB consists of several convolutional neural networks (CNN) for feature extraction and Mahalanobis matrices for distance metrics. They are trained using synthetic data with different illumination conditions such that their synergistic effect makes the SMB robust against illumination variation. To better quantify the illumination intensity and improve the quality of synthetic images, we introduce a new 3D virtual-human dataset for GAN-based image synthesis. From our experiments, the proposed SMB outperforms other synthesis methods on several re-ID benchmarks. "
}