{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Software quality estimation",
    "Software refactoring",
    "Many-objective optimization"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "NSGA-II genetic algorithm",
    "Performance and reliability variations",
    "Performance antipatterns detection",
    "Architectural distance metric"
  ],
  "results": [
    "Performance improvement up to 42%",
    "Reliability improvement up to 32%",
    "Order of preference of refactoring actions",
    "Suitability of architectural distance metric for refactoring effort estimation"
  ],
  "paper_id": "65b9b7e0939a5f408231eea1",
  "title": "Many-Objective Optimization of Non-Functional Attributes based on\n  Refactoring of Software Models",
  "abstract": "Software quality estimation is a challenging and time-consuming activity, and\nmodels are crucial to face the complexity of such activity on modern software\napplications. In this context, software refactoring is a crucial activity\nwithin development life-cycles where requirements and functionalities rapidly\nevolve. One main challenge is that the improvement of distinctive quality\nattributes may require contrasting refactoring actions on software, as for\ntrade-off between performance and reliability (or other non-functional\nattributes). In such cases, multi-objective optimization can provide the\ndesigner with a wider view on these trade-offs and, consequently, can lead to\nidentify suitable refactoring actions that take into account independent or\neven competing objectives. In this paper, we present an approach that exploits\nNSGA-II as the genetic algorithm to search optimal Pareto frontiers for\nsoftware refactoring while considering many objectives. We consider performance\nand reliability variations of a model alternative with respect to an initial\nmodel, the amount of performance antipatterns detected on the model\nalternative, and the architectural distance, which quantifies the effort to\nobtain a model alternative from the initial one. We applied our approach on two\ncase studies: a Train Ticket Booking Service, and CoCoME. We observed that our\napproach is able to improve performance (by up to 42%) while preserving or\neven improving the reliability (by up to 32%) of generated model alternatives.\nWe also observed that there exists an order of preference of refactoring\nactions among model alternatives. We can state that performance antipatterns\nconfirmed their ability to improve performance of a subject model in the\ncontext of many-objective optimization. In addition, the metric that we adopted\nfor the architectural distance seems to be suitable for estimating the\nrefactoring effort."
}