{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Face Animation"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Multiple source images",
    "Optical flow",
    "Deep neural networks"
  ],
  "results": [
    "None"
  ],
  "paper_id": "63896cd590e50fcafde79e5f",
  "title": "Face Animation with Multiple Source Images",
  "abstract": "  Face animation has received a lot of attention from researchers in recent years due to its wide range of promising applications. Many face animation models based on optical flow or deep neural networks have achieved great success. However, these models are likely to fail in animated scenarios with significant view changes, resulting in unrealistic or distorted faces. One of the possible reasons is that such models lack prior knowledge of human faces and are not proficient to imagine facial regions they have never seen before. In this paper, we propose a flexible and generic approach to improve the performance of face animation without additional training. We use multiple source images as input as compensation for the lack of prior knowledge of faces. The effectiveness of our method is experimentally demonstrated, where the proposed method successfully supplements the baseline method. "
}