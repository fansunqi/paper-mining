{
  "code_links": [
    "http://luqi.info/entityv2.github.io/"
  ],
  "tasks": [
    "Entity segmentation"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "CropFormer"
  ],
  "results": [
    "AP gain of 1.9 on entity segmentation"
  ],
  "paper_id": "636dbe6b90e50fcafd79ae1d",
  "title": "High-Quality Entity Segmentation",
  "abstract": "  Dense image segmentation tasks e.g., semantic, panoptic) are useful for image editing, but existing methods can hardly generalize well in an in-the-wild setting where there are unrestricted image domains, classes, and image resolution and quality variations. Motivated by these observations, we construct a new entity segmentation dataset, with a strong focus on high-quality dense segmentation in the wild. The dataset contains images spanning diverse image domains and entities, along with plentiful high-resolution images and high-quality mask annotations for training and testing. Given the high-quality and -resolution nature of the dataset, we propose CropFormer which is designed to tackle the intractability of instance-level segmentation on high-resolution images. It improves mask prediction by fusing high-res image crops that provide more fine-grained image details and the full image. CropFormer is the first query-based Transformer architecture that can effectively fuse mask predictions from multiple image views, by learning queries that effectively associate the same entities across the full image and its crop. With CropFormer, we achieve a significant AP gain of $1.9$ on the challenging entity segmentation task. Furthermore, CropFormer consistently improves the accuracy of traditional segmentation tasks and datasets. The dataset and code will be released at http://luqi.info/entityv2.github.io/. "
}