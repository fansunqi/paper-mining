{
  "code_links": [
    "None"
  ],
  "tasks": [
    "data-driven adaptive control",
    "learning-based control of nonlinear systems"
  ],
  "datasets": [
    "heating, ventilation, and air-conditioning model"
  ],
  "methods": [
    "finite-horizon oracle controller",
    "learning-based MPC",
    "MAB's",
    "control-theoretic analysis"
  ],
  "results": [
    "low regret with respect to finite-horizon oracle",
    "simulations exhibit low regret on HVAC model with partially-unknown cost function"
  ],
  "paper_id": "610cace35244ab9dcb1b00c5",
  "title": "Regret Analysis of Learning-Based MPC with Partially-Unknown Cost\n  Function",
  "abstract": "  The exploration/exploitation trade-off is an inherent challenge in data-driven adaptive control. Though this trade-off has been studied for multi-armed bandits (MAB's) and reinforcement learning for linear systems; it is less well-studied for learning-based control of nonlinear systems. A significant theoretical challenge in the nonlinear setting is that there is no explicit characterization of an optimal controller for a given set of cost and system parameters. We propose the use of a finite-horizon oracle controller with full knowledge of parameters as a reasonable surrogate to optimal controller. This allows us to develop policies in the context of learning-based MPC and MAB's and conduct a control-theoretic analysis using techniques from MPC- and optimization-theory to show these policies achieve low regret with respect to this finite-horizon oracle. Our simulations exhibit the low regret of our policy on a heating, ventilation, and air-conditioning model with partially-unknown cost function. "
}