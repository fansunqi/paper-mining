{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Many Episode Learning",
    "Modular Embodied Agent Improvement"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "End-to-End Interaction",
    "Credit Assignment",
    "Data Annotation",
    "Model Re-training and Re-deployment"
  ],
  "results": [
    "Demonstrated agent improvement over multiple interaction rounds"
  ],
  "paper_id": "625f6bf65aee126c0ffb3515",
  "title": "Many Episode Learning in a Modular Embodied Agent via End-to-End\n  Interaction",
  "abstract": "  In this work we give a case study of an embodied machine-learning (ML) powered agent that improves itself via interactions with crowd-workers. The agent consists of a set of modules, some of which are learned, and others heuristic. While the agent is not \"end-to-end\" in the ML sense, end-to-end interaction is a vital part of the agent's learning mechanism. We describe how the design of the agent works together with the design of multiple annotation interfaces to allow crowd-workers to assign credit to module errors from end-to-end interactions, and to label data for individual modules. Over multiple automated human-agent interaction, credit assignment, data annotation, and model re-training and re-deployment, rounds we demonstrate agent improvement. "
}