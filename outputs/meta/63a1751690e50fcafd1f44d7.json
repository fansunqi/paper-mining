{
  "code_links": [
    "https://github.com/keeganhk/Flattening-Net"
  ],
  "tasks": [
    "3D Point Cloud Representation"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Flattening-Net"
  ],
  "results": [
    "State-of-the-art performance against current competitors"
  ],
  "paper_id": "63a1751690e50fcafd1f44d7",
  "title": "Flattening-Net: Deep Regular 2D Representation for 3D Point Cloud\n  Analysis",
  "abstract": "  Point clouds are characterized by irregularity and unstructuredness, which pose challenges in efficient data exploitation and discriminative feature extraction. In this paper, we present an unsupervised deep neural architecture called Flattening-Net to represent irregular 3D point clouds of arbitrary geometry and topology as a completely regular 2D point geometry image (PGI) structure, in which coordinates of spatial points are captured in colors of image pixels. \\mr{Intuitively, Flattening-Net implicitly approximates a locally smooth 3D-to-2D surface flattening process while effectively preserving neighborhood consistency.} \\mr{As a generic representation modality, PGI inherently encodes the intrinsic property of the underlying manifold structure and facilitates surface-style point feature aggregation.} To demonstrate its potential, we construct a unified learning framework directly operating on PGIs to achieve \\mr{diverse types of high-level and low-level} downstream applications driven by specific task networks, including classification, segmentation, reconstruction, and upsampling. Extensive experiments demonstrate that our methods perform favorably against the current state-of-the-art competitors. We will make the code and data publicly available at https://github.com/keeganhk/Flattening-Net. "
}