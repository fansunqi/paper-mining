{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Federated Split Learning",
    "Data privacy",
    "Efficiency of communications"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Hybrid Federated Split Learning architecture"
  ],
  "results": [
    "Lower processing power required by clients",
    "Reduced training and inference time",
    "Similar accuracy",
    "Resilience to deep learning privacy inference attacks"
  ],
  "paper_id": "63bcd72f90e50fcafdef962b",
  "title": "Privacy and Efficiency of Communications in Federated Split Learning",
  "abstract": "  Everyday, large amounts of sensitive data is distributed across mobile phones, wearable devices, and other sensors. Traditionally, these enormous datasets have been processed on a single system, with complex models being trained to make valuable predictions. Distributed machine learning techniques such as Federated and Split Learning have recently been developed to protect user data and privacy better while ensuring high performance. Both of these distributed learning architectures have advantages and disadvantages. In this paper, we examine these tradeoffs and suggest a new hybrid Federated Split Learning architecture that combines the efficiency and privacy benefits of both. Our evaluation demonstrates how our hybrid Federated Split Learning approach can lower the amount of processing power required by each client running a distributed learning system, reduce training and inference time while keeping a similar accuracy. We also discuss the resiliency of our approach to deep learning privacy inference attacks and compare our solution to other recently proposed benchmarks. "
}