{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Variance estimation of random forests using Infinite-order U-statistics"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "New view of Hoeffding decomposition for unbiased variance estimation",
    "Local smoothing procedure for improved finite sample performance"
  ],
  "results": [
    "Lower bias in estimators",
    "Achieves targeted coverage rates for confidence intervals",
    "First to establish ratio consistency of such a variance estimator"
  ],
  "paper_id": "6213029a5aee126c0f42a3b6",
  "title": "On Variance Estimation of Random Forests with Infinite-Order\n  U-statistics",
  "abstract": "  Infinite-order U-statistics (IOUS) has been used extensively on subbagging ensemble learning algorithms such as random forests to quantify its uncertainty. While normality results of IOUS have been studied extensively, its variance estimation approaches and theoretical properties remain mostly unexplored. Existing approaches mainly utilize the leading term dominance property in the Hoeffding decomposition. However, such a view usually leads to biased estimation when the kernel size is large or the sample size is small. On the other hand, while several unbiased estimators exist in the literature, their relationships and theoretical properties, especially the ratio consistency, have never been studied. These limitations lead to unguaranteed performances of constructed confidence intervals. To bridge these gaps in the literature, we propose a new view of the Hoeffding decomposition for variance estimation that leads to an unbiased estimator. Instead of leading term dominance, our view utilizes the dominance of the peak region. Moreover, we establish the connection and equivalence of our estimator with several existing unbiased variance estimators. Theoretically, we are the first to establish the ratio consistency of such a variance estimator, which justifies the coverage rate of confidence intervals constructed from random forests. Numerically, we further propose a local smoothing procedure to improve the estimator's finite sample performance. Extensive simulation studies show that our estimators enjoy lower bias and archive targeted coverage rates. "
}