{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Neural Network Verification"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "ONNX",
    "VNN-LIB",
    "Automatic Evaluation Pipeline"
  ],
  "results": [
    "11 teams participated",
    "12 scored benchmarks"
  ],
  "paper_id": "63a2794d90e50fcafd294532",
  "title": "The Third International Verification of Neural Networks Competition\n  (VNN-COMP 2022): Summary and Results",
  "abstract": "  This report summarizes the 3rd International Verification of Neural Networks Competition (VNN-COMP 2022), held as a part of the 5th Workshop on Formal Methods for ML-Enabled Autonomous Systems (FoMLAS), which was collocated with the 34th International Conference on Computer-Aided Verification (CAV). VNN-COMP is held annually to facilitate the fair and objective comparison of state-of-the-art neural network verification tools, encourage the standardization of tool interfaces, and bring together the neural network verification community. To this end, standardized formats for networks (ONNX) and specification (VNN-LIB) were defined, tools were evaluated on equal-cost hardware (using an automatic evaluation pipeline based on AWS instances), and tool parameters were chosen by the participants before the final test sets were made public. In the 2022 iteration, 11 teams participated on a diverse set of 12 scored benchmarks. This report summarizes the rules, benchmarks, participating tools, results, and lessons learned from this iteration of this competition. "
}