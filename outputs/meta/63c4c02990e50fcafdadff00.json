{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Linguistic Nativism",
    "Accessibility of Large Language Models (LLMs)"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "None"
  ],
  "results": [
    "None"
  ],
  "paper_id": "63c4c02990e50fcafdadff00",
  "title": "Inaccessible Neural Language Models Could Reinvigorate Linguistic\n  Nativism",
  "abstract": "  Large Language Models (LLMs) have been making big waves in the machine learning community within the past few years. The impressive scalability of LLMs due to the advent of deep learning can be seen as a continuation of empiricist lingusitic methods, as opposed to rule-based linguistic methods that are grounded in a nativist perspective. Current LLMs are generally inaccessible to resource-constrained researchers, due to a variety of factors including closed source code. This work argues that this lack of accessibility could instill a nativist bias in researchers new to computational linguistics, given that new researchers may only have rule-based, nativist approaches to study to produce new work. Also, given that there are numerous critics of deep learning claiming that LLMs and related methods may soon lose their relevancy, we speculate that such an event could trigger a new wave of nativism in the language processing community. To prevent such a dramatic shift and placing favor in hybrid methods of rules and deep learning, we call upon researchers to open source their LLM code wherever possible to allow both empircist and hybrid approaches to remain accessible. "
}