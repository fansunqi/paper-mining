{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Context-aware neural machine translation"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Layer-wise selection mechanism"
  ],
  "results": [
    "Significantly outperforms previous models on all datasets via the soft selection mechanism"
  ],
  "paper_id": "63c8b59590e50fcafd90b6f6",
  "title": "HanoiT: Enhancing Context-aware Translation via Selective Context",
  "abstract": "  Context-aware neural machine translation aims to use the document-level context to improve translation quality. However, not all words in the context are helpful. The irrelevant or trivial words may bring some noise and distract the model from learning the relationship between the current sentence and the auxiliary context. To mitigate this problem, we propose a novel end-to-end encoder-decoder model with a layer-wise selection mechanism to sift and refine the long document context. To verify the effectiveness of our method, extensive experiments and extra quantitative analysis are conducted on four document-level machine translation benchmarks. The experimental results demonstrate that our model significantly outperforms previous models on all datasets via the soft selection mechanism. "
}