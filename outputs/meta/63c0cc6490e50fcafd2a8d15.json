{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Motor type classification",
    "Object detection",
    "Part segmentation",
    "Reinforcement learning-based robotics control",
    "View-planning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Blender add-on for mesh model generation",
    "Synthetic RGB images",
    "Depth images",
    "Normal images",
    "Segmentation ground truth masks",
    "3D point cloud datasets"
  ],
  "results": [
    "None"
  ],
  "paper_id": "63c0cc6490e50fcafd2a8d15",
  "title": "MotorFactory: A Blender Add-on for Large Dataset Generation of Small\n  Electric Motors",
  "abstract": "  To enable automatic disassembly of different product types with uncertain conditions and degrees of wear in remanufacturing, agile production systems that can adapt dynamically to changing requirements are needed. Machine learning algorithms can be employed due to their generalization capabilities of learning from various types and variants of products. However, in reality, datasets with a diversity of samples that can be used to train models are difficult to obtain in the initial period. This may cause bad performances when the system tries to adapt to new unseen input data in the future. In order to generate large datasets for different learning purposes, in our project, we present a Blender add-on named MotorFactory to generate customized mesh models of various motor instances. MotorFactory allows to create mesh models which, complemented with additional add-ons, can be further used to create synthetic RGB images, depth images, normal images, segmentation ground truth masks, and 3D point cloud datasets with point-wise semantic labels. The created synthetic datasets may be used for various tasks including motor type classification, object detection for decentralized material transfer tasks, part segmentation for disassembly and handling tasks, or even reinforcement learning-based robotics control or view-planning. "
}