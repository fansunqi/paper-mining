{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Online Learning in Stackelberg Games"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Omniscient follower strategy",
    "Sample complexity analysis"
  ],
  "results": [
    "Sample complexity changes from constant to exponential based on reward structure"
  ],
  "paper_id": "63d7352390e50fcafda302f8",
  "title": "Online Learning in Stackelberg Games with an Omniscient Follower",
  "abstract": "  We study the problem of online learning in a two-player decentralized cooperative Stackelberg game. In each round, the leader first takes an action, followed by the follower who takes their action after observing the leader's move. The goal of the leader is to learn to minimize the cumulative regret based on the history of interactions. Differing from the traditional formulation of repeated Stackelberg games, we assume the follower is omniscient, with full knowledge of the true reward, and that they always best-respond to the leader's actions. We analyze the sample complexity of regret minimization in this repeated Stackelberg game. We show that depending on the reward structure, the existence of the omniscient follower may change the sample complexity drastically, from constant to exponential, even for linear cooperative Stackelberg games. This poses unique challenges for the learning process of the leader and the subsequent regret analysis. "
}