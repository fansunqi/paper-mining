{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Machine Learning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Shape-based analog computing (S-AC) circuits",
    "margin-propagation-based analog computing framework"
  ],
  "results": [
    "Circuit input/output characteristics remain robust when mapped from a planar CMOS 180nm process to a FinFET 7nm process",
    "Classification accuracy of a S-AC based neural network remains robust when mapped across the two processes and to changes in temperature"
  ],
  "paper_id": "627c6cff5aee126c0f83232f",
  "title": "Process, Bias and Temperature Scalable CMOS Analog Computing Circuits\n  for Machine Learning",
  "abstract": "  Analog computing is attractive compared to digital computing due to its potential for achieving higher computational density and higher energy efficiency. However, unlike digital circuits, conventional analog computing circuits cannot be easily mapped across different process nodes due to differences in transistor biasing regimes, temperature variations and limited dynamic range. In this work, we generalize the previously reported margin-propagation-based analog computing framework for designing novel \\textit{shape-based analog computing} (S-AC) circuits that can be easily cross-mapped across different process nodes. Similar to digital designs S-AC designs can also be scaled for precision, speed, and power. As a proof-of-concept, we show several examples of S-AC circuits implementing mathematical functions that are commonly used in machine learning (ML) architectures. Using circuit simulations we demonstrate that the circuit input/output characteristics remain robust when mapped from a planar CMOS 180nm process to a FinFET 7nm process. Also, using benchmark datasets we demonstrate that the classification accuracy of a S-AC based neural network remains robust when mapped across the two processes and to changes in temperature. "
}