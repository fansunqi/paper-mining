{
  "code_links": [
    "https://github.com/gchochla/Demux-MEmo"
  ],
  "tasks": [
    "Emotion inference from text"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Multilingual models",
    "Demux transformer-based model"
  ],
  "results": [
    "Zero-shot knowledge transfer to new languages, annotation formats, and emotions"
  ],
  "paper_id": "6361dfe090e50fcafd898cce",
  "title": "Using Emotion Embeddings to Transfer Knowledge Between Emotions,\n  Languages, and Annotation Formats",
  "abstract": "  The need for emotional inference from text continues to diversify as more and more disciplines integrate emotions into their theories and applications. These needs include inferring different emotion types, handling multiple languages, and different annotation formats. A shared model between different configurations would enable the sharing of knowledge and a decrease in training costs, and would simplify the process of deploying emotion recognition models in novel environments. In this work, we study how we can build a single model that can transition between these different configurations by leveraging multilingual models and Demux, a transformer-based model whose input includes the emotions of interest, enabling us to dynamically change the emotions predicted by the model. Demux also produces emotion embeddings, and performing operations on them allows us to transition to clusters of emotions by pooling the embeddings of each cluster. We show that Demux can simultaneously transfer knowledge in a zero-shot manner to a new language, to a novel annotation format and to unseen emotions. Code is available at https://github.com/gchochla/Demux-MEmo . "
}