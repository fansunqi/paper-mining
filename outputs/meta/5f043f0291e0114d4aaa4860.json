{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Interpretation of disease evidence in medical images"
  ],
  "datasets": [
    "Chest x-rays (CXRs) for COPD",
    "Brain MRIs for Alzheimer's disease"
  ],
  "methods": [
    "Deformation field interpretation with generative adversarial networks (DeFI-GAN)"
  ],
  "results": [
    "Highlights disease biomarkers not found by previous methods",
    "Identifies potential biases in datasets and learning methods",
    "Compelling results against baseline producing difference maps in longitudinal data"
  ],
  "paper_id": "5f043f0291e0114d4aaa4860",
  "title": "Interpretation of Disease Evidence for Medical Images Using Adversarial\n  Deformation Fields",
  "abstract": "  The high complexity of deep learning models is associated with the difficulty of explaining what evidence they recognize as correlating with specific disease labels. This information is critical for building trust in models and finding their biases. Until now, automated deep learning visualization solutions have identified regions of images used by classifiers, but these solutions are too coarse, too noisy, or have a limited representation of the way images can change. We propose a novel method for formulating and presenting spatial explanations of disease evidence, called deformation field interpretation with generative adversarial networks (DeFI-GAN). An adversarially trained generator produces deformation fields that modify images of diseased patients to resemble images of healthy patients. We validate the method studying chronic obstructive pulmonary disease (COPD) evidence in chest x-rays (CXRs) and Alzheimer's disease (AD) evidence in brain MRIs. When extracting disease evidence in longitudinal data, we show compelling results against a baseline producing difference maps. DeFI-GAN also highlights disease biomarkers not found by previous methods and potential biases that may help in investigations of the dataset and of the adopted learning methods. "
}