{
  "code_links": [
    "None"
  ],
  "tasks": [
    "command-following robots"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "VAR++",
    "self-supervised contrastive learning"
  ],
  "results": [
    "continually self-improve in previously unseen scenarios",
    "achieves better performance compared with previous methods"
  ],
  "paper_id": "63d340de90e50fcafd90f873",
  "title": "Learning Rewards and Skills to Follow Commands with A Data Efficient\n  Visual-Audio Representation",
  "abstract": "  Based on the recent advancements in representation learning, we propose a novel framework for command-following robots with raw sensor inputs. Previous RL-based methods are either difficult to continuously improve after the deployment or require a large number of new labels during the fine-tuning. Motivated by (self-)supervised contrastive learning literature, we propose a novel representation, named VAR++, that generates an intrinsic reward function for command-following robot tasks by associating images with sound commands. After the robot is deployed in a new domain, the representation can be updated intuitively and data-efficiently by non-experts, and the robot is able to fulfill sound commands without any hand-crafted reward functions. We demonstrate our approach on various sound types and robotic tasks, including navigation and manipulation with raw sensor inputs. In the simulated experiments, we show that our system can continually self-improve in previously unseen scenarios given fewer new labeled data, yet achieves better performance, compared with previous methods. "
}