{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Automated Machine Learning (AutoML) evaluation"
  ],
  "datasets": [
    "100 data sets from established AutoML benchmark suites"
  ],
  "methods": [
    "Comprehensive evaluation of AutoML frameworks: AutoWeka, AutoSKlearn, TPOT, Recipe, ATM, SmartML"
  ],
  "results": [
    "Reveals insights on performance impact of design decisions: time budget, search space size, meta-learning, ensemble construction"
  ],
  "paper_id": "625e1a3d5aee126c0fecaf3a",
  "title": "AutoMLBench: A Comprehensive Experimental Evaluation of Automated\n  Machine Learning Frameworks",
  "abstract": "  With the booming demand for machine learning applications, it has been recognized that the number of knowledgeable data scientists can not scale with the growing data volumes and application needs in our digital world. In response to this demand, several automated machine learning (AutoML) frameworks have been developed to fill the gap of human expertise by automating the process of building machine learning pipelines. Each framework comes with different heuristics-based design decisions. In this study, we present a comprehensive evaluation and comparison of the performance characteristics of six popular AutoML frameworks, namely, AutoWeka, AutoSKlearn, TPOT, Recipe, ATM, and SmartML, across 100 data sets from established AutoML benchmark suites. Our experimental evaluation considers different aspects for its comparison, including the performance impact of several design decisions, including time budget, size of search space, meta-learning, and ensemble construction. The results of our study reveal various interesting insights that can significantly guide and impact the design of AutoML frameworks. "
}