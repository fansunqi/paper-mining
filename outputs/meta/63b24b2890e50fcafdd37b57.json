{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Latency and Reliability Optimization in the Metaverse over Wireless Communications"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Asynchronous Actors Hybrid Critic (AAHC)"
  ],
  "results": [
    "Better solutions with satisfactory training time compared to proposed baselines"
  ],
  "paper_id": "63b24b2890e50fcafdd37b57",
  "title": "Asynchronous Hybrid Reinforcement Learning for Latency and Reliability\n  Optimization in the Metaverse over Wireless Communications",
  "abstract": "  Technology advancements in wireless communications and high-performance Extended Reality (XR) have empowered the developments of the Metaverse. The demand for the Metaverse applications and hence, real-time digital twinning of real-world scenes is increasing. Nevertheless, the replication of 2D physical world images into 3D virtual objects is computationally intensive and requires computation offloading. The disparity in transmitted object dimension (2D as opposed to 3D) leads to asymmetric data sizes in uplink (UL) and downlink (DL). To ensure the reliability and low latency of the system, we consider an asynchronous joint UL-DL scenario where in the UL stage, the smaller data size of the physical world images captured by multiple extended reality users (XUs) will be uploaded to the Metaverse Console (MC) to be construed and rendered. In the DL stage, the larger-size 3D virtual objects need to be transmitted back to the XUs. We design a novel multi-agent reinforcement learning algorithm structure, namely Asynchronous Actors Hybrid Critic (AAHC), to optimize the decisions pertaining to computation offloading and channel assignment in the UL stage and optimize the DL transmission power in the DL stage. Extensive experiments demonstrate that compared to proposed baselines, AAHC obtains better solutions with satisfactory training time. "
}