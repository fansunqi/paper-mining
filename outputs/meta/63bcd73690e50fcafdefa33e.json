{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Multi-UAV Path Learning",
    "Age and Power Optimization in IoT with UAV Battery Recharge"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Deep Q-Network",
    "Function Approximation"
  ],
  "results": [
    "Lower ergodic age",
    "Lower ergodic energy consumption"
  ],
  "paper_id": "63bcd73690e50fcafdefa33e",
  "title": "Multi-UAV Path Learning for Age and Power Optimization in IoT with UAV\n  Battery Recharge",
  "abstract": "  In many emerging Internet of Things (IoT) applications, the freshness of the is an important design criterion. Age of Information (AoI) quantifies the freshness of the received information or status update. This work considers a setup of deployed IoT devices in an IoT network; multiple unmanned aerial vehicles (UAVs) serve as mobile relay nodes between the sensors and the base station. We formulate an optimization problem to jointly plan the UAVs' trajectory, while minimizing the AoI of the received messages and the devices' energy consumption. The solution accounts for the UAVs' battery lifetime and flight time to recharging depots to ensure the UAVs' green operation. The complex optimization problem is efficiently solved using a deep reinforcement learning algorithm. In particular, we propose a deep Q-network, which works as a function approximation to estimate the state-action value function. The proposed scheme is quick to converge and results in a lower ergodic age and ergodic energy consumption when compared with benchmark algorithms such as greedy algorithm (GA), nearest neighbour (NN), and random-walk (RW). "
}