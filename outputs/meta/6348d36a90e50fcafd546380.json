{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Learning Stochastic Dynamics from Samples"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Action Matching"
  ],
  "results": [
    "Competitive performance in diverse set of experiments from biology, physics, and generative modeling"
  ],
  "paper_id": "6348d36a90e50fcafd546380",
  "title": "Action Matching: Learning Stochastic Dynamics from Samples",
  "abstract": "  Learning the continuous dynamics of a system from snapshots of its time evolution is a problem which appears throughout natural sciences and machine learning, including in quantum systems, single-cell biological data, and generative modeling. In these settings, we assume that only uncorrelated samples rather than full trajectory data are available. In order to better understand the systems under observation, we would like to learn a model of the underlying process that allows us to propagate samples in time and thereby simulate entire individual trajectories. In this work, we propose Action Matching, a method for learning a rich family of dynamics using only independent samples from its time evolution. We derive a tractable training objective, which does not rely on explicit assumptions about the underlying dynamics and does not require back-propagation through differential equation or optimal transport solvers. Inspired by connections with optimal transport, we derive extensions of Action Matching to learn stochastic differential equations and dynamics involving creation or destruction of probability mass. Finally, we showcase applications of Action Matching by achieving competitive performance in a diverse set of experiments from biology, physics, and generative modeling. "
}