{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Image classification on ImageNet"
  ],
  "datasets": [
    "ImageNet"
  ],
  "methods": [
    "Neural scaling laws",
    "Shapley values"
  ],
  "results": [
    "Algorithmic improvements have been roughly as important as the scaling of compute",
    "Compute-augmenting algorithmic advances halve compute requirements every nine months"
  ],
  "paper_id": "6397ed4390e50fcafdf42ba8",
  "title": "Algorithmic progress in computer vision",
  "abstract": "  We investigate algorithmic progress in image classification on ImageNet, perhaps the most well-known test bed for computer vision. We estimate a model, informed by work on neural scaling laws, and infer a decomposition of progress into the scaling of compute, data, and algorithms. Using Shapley values to attribute performance improvements, we find that algorithmic improvements have been roughly as important as the scaling of compute for progress computer vision. Our estimates indicate that algorithmic innovations mostly take the form of compute-augmenting algorithmic advances (which enable researchers to get better performance from less compute), not data-augmenting algorithmic advances. We find that compute-augmenting algorithmic advances are made at a pace more than twice as fast as the rate usually associated with Moore's law. In particular, we estimate that compute-augmenting innovations halve compute requirements every nine months (95\\% confidence interval: 4 to 25 months). "
}