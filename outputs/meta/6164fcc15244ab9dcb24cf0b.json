{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Distantly-Supervised Named Entity Recognition (DS-NER)"
  ],
  "datasets": [
    "five real-world datasets"
  ],
  "methods": [
    "Self-Collaborative Denoising Learning (SCDL)",
    "two teacher-student networks",
    "iterative noisy label refinery",
    "self denoising",
    "collaborative denoising"
  ],
  "results": [
    "SCDL is superior to state-of-the-art DS-NER denoising methods"
  ],
  "paper_id": "6164fcc15244ab9dcb24cf0b",
  "title": "Improving Distantly-Supervised Named Entity Recognition with\n  Self-Collaborative Denoising Learning",
  "abstract": "  Distantly supervised named entity recognition (DS-NER) efficiently reduces labor costs but meanwhile intrinsically suffers from the label noise due to the strong assumption of distant supervision. Typically, the wrongly labeled instances comprise numbers of incomplete and inaccurate annotation noise, while most prior denoising works are only concerned with one kind of noise and fail to fully explore useful information in the whole training set. To address this issue, we propose a robust learning paradigm named Self-Collaborative Denoising Learning (SCDL), which jointly trains two teacher-student networks in a mutually-beneficial manner to iteratively perform noisy label refinery. Each network is designed to exploit reliable labels via self denoising, and two networks communicate with each other to explore unreliable annotations by collaborative denoising. Extensive experimental results on five real-world datasets demonstrate that SCDL is superior to state-of-the-art DS-NER denoising methods. "
}