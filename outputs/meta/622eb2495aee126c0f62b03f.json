{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Speaker Verification"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Parameter-Free Attentive Scoring",
    "Scaled Dot Product Attention Mechanism",
    "Different Types of Normalization",
    "Independent vs. Tied Query/Key Estimation",
    "Varying Number of Key-Value Pairs",
    "Pooling Multiple Enrollment Utterance Statistics"
  ],
  "results": [
    "Improves average EER by 10% over the best cosine similarity baseline"
  ],
  "paper_id": "622eb2495aee126c0f62b03f",
  "title": "Parameter-Free Attentive Scoring for Speaker Verification",
  "abstract": "  This paper presents a novel study of parameter-free attentive scoring for speaker verification. Parameter-free scoring provides the flexibility of comparing speaker representations without the need of an accompanying parametric scoring model. Inspired by the attention component in Transformer neural networks, we propose a variant of the scaled dot product attention mechanism to compare enrollment and test segment representations. In addition, this work explores the effect on performance of (i) different types of normalization, (ii) independent versus tied query/key estimation, (iii) varying the number of key-value pairs and (iv) pooling multiple enrollment utterance statistics. Experimental results for a 4 task average show that a simple parameter-free attentive scoring mechanism can improve the average EER by 10% over the best cosine similarity baseline. "
}