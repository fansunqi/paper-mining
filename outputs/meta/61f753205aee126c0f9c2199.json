{
  "code_links": [
    "None"
  ],
  "tasks": [
    "RGB-D SLAM"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Object-Aware Attention Guided Frame Association",
    "Integrating layer-wise object attention information with CNN layer representations"
  ],
  "results": [
    "Improved performance over the baseline"
  ],
  "paper_id": "61f753205aee126c0f9c2199",
  "title": "Exploring Object-Aware Attention Guided Frame Association for RGB-D SLAM",
  "abstract": "  Deep learning models as an emerging topic have shown great progress in various fields. Especially, visualization tools such as class activation mapping methods provided visual explanation on the reasoning of convolutional neural networks (CNNs). By using the gradients of the network layers, it is possible to demonstrate where the networks pay attention during a specific image recognition task. Moreover, these gradients can be integrated with CNN features for localizing more generalized task dependent attentive (salient) objects in scenes. Despite this progress, there is not much explicit usage of this gradient (network attention) information to integrate with CNN representations for object semantics. This can be very useful for visual tasks such as simultaneous localization and mapping (SLAM) where CNN representations of spatially attentive object locations may lead to improved performance. Therefore, in this work, we propose the use of task specific network attention for RGB-D indoor SLAM. To do so, we integrate layer-wise object attention information (layer gradients) with CNN layer representations to improve frame association performance in an RGB-D indoor SLAM method. Experiments show promising results with improved performance over the baseline. "
}