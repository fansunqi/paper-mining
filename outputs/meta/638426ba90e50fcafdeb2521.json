{
  "code_links": [
    "https://nimrodshabtay.github.io/PIP/"
  ],
  "tasks": [
    "Image Reconstruction",
    "Video Reconstruction"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Positional Encoding Image Prior (PIP)",
    "Fourier-Features",
    "Pixel-level MLPs"
  ],
  "results": [
    "Similar performance to DIP with fewer parameters",
    "Extends to video reconstruction"
  ],
  "paper_id": "638426ba90e50fcafdeb2521",
  "title": "PIP: Positional-encoding Image Prior",
  "abstract": "  In Deep Image Prior (DIP), a Convolutional Neural Network (CNN) is fitted to map a latent space to a degraded (e.g. noisy) image but in the process learns to reconstruct the clean image. This phenomenon is attributed to CNN's internal image-prior. We revisit the DIP framework, examining it from the perspective of a neural implicit representation. Motivated by this perspective, we replace the random or learned latent with Fourier-Features (Positional Encoding). We show that thanks to the Fourier features properties, we can replace the convolution layers with simple pixel-level MLPs. We name this scheme ``Positional Encoding Image Prior\" (PIP) and exhibit that it performs very similarly to DIP on various image-reconstruction tasks with much less parameters required. Additionally, we demonstrate that PIP can be easily extended to videos, where 3D-DIP struggles and suffers from instability. Code and additional examples for all tasks, including videos, are available on the project page https://nimrodshabtay.github.io/PIP/ "
}