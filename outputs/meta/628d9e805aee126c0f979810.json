{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Fluid intelligence of machines",
    "Sequence consistency evaluation",
    "Anomaly detection tasks"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Naive few-shot learning",
    "Single SCE with a single optimization step"
  ],
  "results": [
    "Naive deep learning models solve non-trivial versions of the task relatively well",
    "Real-world anomaly detection tasks in visual and auditory modalities"
  ],
  "paper_id": "628d9e805aee126c0f979810",
  "title": "Naive Few-Shot Learning: Uncovering the fluid intelligence of machines",
  "abstract": "  In this paper, we aimed to help bridge the gap between human fluid intelligence - the ability to solve novel tasks without prior training - and the performance of deep neural networks, which typically require extensive prior training. An essential cognitive component for solving intelligence tests, which in humans are used to measure fluid intelligence, is the ability to identify regularities in sequences. This motivated us to construct a benchmark task, which we term \\textit{sequence consistency evaluation} (SCE), whose solution requires the ability to identify regularities in sequences. Given the proven capabilities of deep networks, their ability to solve such tasks after extensive training is expected. Surprisingly, however, we show that naive (randomly initialized) deep learning models that are trained on a \\textit{single} SCE with a \\textit{single} optimization step can still solve non-trivial versions of the task relatively well. We extend our findings to solve, without any prior training, real-world anomaly detection tasks in the visual and auditory modalities. These results demonstrate the fluid-intelligent computational capabilities of deep networks. We discuss the implications of our work for constructing fluid-intelligent machines. "
}