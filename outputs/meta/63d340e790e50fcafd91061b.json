{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Story generation"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Very large pre-trained language models (VLPLMs)"
  ],
  "results": [
    "VLPLMs generate much higher quality stories",
    "Rival human authors in story generation",
    "Tend to 'plagiarise' real stories in scenarios involving world knowledge"
  ],
  "paper_id": "63d340e790e50fcafd91061b",
  "title": "Can Very Large Pretrained Language Models Learn Storytelling With A Few\n  Examples?",
  "abstract": "  While pre-trained language models can generate individually fluent sentences for automatic story generation, they struggle to generate stories that are coherent, sensible and interesting. Current state-of-the-art (SOTA) story generation models explore using higher-level features such as plots or commonsense knowledge to improve the quality of generated stories. Prompt-based learning using very large pre-trained language models (VLPLMs) such as GPT3 has demonstrated impressive performance even across various NLP tasks. In this paper, we present an extensive study using automatic and human evaluation to compare the story generation capability of VLPLMs to those SOTA models in three different datasets where stories differ in style, register and length. Our results show that VLPLMs generate much higher quality stories than other story generation models, and to a certain extent rival human authors, although preliminary investigation also reveals that they tend to ``plagiarise'' real stories in scenarios that involve world knowledge. "
}