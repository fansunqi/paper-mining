{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Person re-identification"
  ],
  "datasets": [
    "FRIDA"
  ],
  "methods": [
    "Spatio-Visual Fusion-Based Feature Fusion"
  ],
  "results": [
    "Outperforms appearance-based deep-learning methods by almost 18% points",
    "Outperforms location-based methods by almost 3% points in matching accuracy"
  ],
  "paper_id": "63a51c5c90e50fcafde93b43",
  "title": "Spatio-Visual Fusion-Based Person Re-Identification for Overhead Fisheye\n  Images",
  "abstract": "  Person re-identification (PRID) has been thoroughly researched in typical surveillance scenarios where various scenes are monitored by side-mounted, rectilinear-lens cameras. To date, few methods have been proposed for fisheye cameras mounted overhead and their performance is lacking. In order to close this performance gap, we propose a multi-feature framework for fisheye PRID where we combine deep-learning, color-based and location-based features by means of novel feature fusion. We evaluate the performance of our framework for various feature combinations on FRIDA, a public fisheye PRID dataset. The results demonstrate that our multi-feature approach outperforms recent appearance-based deep-learning methods by almost 18% points and location-based methods by almost 3% points in matching accuracy. We also demonstrate the potential application of the proposed PRID framework to people counting in large, crowded indoor spaces. "
}