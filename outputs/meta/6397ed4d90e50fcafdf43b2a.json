{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Automated GUI testing",
    "Android app quality assurance"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "AdaT",
    "Deep learning model for rendering state inference"
  ],
  "results": [
    "Accuracy, efficiency, and effectiveness of AdaT",
    "Integration with existing automated testing tools"
  ],
  "paper_id": "6397ed4d90e50fcafdf43b2a",
  "title": "Efficiency Matters: Speeding Up Automated Testing with GUI Rendering\n  Inference",
  "abstract": "  Due to the importance of Android app quality assurance, many automated GUI testing tools have been developed. Although the test algorithms have been improved, the impact of GUI rendering has been overlooked. On the one hand, setting a long waiting time to execute events on fully rendered GUIs slows down the testing process. On the other hand, setting a short waiting time will cause the events to execute on partially rendered GUIs, which negatively affects the testing effectiveness. An optimal waiting time should strike a balance between effectiveness and efficiency. We propose AdaT, a lightweight image-based approach to dynamically adjust the inter-event time based on GUI rendering state. Given the real-time streaming on the GUI, AdaT presents a deep learning model to infer the rendering state, and synchronizes with the testing tool to schedule the next event when the GUI is fully rendered. The evaluations demonstrate the accuracy, efficiency, and effectiveness of our approach. We also integrate our approach with the existing automated testing tool to demonstrate the usefulness of AdaT in covering more activities and executing more events on fully rendered GUIs. "
}