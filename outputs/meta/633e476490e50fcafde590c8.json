{
  "code_links": [
    "https://github.com/Chris210634/metric-learning-using-contextual-similarity"
  ],
  "tasks": [
    "Image retrieval"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Contextual loss"
  ],
  "results": [
    "State-of-the-art across four image retrieval benchmarks"
  ],
  "paper_id": "633e476490e50fcafde590c8",
  "title": "Supervised Metric Learning to Rank for Retrieval via Contextual\n  Similarity Optimization",
  "abstract": "  There is extensive interest in metric learning methods for image retrieval. Many metric learning loss functions focus on learning a correct ranking of training samples, but strongly overfit semantically inconsistent labels and require a large amount of data. To address these shortcomings, we propose a new metric learning method, called contextual loss, which optimizes contextual similarity in addition to cosine similarity. Our contextual loss implicitly enforces semantic consistency among neighbors while converging to the correct ranking. We empirically show that the proposed loss is more robust to label noise, and is less prone to overfitting even when a large portion of train data is withheld. Extensive experiments demonstrate that our method achieves a new state-of-the-art across four image retrieval benchmarks and multiple different evaluation settings. Code is available at: https://github.com/Chris210634/metric-learning-using-contextual-similarity "
}