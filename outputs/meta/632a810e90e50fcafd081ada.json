{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Identifying and Characterizing Behavioral Classes of Radicalization within the QAnon Conspiracy on Twitter"
  ],
  "datasets": [
    "240M tweets collected in the run-up to the 2020 US Presidential election"
  ],
  "methods": [
    "Framework exploiting social interaction and content signals",
    "Multivariate metric of radicalization"
  ],
  "results": [
    "Separation of users into distinct classes of behaviors",
    "Analysis of Twitter's moderation policies",
    "Findings refine understanding of online radicalization processes"
  ],
  "paper_id": "632a810e90e50fcafd081ada",
  "title": "Identifying and Characterizing Behavioral Classes of Radicalization\n  within the QAnon Conspiracy on Twitter",
  "abstract": "  Social media provide a fertile ground where conspiracy theories and radical ideas can flourish, reach broad audiences, and sometimes lead to hate or violence beyond the online world itself. QAnon represents a notable example of a political conspiracy that started out on social media but turned mainstream, in part due to public endorsement by influential political figures. Nowadays, QAnon conspiracies often appear in the news, are part of political rhetoric, and are espoused by significant swaths of people in the United States. It is therefore crucial to understand how such a conspiracy took root online, and what led so many social media users to adopt its ideas. In this work, we propose a framework that exploits both social interaction and content signals to uncover evidence of user radicalization or support for QAnon. Leveraging a large dataset of 240M tweets collected in the run-up to the 2020 US Presidential election, we define and validate a multivariate metric of radicalization. We use that to separate users in distinct, naturally-emerging, classes of behaviors associated to radicalization processes, from self-declared QAnon supporters to hyper-active conspiracy promoters. We also analyze the impact of Twitter's moderation policies on the interactions among different classes: we discover aspects of moderation that succeed, yielding a substantial reduction in the endorsement received by hyper-active QAnon accounts. But we also uncover where moderation fails, showing how QAnon content amplifiers are not deterred or affected by Twitter intervention. Our findings refine our understanding of online radicalization processes, reveal effective and ineffective aspects of moderation, and call for the need to further investigate the role social media play in the spread of conspiracies. "
}