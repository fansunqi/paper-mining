{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Polyphonic melody extraction"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Meta-learning-based adaptation"
  ],
  "results": [
    "Outperforms existing state-of-the-art non-adaptive polyphonic melody extraction algorithms"
  ],
  "paper_id": "635753cc90e50fcafddddc06",
  "title": "Deep domain adaptation for polyphonic melody extraction",
  "abstract": "  Extraction of the predominant pitch from polyphonic audio is one of the fundamental tasks in the field of music information retrieval and computational musicology. To accomplish this task using machine learning, a large amount of labeled audio data is required to train the model that predicts the pitch contour. But a classical model pre-trained on data from one domain (source), e.g, songs of a particular singer or genre, may not perform comparatively well in extracting melody from other domains (target). The performance of such models can be boosted by adapting the model using some annotated data in the target domain. In this work, we study various adaptation techniques applied to machine learning models for polyphonic melody extraction. Experimental results show that meta-learning-based adaptation performs better than simple fine-tuning. In addition to this, we find that this method outperforms the existing state-of-the-art non-adaptive polyphonic melody extraction algorithms. "
}