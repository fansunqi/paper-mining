{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Interpretable Inference Rules Generation"
  ],
  "datasets": [
    "Scientific QA datasets"
  ],
  "methods": [
    "Neural language modeling",
    "Guided generation",
    "Semiparametric dense retrieval"
  ],
  "results": [
    "Competitive performance on scientific QA datasets"
  ],
  "paper_id": "6327dda690e50fcafd67df4f",
  "title": "Dynamic Generation of Interpretable Inference Rules in a Neuro-Symbolic\n  Expert System",
  "abstract": "  We present an approach for systematic reasoning that produces human interpretable proof trees grounded in a factbase. Our solution evokes classic Prolog-based inference engines, where we replace handcrafted rules through a combination of neural language modeling, guided generation, and semiparametric dense retrieval. This novel reasoning engine, NELLIE, dynamically instantiates interpretable inference rules that capture and score entailment (de)compositions over natural language statements. NELLIE shows competitive performance on scientific QA datasets requiring structured explanations over multiple facts while fully grounding justification proofs in verified knowledge. "
}