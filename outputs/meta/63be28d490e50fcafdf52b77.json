{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Speech Emotion Recognition"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Synthetic Emotional Speech Augmentation",
    "end-to-end text-to-speech (TTS) system",
    "extended Tacotron architecture",
    "encoders for speaker and emotion embeddings",
    "sequence-to-sequence text generator",
    "WaveRNN"
  ],
  "results": [
    "Quality of the generated emotional speech can significantly improve SER performance",
    "Higher mean opinion score (MOS) compared to the baseline"
  ],
  "paper_id": "63be28d490e50fcafdf52b77",
  "title": "Generative Emotional AI for Speech Emotion Recognition: The Case for\n  Synthetic Emotional Speech Augmentation",
  "abstract": "  Despite advances in deep learning, current state-of-the-art speech emotion recognition (SER) systems still have poor performance due to a lack of speech emotion datasets. This paper proposes augmenting SER systems with synthetic emotional speech generated by an end-to-end text-to-speech (TTS) system based on an extended Tacotron architecture. The proposed TTS system includes encoders for speaker and emotion embeddings, a sequence-to-sequence text generator for creating Mel-spectrograms, and a WaveRNN to generate audio from the Mel-spectrograms. Extensive experiments show that the quality of the generated emotional speech can significantly improve SER performance on multiple datasets, as demonstrated by a higher mean opinion score (MOS) compared to the baseline. The generated samples were also effective at augmenting SER performance. "
}