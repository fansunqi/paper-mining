{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Robust perception in autonomous racing under adverse weather conditions"
  ],
  "datasets": [
    "Synthesised adverse condition datasets generated using CycleGAN"
  ],
  "methods": [
    "CycleGAN for data augmentation",
    "Comparative analysis of five object detectors"
  ],
  "results": [
    "Average improvement of 42.7 mAP in night-time conditions",
    "Average improvement of 4.4 mAP in presence of droplets"
  ],
  "paper_id": "61dcf5495244ab9dcb1fb75a",
  "title": "Vision in adverse weather: Augmentation using CycleGANs with various\n  object detectors for robust perception in autonomous racing",
  "abstract": "  In an autonomous driving system, perception - identification of features and objects from the environment - is crucial. In autonomous racing, high speeds and small margins demand rapid and accurate detection systems. During the race, the weather can change abruptly, causing significant degradation in perception, resulting in ineffective manoeuvres. In order to improve detection in adverse weather, deep-learning-based models typically require extensive datasets captured in such conditions - the collection of which is a tedious, laborious, and costly process. However, recent developments in CycleGAN architectures allow the synthesis of highly realistic scenes in multiple weather conditions. To this end, we introduce an approach of using synthesised adverse condition datasets in autonomous racing (generated using CycleGAN) to improve the performance of four out of five state-of-the-art detectors by an average of 42.7 and 4.4 mAP percentage points in the presence of night-time conditions and droplets, respectively. Furthermore, we present a comparative analysis of five object detectors - identifying the optimal pairing of detector and training data for use during autonomous racing in challenging conditions. "
}