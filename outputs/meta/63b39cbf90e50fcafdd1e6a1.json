{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Online learning",
    "Control",
    "Memory-based learning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Frank-Wolfe Optimization",
    "Hedge algorithms",
    "OCO-M"
  ],
  "results": [
    "Bounded dynamic regret",
    "Online control of linear time-varying systems",
    "Memory-based controller"
  ],
  "paper_id": "63b39cbf90e50fcafdd1e6a1",
  "title": "Efficient Online Learning with Memory via Frank-Wolfe Optimization:\n  Algorithms with Bounded Dynamic Regret and Applications to Control",
  "abstract": "  Projection operations are a typical computation bottleneck in online learning. In this paper, we enable projection-free online learning within the framework of Online Convex Optimization with Memory (OCO-M) -- OCO-M captures how the history of decisions affects the current outcome by allowing the online learning loss functions to depend on both current and past decisions. Particularly, we introduce the first projection-free meta-base learning algorithm with memory that minimizes dynamic regret, i.e., that minimizes the suboptimality against any sequence of time-varying decisions. We are motivated by artificial intelligence applications where autonomous agents need to adapt to time-varying environments in real-time, accounting for how past decisions affect the present. Examples of such applications are: online control of dynamical systems; statistical arbitrage; and time series prediction. The algorithm builds on the Online Frank-Wolfe (OFW) and Hedge algorithms. We demonstrate how our algorithm can be applied to the online control of linear time-varying systems in the presence of unpredictable process noise. To this end, we develop a controller with memory and bounded dynamic regret against any optimal time-varying linear feedback control policy. We validate our algorithm in simulated scenarios of online control of linear time-invariant systems. "
}