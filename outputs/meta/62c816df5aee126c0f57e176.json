{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Generic Event Boundary Captioning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Dual-Stream Transformer",
    "pre-trained models",
    "boundary as hints",
    "word-level ensemble strategy"
  ],
  "results": [
    "promising results on the GEBC test split"
  ],
  "paper_id": "62c816df5aee126c0f57e176",
  "title": "Dual-Stream Transformer for Generic Event Boundary Captioning",
  "abstract": "  This paper describes our champion solution for the CVPR2022 Generic Event Boundary Captioning (GEBC) competition. GEBC requires the captioning model to have a comprehension of instantaneous status changes around the given video boundary, which makes it much more challenging than conventional video captioning task. In this paper, a Dual-Stream Transformer with improvements on both video content encoding and captions generation is proposed: (1) We utilize three pre-trained models to extract the video features from different granularities. Moreover, we exploit the types of boundary as hints to help the model generate captions. (2) We particularly design an model, termed as Dual-Stream Transformer, to learn discriminative representations for boundary captioning. (3) Towards generating content-relevant and human-like captions, we improve the description quality by designing a word-level ensemble strategy. The promising results on the GEBC test split demonstrate the efficacy of our proposed model. "
}