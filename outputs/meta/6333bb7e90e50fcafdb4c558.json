{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Parameter estimation for large-scale multi-agent models"
  ],
  "datasets": [
    "Synthetic time series data of the SIR model",
    "Harris-Wilson model of economic activity on a network"
  ],
  "methods": [
    "Neural differential equations",
    "Multi-agent models as forward solvers",
    "Neural network for parameter extraction"
  ],
  "results": [
    "Model calibration orders of magnitude more accurate than previous studies",
    "Computationally 195 to 390 times faster"
  ],
  "paper_id": "6333bb7e90e50fcafdb4c558",
  "title": "Neural parameter calibration for large-scale multi-agent models",
  "abstract": "  Computational models have become a powerful tool in the quantitative sciences to understand the behaviour of complex systems that evolve in time. However, they often contain a potentially large number of free parameters whose values cannot be obtained from theory but need to be inferred from data. This is especially the case for models in the social sciences, economics, or computational epidemiology. Yet many current parameter estimation methods are mathematically involved and computationally slow to run. In this paper we present a computationally simple and fast method to retrieve accurate probability densities for model parameters using neural differential equations. We present a pipeline comprising multi-agent models acting as forward solvers for systems of ordinary or stochastic differential equations, and a neural network to then extract parameters from the data generated by the model. The two combined create a powerful tool that can quickly estimate densities on model parameters, even for very large systems. We demonstrate the method on synthetic time series data of the SIR model of the spread of infection, and perform an in-depth analysis of the Harris-Wilson model of economic activity on a network, representing a non-convex problem. For the latter, we apply our method both to synthetic data and to data of economic activity across Greater London. We find that our method calibrates the model orders of magnitude more accurately than a previous study of the same dataset using classical techniques, while running between 195 and 390 times faster. "
}