{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Face Generation"
  ],
  "datasets": [
    "Synthesized sketches",
    "Hand-drawn sketches"
  ],
  "methods": [
    "W-W+ encoder architecture",
    "Semantic feature matching loss",
    "Sketch semantic interpretation approach"
  ],
  "results": [
    "Superiority over existing approaches on semantics-preserving and generalization ability"
  ],
  "paper_id": "637ee0ee90e50fcafd0f7058",
  "title": "Semantics-Preserving Sketch Embedding for Face Generation",
  "abstract": "  With recent advances in image-to-image translation tasks, remarkable progress has been witnessed in generating face images from sketches. However, existing methods frequently fail to generate images with details that are semantically and geometrically consistent with the input sketch, especially when various decoration strokes are drawn. To address this issue, we introduce a novel W-W+ encoder architecture to take advantage of the high expressive power of W+ space and semantic controllability of W space. We introduce an explicit intermediate representation for sketch semantic embedding. With a semantic feature matching loss for effective semantic supervision, our sketch embedding precisely conveys the semantics in the input sketches to the synthesized images. Moreover, a novel sketch semantic interpretation approach is designed to automatically extract semantics from vectorized sketches. We conduct extensive experiments on both synthesized sketches and hand-drawn sketches, and the results demonstrate the superiority of our method over existing approaches on both semantics-preserving and generalization ability. "
}