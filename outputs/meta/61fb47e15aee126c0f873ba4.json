{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Investigate trust in anthropomorphic agents"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Online experiment with cognitive tasks (calculation, emotion recognition)"
  ],
  "results": [
    "Trust in social robot is between that in AI agent and human",
    "Manipulating anthropomorphic features may help calibrate trust"
  ],
  "paper_id": "61fb47e15aee126c0f873ba4",
  "title": "Experimental Investigation of Trust in Anthropomorphic Agents as Task\n  Partners",
  "abstract": "  This study investigated whether human trust in a social robot with anthropomorphic physicality is similar to that in an AI agent or in a human in order to clarify how anthropomorphic physicality influences human trust in an agent. We conducted an online experiment using two types of cognitive tasks, calculation and emotion recognition tasks, where participants answered after referring to the answers of an AI agent, a human, or a social robot. During the experiment, the participants rated their trust levels in their partners. As a result, trust in the social robot was basically neither similar to that in the AI agent nor in the human and instead settled between them. The results showed a possibility that manipulating anthropomorphic features would help assist human users in appropriately calibrating trust in an agent. "
}