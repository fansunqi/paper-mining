{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Dimensionality reduction",
    "Data visualization explanation"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Contrasting explanations for dimensionality reduction"
  ],
  "results": [
    "None"
  ],
  "paper_id": "62aa9fb55aee126c0fa5c966",
  "title": "\"Why Here and Not There?\" -- Diverse Contrasting Explanations of\n  Dimensionality Reduction",
  "abstract": "  Dimensionality reduction is a popular preprocessing and a widely used tool in data mining. Transparency, which is usually achieved by means of explanations, is nowadays a widely accepted and crucial requirement of machine learning based systems like classifiers and recommender systems. However, transparency of dimensionality reduction and other data mining tools have not been considered in much depth yet, still it is crucial to understand their behavior -- in particular practitioners might want to understand why a specific sample got mapped to a specific location.   In order to (locally) understand the behavior of a given dimensionality reduction method, we introduce the abstract concept of contrasting explanations for dimensionality reduction, and apply a realization of this concept to the specific application of explaining two dimensional data visualization. "
}