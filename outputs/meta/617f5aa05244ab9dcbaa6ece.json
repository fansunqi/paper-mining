{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Weakly Supervised Concept Map Generation",
    "Document Classification"
  ],
  "datasets": [
    "Three real-world corpora"
  ],
  "methods": [
    "GT-D2G (Graph Translation-based Document To Graph)",
    "Generalized NLP pipelines",
    "Weak supervision of downstream task labels"
  ],
  "results": [
    "GT-D2G beats other concept map generation methods",
    "Demonstrated through human evaluation and case studies",
    "Validated labeling efficiency in label-efficient learning",
    "Flexibility of generated graph sizes in controlled hyper-parameter studies"
  ],
  "paper_id": "617f5aa05244ab9dcbaa6ece",
  "title": "Weakly Supervised Concept Map Generation through Task-Guided Graph\n  Translation",
  "abstract": "  Recent years have witnessed the rapid development of concept map generation techniques due to their advantages in providing well-structured summarization of knowledge from free texts. Traditional unsupervised methods do not generate task-oriented concept maps, whereas deep generative models require large amounts of training data. In this work, we present GT-D2G (Graph Translation-based Document To Graph), an automatic concept map generation framework that leverages generalized NLP pipelines to derive semantic-rich initial graphs, and translates them into more concise structures under the weak supervision of downstream task labels. The concept maps generated by GT-D2G can provide interpretable summarization of structured knowledge for the input texts, which are demonstrated through human evaluation and case studies on three real-world corpora. Further experiments on the downstream task of document classification show that GT-D2G beats other concept map generation methods. Moreover, we specifically validate the labeling efficiency of GT-D2G in the label-efficient learning setting and the flexibility of generated graph sizes in controlled hyper-parameter studies. "
}