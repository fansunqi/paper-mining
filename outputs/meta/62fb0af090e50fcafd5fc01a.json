{
  "code_links": [
    "None"
  ],
  "tasks": [
    "3D scene geometry decomposition and manipulation from 2D images"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "DM-NeRF",
    "implicit neural representation techniques",
    "neural radiance fields",
    "inverse query algorithm"
  ],
  "results": [
    "accurately decompose all 3D objects from 2D views",
    "manipulate any specified 3D object shape in 3D space"
  ],
  "paper_id": "62fb0af090e50fcafd5fc01a",
  "title": "DM-NeRF: 3D Scene Geometry Decomposition and Manipulation from 2D Images",
  "abstract": "  In this paper, we study the problem of 3D scene geometry decomposition and manipulation from 2D views. By leveraging the recent implicit neural representation techniques, particularly the appealing neural radiance fields, we introduce an object field component to learn unique codes for all individual objects in 3D space only from 2D supervision. The key to this component is a series of carefully designed loss functions to enable every 3D point, especially in non-occupied space, to be effectively optimized even without 3D labels. In addition, we introduce an inverse query algorithm to freely manipulate any specified 3D object shape in the learned scene representation. Notably, our manipulation algorithm can explicitly tackle key issues such as object collisions and visual occlusions. Our method, called DM-NeRF, is among the first to simultaneously reconstruct, decompose, manipulate and render complex 3D scenes in a single pipeline. Extensive experiments on three datasets clearly show that our method can accurately decompose all 3D objects from 2D views, allowing any interested object to be freely manipulated in 3D space such as translation, rotation, size adjustment, and deformation. "
}