{
  "code_links": [
    "None"
  ],
  "tasks": [
    "3D Semantic Instance Segmentation"
  ],
  "datasets": [
    "ScanNet",
    "S3DIS",
    "STPLS3D",
    "ScanNet200"
  ],
  "methods": [
    "Mask3D",
    "Transformer-based approach"
  ],
  "results": [
    "+6.2 mAP on ScanNet test",
    "+10.1 mAP on S3DIS 6-fold",
    "+11.2 mAP on STPLS3D",
    "+12.4 mAP on ScanNet200 test"
  ],
  "paper_id": "633f98d790e50fcafd78e2ad",
  "title": "Mask3D: Mask Transformer for 3D Semantic Instance Segmentation",
  "abstract": "  Modern 3D semantic instance segmentation approaches predominantly rely on specialized voting mechanisms followed by carefully designed geometric clustering techniques. Building on the successes of recent Transformer-based methods for object detection and image segmentation, we propose the first Transformer-based approach for 3D semantic instance segmentation. We show that we can leverage generic Transformer building blocks to directly predict instance masks from 3D point clouds. In our model called Mask3D each object instance is represented as an instance query. Using Transformer decoders, the instance queries are learned by iteratively attending to point cloud features at multiple scales. Combined with point features, the instance queries directly yield all instance masks in parallel. Mask3D has several advantages over current state-of-the-art approaches, since it neither relies on (1) voting schemes which require hand-selected geometric properties (such as centers) nor (2) geometric grouping mechanisms requiring manually-tuned hyper-parameters (e.g. radii) and (3) enables a loss that directly optimizes instance masks. Mask3D sets a new state-of-the-art on ScanNet test (+6.2 mAP), S3DIS 6-fold (+10.1 mAP), STPLS3D (+11.2 mAP) and ScanNet200 test (+12.4 mAP). "
}