{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Class-Incremental Learning"
  ],
  "datasets": [
    "CIFAR100",
    "TinyImageNet"
  ],
  "methods": [
    "stochastic scenario generators",
    "replay strategy"
  ],
  "results": [
    "outperforms other replay approaches"
  ],
  "paper_id": "63d7352390e50fcafda30246",
  "title": "Class-Incremental Learning with Repetition",
  "abstract": "  Real-world data streams naturally include the repetition of previous concepts. From a Continual Learning (CL) perspective, repetition is a property of the environment and, unlike replay, cannot be controlled by the user. Nowadays, Class-Incremental scenarios represent the leading test-bed for assessing and comparing CL strategies. This family of scenarios is very easy to use, but it never allows revisiting previously seen classes, thus completely disregarding the role of repetition. We focus on the family of Class-Incremental with Repetition (CIR) scenarios, where repetition is embedded in the definition of the stream. We propose two stochastic scenario generators that produce a wide range of CIR scenarios starting from a single dataset and a few control parameters. We conduct the first comprehensive evaluation of repetition in CL by studying the behavior of existing CL strategies under different CIR scenarios. We then present a novel replay strategy that exploits repetition and counteracts the natural imbalance present in the stream. On both CIFAR100 and TinyImageNet, our strategy outperforms other replay approaches, which are not designed for environments with repetition. "
}