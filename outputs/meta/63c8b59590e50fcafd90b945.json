{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Adaptive Inference",
    "Early Exit for DNNs"
  ],
  "datasets": [
    "CIFAR-10",
    "CIFAR-100",
    "ImageNet",
    "SST-2",
    "AgNews"
  ],
  "methods": [
    "EENet",
    "Multi-objective learning",
    "Early exit utility scores"
  ],
  "results": [
    "Performance improvements compared to existing early exit techniques"
  ],
  "paper_id": "63c8b59590e50fcafd90b945",
  "title": "EENet: Learning to Early Exit for Adaptive Inference",
  "abstract": "  Budgeted adaptive inference with early exits is an emerging technique to improve the computational efficiency of deep neural networks (DNNs) for edge AI applications with limited resources at test time. This method leverages the fact that different test data samples may not require the same amount of computation for a correct prediction. By allowing early exiting from full layers of DNN inference for some test examples, we can reduce latency and improve throughput of edge inference while preserving performance. Although there have been numerous studies on designing specialized DNN architectures for training early-exit enabled DNN models, most of the existing work employ hand-tuned or manual rule-based early exit policies. In this study, we introduce a novel multi-exit DNN inference framework, coined as EENet, which leverages multi-objective learning to optimize the early exit policy for a trained multi-exit DNN under a given inference budget. This paper makes two novel contributions. First, we introduce the concept of early exit utility scores by combining diverse confidence measures with class-wise prediction scores to better estimate the correctness of test-time predictions at a given exit. Second, we train a lightweight, budget-driven, multi-objective neural network over validation predictions to learn the exit assignment scheduling for query examples at test time. The EENet early exit scheduler optimizes both the distribution of test samples to different exits and the selection of the exit utility thresholds such that the given inference budget is satisfied while the performance metric is maximized. Extensive experiments are conducted on five benchmarks, including three image datasets (CIFAR-10, CIFAR-100, ImageNet) and two NLP datasets (SST-2, AgNews). The results demonstrate the performance improvements of EENet compared to existing representative early exit techniques. "
}