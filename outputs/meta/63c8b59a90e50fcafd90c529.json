{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Online Learning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Optimistically Tempered Online Learning"
  ],
  "results": [
    "Dynamic regret bounds",
    "Experimental validation of the usefulness of the OT approach"
  ],
  "paper_id": "63c8b59a90e50fcafd90c529",
  "title": "Optimistically Tempered Online Learning",
  "abstract": "Optimistic Online Learning algorithms have been developed to exploit expert\nadvices, assumed optimistically to be always useful. However, it is legitimate\nto question the relevance of such advices w.r.t. the learning\ninformation provided by gradient-based online algorithms. In this work, we\nchallenge the confidence assumption on the expert and develop the\noptimistically tempered (OT) online learning framework as well as OT\nadaptations of online algorithms. Our algorithms come with sound theoretical\nguarantees in the form of dynamic regret bounds, and we eventually provide\nexperimental validation of the usefulness of the OT approach."
}