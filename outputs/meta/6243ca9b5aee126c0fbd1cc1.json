{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Interpretability of tree-ensemble algorithms",
    "Binary classification",
    "Regression",
    "Multi-label classification",
    "Time-to-event tasks"
  ],
  "datasets": [
    "89 real-world datasets"
  ],
  "methods": [
    "Bellatrex (Building Explanations through a LocaLly AccuraTe Rule EXtractor)",
    "Pre-selecting rules",
    "Vector representation of rules",
    "Low-dimensional projection",
    "Clustering rule representations"
  ],
  "results": [
    "Bellatrex can handle multiple tasks within the same framework",
    "Surrogate model approximates ensemble model performance with few trees",
    "Substantially outperforms other explainable methods in predictive performance"
  ],
  "paper_id": "6243ca9b5aee126c0fbd1cc1",
  "title": "BELLATREX: Building Explanations through a LocaLly AccuraTe Rule\n  EXtractor",
  "abstract": "  Tree-ensemble algorithms, such as random forest, are effective machine learning methods popular for their flexibility, high performance, and robustness to overfitting. However, since multiple learners are combined, they are not as interpretable as a single decision tree. In this work we propose a novel method that is Building Explanations through a LocalLy AccuraTe Rule EXtractor (Bellatrex), and is able to explain the forest prediction for a given test instance with only a few diverse rules. Starting from the decision trees generated by a random forest, our method 1) pre-selects a subset of the rules used to make the prediction, 2) creates a vector representation of such rules, 3) projects them to a low-dimensional space, 4) clusters such representations to pick a rule from each cluster to explain the instance prediction. We test the effectiveness of Bellatrex on 89 real-world datasets and we demonstrate the validity of our method for binary classification, regression, multi-label classification and time-to-event tasks. To the best of our knowledge, it is the first time that an interpretability toolbox can handle all these tasks within the same framework. We also show that our extracted surrogate model can approximate the performance of the corresponding ensemble model in all considered tasks, while selecting only few trees from the whole forest. We also show that our proposed approach substantially outperforms other explainable methods in terms of predictive performance. "
}