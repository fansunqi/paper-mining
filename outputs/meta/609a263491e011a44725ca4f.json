{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Mathematical analysis of deep learning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Overview of modern approaches to deep learning questions",
    "Analysis of overparametrized neural networks",
    "Role of depth in deep architectures",
    "Absence of curse of dimensionality",
    "Optimization performance in non-convex problems",
    "Understanding learned features",
    "Performance in physical problems",
    "Architecture aspects affecting learning behavior"
  ],
  "results": [
    "Partial answers to key deep learning research questions"
  ],
  "paper_id": "609a263491e011a44725ca4f",
  "title": "The Modern Mathematics of Deep Learning",
  "abstract": "  We describe the new field of mathematical analysis of deep learning. This field emerged around a list of research questions that were not answered within the classical framework of learning theory. These questions concern: the outstanding generalization power of overparametrized neural networks, the role of depth in deep architectures, the apparent absence of the curse of dimensionality, the surprisingly successful optimization performance despite the non-convexity of the problem, understanding what features are learned, why deep architectures perform exceptionally well in physical problems, and which fine aspects of an architecture affect the behavior of a learning task in which way. We present an overview of modern approaches that yield partial answers to these questions. For selected approaches, we describe the main ideas in more detail. "
}