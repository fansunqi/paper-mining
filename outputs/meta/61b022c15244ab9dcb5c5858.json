{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Underwater vehicle manipulator system scene mapping"
  ],
  "datasets": [
    "Costa Rican continental shelf margin dataset",
    "Shallow reef survey dataset"
  ],
  "methods": [
    "Hybrid Visual SLAM",
    "GPU accelerated SIFT features",
    "Graph optimization framework",
    "Stereo camera feature mapping",
    "Fisheye camera feature fusion"
  ],
  "results": [
    "High accuracy in natural seafloor environments",
    "Suitability for diverse seafloor environments"
  ],
  "paper_id": "61b022c15244ab9dcb5c5858",
  "title": "Hybrid Visual SLAM for Underwater Vehicle Manipulator Systems",
  "abstract": "  This paper presents a novel visual feature based scene mapping method for underwater vehicle manipulator systems (UVMSs), with specific emphasis on robust mapping in natural seafloor environments. Our method uses GPU accelerated SIFT features in a graph optimization framework to build a feature map. The map scale is constrained by features from a vehicle mounted stereo camera, and we exploit the dynamic positioning capability of the manipulator system by fusing features from a wrist mounted fisheye camera into the map to extend it beyond the limited viewpoint of the vehicle mounted cameras. Our hybrid SLAM method is evaluated on challenging image sequences collected with a UVMS in natural deep seafloor environments of the Costa Rican continental shelf margin, and we also evaluate the stereo only mode on a shallow reef survey dataset. Results on these datasets demonstrate the high accuracy of our system and suitability for operating in diverse and natural seafloor environments. We also contribute these datasets for public use. "
}