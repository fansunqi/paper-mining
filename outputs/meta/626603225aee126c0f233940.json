{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Multimodal intent and trajectory prediction for vehicles in parking lots"
  ],
  "datasets": [
    "first public 4K video dataset of human driving in parking lots"
  ],
  "methods": [
    "CNN",
    "Transformer"
  ],
  "results": [
    "outperform existing models in accuracy",
    "allow an arbitrary number of modes",
    "encode complex multi-agent scenarios",
    "adapt to different parking maps"
  ],
  "paper_id": "626603225aee126c0f233940",
  "title": "ParkPredict+: Multimodal Intent and Motion Prediction for Vehicles in\n  Parking Lots with CNN and Transformer",
  "abstract": "  The problem of multimodal intent and trajectory prediction for human-driven vehicles in parking lots is addressed in this paper. Using models designed with CNN and Transformer networks, we extract temporal-spatial and contextual information from trajectory history and local bird's eye view (BEV) semantic images, and generate predictions about intent distribution and future trajectory sequences. Our methods outperform existing models in accuracy, while allowing an arbitrary number of modes, encoding complex multi-agent scenarios, and adapting to different parking maps. To train and evaluate our method, we present the first public 4K video dataset of human driving in parking lots with accurate annotation, high frame rate, and rich traffic scenarios. "
}