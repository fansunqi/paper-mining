{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Graph data generative models"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Micro-macro training objective",
    "GraphVAE"
  ],
  "results": [
    "Graph quality scores improved up to 2 orders of magnitude",
    "Maintains GraphVAE generation speed advantage"
  ],
  "paper_id": "63608e5190e50fcafdee12d0",
  "title": "Micro and Macro Level Graph Modeling for Graph Variational Auto-Encoders",
  "abstract": "  Generative models for graph data are an important research topic in machine learning. Graph data comprise two levels that are typically analyzed separately: node-level properties such as the existence of a link between a pair of nodes, and global aggregate graph-level statistics, such as motif counts. This paper proposes a new multi-level framework that jointly models node-level properties and graph-level statistics, as mutually reinforcing sources of information. We introduce a new micro-macro training objective for graph generation that combines node-level and graph-level losses. We utilize the micro-macro objective to improve graph generation with a GraphVAE, a well-established model based on graph-level latent variables, that provides fast training and generation time for medium-sized graphs. Our experiments show that adding micro-macro modeling to the GraphVAE model improves graph quality scores up to 2 orders of magnitude on five benchmark datasets, while maintaining the GraphVAE generation speed advantage. "
}