{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Inductive Relation Prediction",
    "Explainable Inductive Relation Prediction"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Sentence Transformer",
    "Knowledge Reasoning Sentence Transformer (KRST)",
    "Relation path coverage",
    "Relation path confidence"
  ],
  "results": [
    "Best performance in most transductive and inductive test cases (4 of 6)",
    "Best performance in 11 of 12 few-shot test cases"
  ],
  "paper_id": "63b63fd290e50fcafd8f5d64",
  "title": "Multi-Aspect Explainable Inductive Relation Prediction by Sentence\n  Transformer",
  "abstract": "  Recent studies on knowledge graphs (KGs) show that path-based methods empowered by pre-trained language models perform well in the provision of inductive and explainable relation predictions. In this paper, we introduce the concepts of relation path coverage and relation path confidence to filter out unreliable paths prior to model training to elevate the model performance. Moreover, we propose Knowledge Reasoning Sentence Transformer (KRST) to predict inductive relations in KGs. KRST is designed to encode the extracted reliable paths in KGs, allowing us to properly cluster paths and provide multi-aspect explanations. We conduct extensive experiments on three real-world datasets. The experimental results show that compared to SOTA models, KRST achieves the best performance in most transductive and inductive test cases (4 of 6), and in 11 of 12 few-shot test cases. "
}