{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Hybrid ensemble for regression"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Hybrid ensemble with negative correlation learning",
    "Interior-point filtering linear-search algorithm",
    "Incorporates negative correlation learning as a penalty term"
  ],
  "results": [
    "NCL ensemble outperforms simple average and other state-of-the-art weighting methods",
    "Comparable accuracy to potential optimal sub-models"
  ],
  "paper_id": "606d838991e011c5ec0d7cf3",
  "title": "A hybrid ensemble method with negative correlation learning for\n  regression",
  "abstract": "  Hybrid ensemble, an essential branch of ensembles, has flourished in the regression field, with studies confirming diversity's importance. However, previous ensembles consider diversity in the sub-model training stage, with limited improvement compared to single models. In contrast, this study automatically selects and weights sub-models from a heterogeneous model pool. It solves an optimization problem using an interior-point filtering linear-search algorithm. The objective function innovatively incorporates negative correlation learning as a penalty term, with which a diverse model subset can be selected. The best sub-models from each model class are selected to build the NCL ensemble, which performance is better than the simple average and other state-of-the-art weighting methods. It is also possible to improve the NCL ensemble with a regularization term in the objective function. In practice, it is difficult to conclude the optimal sub-model for a dataset prior due to the model uncertainty. Regardless, our method would achieve comparable accuracy as the potential optimal sub-models. In conclusion, the value of this study lies in its ease of use and effectiveness, allowing the hybrid ensemble to embrace diversity and accuracy. "
}