{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Statistical relational AI",
    "Probabilistic logic programming"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "DC#",
    "FO-CS-LW"
  ],
  "results": [
    "None"
  ],
  "paper_id": "61f360c45aee126c0f7d5d17",
  "title": "First-Order Context-Specific Likelihood Weighting in Hybrid\n  Probabilistic Logic Programs",
  "abstract": "  Statistical relational AI and probabilistic logic programming have so far mostly focused on discrete probabilistic models. The reasons for this is that one needs to provide constructs to succinctly model the independencies in such models, and also provide efficient inference.   Three types of independencies are important to represent and exploit for scalable inference in hybrid models: conditional independencies elegantly modeled in Bayesian networks, context-specific independencies naturally represented by logical rules, and independencies amongst attributes of related objects in relational models succinctly expressed by combining rules.   This paper introduces a hybrid probabilistic logic programming language, DC#, which integrates distributional clauses' syntax and semantics principles of Bayesian logic programs. It represents the three types of independencies qualitatively. More importantly, we also introduce the scalable inference algorithm FO-CS-LW for DC#. FO-CS-LW is a first-order extension of the context-specific likelihood weighting algorithm (CS-LW), a novel sampling method that exploits conditional independencies and context-specific independencies in ground models. The FO-CS-LW algorithm upgrades CS-LW with unification and combining rules to the first-order case. "
}