{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Physical assistance in human-robot conjoined actions"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "SUPER-MAN concept",
    "Admittance-type interface",
    "Human-robot interaction controller",
    "Supernumerary robotic body",
    "MOCA-MAN system",
    "Kairos-MAN system",
    "Whole-body controllers"
  ],
  "results": [
    "Quantitative performance in effort-demanding and dexterous tasks",
    "Qualitative results from NASA-TLX questionnaire"
  ],
  "paper_id": "61e781675244ab9dcbf9a684",
  "title": "SUPER-MAN: SUPERnumerary Robotic Bodies for Physical Assistance in\n  HuMAN-Robot Conjoined Actions",
  "abstract": "  This paper presents a mobile supernumerary robotic approach to physical assistance in human-robot conjoined actions. The study starts with a description of the SUPER-MAN concept. The idea is to develop and utilize mobile collaborative systems that can follow human loco-manipulation commands to perform industrial tasks through three main components: i) an admittance-type interface, ii) a human-robot interaction controller, and iii) a supernumerary robotic body. Next, we present two possible implementations within the framework from theoretical and hardware perspectives. The first system is called MOCA-MAN and comprises a redundant torque-controlled robotic arm and an omnidirectional mobile platform. The second one is called Kairos-MAN, formed by a high-payload 6-DoF velocity-controlled robotic arm and an omnidirectional mobile platform. The systems share the same admittance interface, through which user wrenches are translated to loco-manipulation commands generated by whole-body controllers of each system. Besides, a thorough user study with multiple and cross-gender subjects is presented to reveal the quantitative performance of the two systems in effort-demanding and dexterous tasks. Moreover, we provide qualitative results from the NASA-TLX questionnaire to demonstrate the SUPER-MAN approach's potential and its acceptability from the users' viewpoint. "
}