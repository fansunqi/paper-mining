{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Classification"
  ],
  "datasets": [
    "Synthetic datasets",
    "UCI repository"
  ],
  "methods": [
    "Mixed-integer quadratic formulation",
    "Support Vector Machines",
    "Feature selection constraints"
  ],
  "results": [
    "MARGOT formulation easier to solve than other OCT approaches",
    "Better generalization on new observations",
    "Effective feature selection and good prediction quality"
  ],
  "paper_id": "6350bc6d90e50fcafdecf21a",
  "title": "Margin Optimal Classification Trees",
  "abstract": "  In recent years there has been growing attention to interpretable machine learning models which can give explanatory insights on their behavior. Thanks to their interpretability, decision trees have been intensively studied for classification tasks, and due to the remarkable advances in mixed-integer programming (MIP), various approaches have been proposed to formulate the problem of training an Optimal Classification Tree (OCT) as a MIP model. We present a novel mixed-integer quadratic formulation for the OCT problem, which exploits the generalization capabilities of Support Vector Machines for binary classification. Our model, denoted as Margin Optimal Classification Tree (MARGOT), encompasses the use of maximum margin multivariate hyperplanes nested in a binary tree structure. To enhance the interpretability of our approach, we analyse two alternative versions of MARGOT, which include feature selection constraints inducing local sparsity of the hyperplanes. First, MARGOT has been tested on non-linearly separable synthetic datasets in 2-dimensional feature space to provide a graphical representation of the maximum margin approach. Finally, the proposed models have been tested on benchmark datasets from the UCI repository. The MARGOT formulation turns out to be easier to solve than other OCT approaches, and the generated tree better generalizes on new observations. The two interpretable versions are effective in selecting the most relevant features and maintaining good prediction quality. "
}