{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Knowledge Graph Completion (KGC)"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Jointly Modeling Knowledge Graphs and Soft Rules",
    "Rule confidence regularizer",
    "Iterative method for KGEs improvement"
  ],
  "results": [
    "Improves performance by 2.7% and 4.3% in MRR"
  ],
  "paper_id": "63bcd73090e50fcafdef987f",
  "title": "Knowledge Reasoning via Jointly Modeling Knowledge Graphs and Soft Rules",
  "abstract": "  Knowledge graphs (KGs) play a crucial role in many applications, such as question answering, but incompleteness is an urgent issue for their broad application. Much research in knowledge graph completion (KGC) has been performed to resolve this issue. The methods of KGC can be classified into two major categories: rule-based reasoning and embedding-based reasoning. The former has high accuracy and good interpretability, but a major challenge is to obtain effective rules on large-scale KGs. The latter has good efficiency and scalability, but it relies heavily on data richness and cannot fully use domain knowledge in the form of logical rules. We propose a novel method that injects rules and learns representations iteratively to take full advantage of rules and embeddings. Specifically, we model the conclusions of rule groundings as 0-1 variables and use a rule confidence regularizer to remove the uncertainty of the conclusions. The proposed approach has the following advantages: 1) It combines the benefits of both rules and knowledge graph embeddings (KGEs) and achieves a good balance between efficiency and scalability. 2) It uses an iterative method to continuously improve KGEs and remove incorrect rule conclusions. Evaluations on two public datasets show that our method outperforms the current state-of-the-art methods, improving performance by 2.7\\% and 4.3\\% in mean reciprocal rank (MRR). "
}