{
  "code_links": [
    "https://github.com/tangg555/meddialog"
  ],
  "tasks": [
    "Medical dialogue generation"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Attention mechanism",
    "Auxiliary terminology recognition task"
  ],
  "results": [
    "Outperforms SOTA language models"
  ],
  "paper_id": "635b487090e50fcafd330e2d",
  "title": "Terminology-aware Medical Dialogue Generation",
  "abstract": "  Medical dialogue generation aims to generate responses according to a history of dialogue turns between doctors and patients. Unlike open-domain dialogue generation, this requires background knowledge specific to the medical domain. Existing generative frameworks for medical dialogue generation fall short of incorporating domain-specific knowledge, especially with regard to medical terminology. In this paper, we propose a novel framework to improve medical dialogue generation by considering features centered on domain-specific terminology. We leverage an attention mechanism to incorporate terminologically centred features, and fill in the semantic gap between medical background knowledge and common utterances by enforcing language models to learn terminology representations with an auxiliary terminology recognition task. Experimental results demonstrate the effectiveness of our approach, in which our proposed framework outperforms SOTA language models. Additionally, we provide a new dataset with medical terminology annotations to support the research on medical dialogue generation. Our dataset and code are available at https://github.com/tangg555/meddialog. "
}