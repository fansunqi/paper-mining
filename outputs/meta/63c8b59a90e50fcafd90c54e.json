{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Targeted Image Reconstruction",
    "Model Inversion Attack"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Pre-trained Diffusion Model"
  ],
  "results": [
    "None"
  ],
  "paper_id": "63c8b59a90e50fcafd90c54e",
  "title": "Targeted Image Reconstruction by Sampling Pre-trained Diffusion Model",
  "abstract": "  A trained neural network model contains information on the training data. Given such a model, malicious parties can leverage the \"knowledge\" in this model and design ways to print out any usable information (known as model inversion attack). Therefore, it is valuable to explore the ways to conduct a such attack and demonstrate its severity. In this work, we proposed ways to generate a data point of the target class without prior knowledge of the exact target distribution by using a pre-trained diffusion model. "
}