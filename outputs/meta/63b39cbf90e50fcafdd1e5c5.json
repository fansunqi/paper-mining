{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Domain adaptation"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Discriminative Radial Domain Adaptation (DRDA)",
    "shared radial structure",
    "optimal-transport assignment"
  ],
  "results": [
    "consistently outperforms state-of-the-art approaches on varied tasks"
  ],
  "paper_id": "63b39cbf90e50fcafdd1e5c5",
  "title": "Discriminative Radial Domain Adaptation",
  "abstract": "  Domain adaptation methods reduce domain shift typically by learning domain-invariant features. Most existing methods are built on distribution matching, e.g., adversarial domain adaptation, which tends to corrupt feature discriminability. In this paper, we propose Discriminative Radial Domain Adaptation (DRDA) which bridges source and target domains via a shared radial structure. It's motivated by the observation that as the model is trained to be progressively discriminative, features of different categories expand outwards in different directions, forming a radial structure. We show that transferring such an inherently discriminative structure would enable to enhance feature transferability and discriminability simultaneously. Specifically, we represent each domain with a global anchor and each category a local anchor to form a radial structure and reduce domain shift via structure matching. It consists of two parts, namely isometric transformation to align the structure globally and local refinement to match each category. To enhance the discriminability of the structure, we further encourage samples to cluster close to the corresponding local anchors based on optimal-transport assignment. Extensively experimenting on multiple benchmarks, our method is shown to consistently outperforms state-of-the-art approaches on varied tasks, including the typical unsupervised domain adaptation, multi-source domain adaptation, domain-agnostic learning, and domain generalization. "
}