{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Expressive facial animation generation from speech"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Deep learning-based approach",
    "Emotion controller module"
  ],
  "results": [
    "Rich in facial emotional expressiveness",
    "Accurate lip movement",
    "Outperforms other state-of-the-art methods"
  ],
  "paper_id": "6597757f939a5f4082b13731",
  "title": "Expressive Speech-driven Facial Animation with controllable emotions",
  "abstract": "It is in high demand to generate facial animation with high realism, but it\nremains a challenging task. Existing approaches of speech-driven facial\nanimation can produce satisfactory mouth movement and lip synchronization, but\nshow weakness in dramatic emotional expressions and flexibility in emotion\ncontrol. This paper presents a novel deep learning-based approach for\nexpressive facial animation generation from speech that can exhibit\nwide-spectrum facial expressions with controllable emotion type and intensity.\nWe propose an emotion controller module to learn the relationship between the\nemotion variations (e.g., types and intensity) and the corresponding facial\nexpression parameters. It enables emotion-controllable facial animation, where\nthe target expression can be continuously adjusted as desired. The qualitative\nand quantitative evaluations show that the animation generated by our method is\nrich in facial emotional expressiveness while retaining accurate lip movement,\noutperforming other state-of-the-art methods."
}