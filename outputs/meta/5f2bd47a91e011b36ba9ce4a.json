{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Understanding neural network decisions",
    "Feature relevance uncertainty estimation"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Monte Carlo Relevance Propagation (MCRP)",
    "Monte Carlo estimation of feature relevance distribution"
  ],
  "results": [
    "Allows deeper understanding of neural network's perception and reasoning",
    "Computes feature relevance uncertainty scores"
  ],
  "paper_id": "5f2bd47a91e011b36ba9ce4a",
  "title": "On Feature Relevance Uncertainty: A Monte Carlo Dropout Sampling\n  Approach",
  "abstract": "  Understanding decisions made by neural networks is key for the deployment of intelligent systems in real world applications. However, the opaque decision making process of these systems is a disadvantage where interpretability is essential. Many feature-based explanation techniques have been introduced over the last few years in the field of machine learning to better understand decisions made by neural networks and have become an important component to verify their reasoning capabilities. However, existing methods do not allow statements to be made about the uncertainty regarding a feature's relevance for the prediction. In this paper, we introduce Monte Carlo Relevance Propagation (MCRP) for feature relevance uncertainty estimation. A simple but powerful method based on Monte Carlo estimation of the feature relevance distribution to compute feature relevance uncertainty scores that allow a deeper understanding of a neural network's perception and reasoning. "
}