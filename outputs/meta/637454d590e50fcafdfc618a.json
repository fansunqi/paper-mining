{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Optimization with Stochastic Dominance Constraints"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Light Stochastic Dominance Solver (light-SD)"
  ],
  "results": [
    "Superior performance on several representative problems"
  ],
  "paper_id": "637454d590e50fcafdfc618a",
  "title": "Learning to Optimize with Stochastic Dominance Constraints",
  "abstract": "  In real-world decision-making, uncertainty is important yet difficult to handle. Stochastic dominance provides a theoretically sound approach for comparing uncertain quantities, but optimization with stochastic dominance constraints is often computationally expensive, which limits practical applicability. In this paper, we develop a simple yet efficient approach for the problem, the Light Stochastic Dominance Solver (light-SD), that leverages useful properties of the Lagrangian. We recast the inner optimization in the Lagrangian as a learning problem for surrogate approximation, which bypasses apparent intractability and leads to tractable updates or even closed-form solutions for gradient calculations. We prove convergence of the algorithm and test it empirically. The proposed light-SD demonstrates superior performance on several representative problems ranging from finance to supply chain management. "
}