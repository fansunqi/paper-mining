{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Understanding Political Polarisation"
  ],
  "datasets": [
    "Wikipedia"
  ],
  "methods": [
    "Language Models",
    "Word2Vec",
    "Doc2Vec",
    "Longformer"
  ],
  "results": [
    "None"
  ],
  "paper_id": "63b63fca90e50fcafd8f438d",
  "title": "Understanding Political Polarisation using Language Models: A dataset\n  and method",
  "abstract": "  Our paper aims to analyze political polarization in US political system using Language Models, and thereby help candidates make an informed decision. The availability of this information will help voters understand their candidates views on the economy, healthcare, education and other social issues. Our main contributions are a dataset extracted from Wikipedia that spans the past 120 years and a Language model based method that helps analyze how polarized a candidate is. Our data is divided into 2 parts, background information and political information about a candidate, since our hypothesis is that the political views of a candidate should be based on reason and be independent of factors such as birthplace, alma mater, etc. We further split this data into 4 phases chronologically, to help understand if and how the polarization amongst candidates changes. This data has been cleaned to remove biases. To understand the polarization we begin by showing results from some classical language models in Word2Vec and Doc2Vec. And then use more powerful techniques like the Longformer, a transformer based encoder, to assimilate more information and find the nearest neighbors of each candidate based on their political view and their background. "
}