{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Bias correction in machine learning",
    "Fairness in machine learning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Weighted vote",
    "Learning bounds",
    "Pruning method"
  ],
  "results": [
    "Increased fairness without significant accuracy degradation"
  ],
  "paper_id": "63d340ef90e50fcafd911509",
  "title": "Increasing Fairness in Compromise on Accuracy via Weighted Vote with\n  Learning Guarantees",
  "abstract": "  As the bias issue is being taken more and more seriously in widely applied machine learning systems, the decrease in accuracy in most cases deeply disturbs researchers when increasing fairness. To address this problem, we present a novel analysis of the expected fairness quality via weighted vote, suitable for both binary and multi-class classification. The analysis takes the correction of biased predictions by ensemble members into account and provides learning bounds that are amenable to efficient minimisation. We further propose a pruning method based on this analysis and the concepts of domination and Pareto optimality, which is able to increase fairness under a prerequisite of little or even no accuracy decline. The experimental results indicate that the proposed learning bounds are faithful and that the proposed pruning method can indeed increase ensemble fairness without much accuracy degradation. "
}