{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Learning under Data Drift"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Time-Varying Importance Weight Estimator"
  ],
  "results": [
    "None"
  ],
  "paper_id": "633cf5cf90e50fcafd772efd",
  "title": "Learning under Data Drift with Time-Varying Importance Weights",
  "abstract": "  Real-world deployment of machine learning models is challenging when data evolves over time. And data does evolve over time. While no model can work when data evolves in an arbitrary fashion, if there is some pattern to these changes, we might be able to design methods to address it. This paper addresses situations when data evolves gradually. We introduce a novel time-varying importance weight estimator that can detect gradual shifts in the distribution of data. Such an importance weight estimator allows the training method to selectively sample past data -- not just similar data from the past like a standard importance weight estimator would but also data that evolved in a similar fashion in the past. Our time-varying importance weight is quite general. We demonstrate different ways of implementing it that exploit some known structure in the evolution of data. We demonstrate and evaluate this approach on a variety of problems ranging from supervised learning tasks (multiple image classification datasets) where the data undergoes a sequence of gradual shifts of our design to reinforcement learning tasks (robotic manipulation and continuous control) where data undergoes a shift organically as the policy or the task changes. "
}