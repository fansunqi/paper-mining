{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Online convex optimization",
    "Regret minimization"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Adaptive and dynamic regret minimization algorithms"
  ],
  "results": [
    "Reduced computational penalty to doubly logarithmic in the number of game iterations",
    "Retained near optimal adaptive and dynamic regret bounds"
  ],
  "paper_id": "62c3abbb5aee126c0fc96e7f",
  "title": "On the Computational Efficiency of Adaptive and Dynamic Regret\n  Minimization",
  "abstract": "  In online convex optimization, the player aims to minimize regret, or the difference between her loss and that of the best fixed decision in hindsight over the entire repeated game. Algorithms that minimize (standard) regret may converge to a fixed decision, which is undesirable in changing or dynamic environments. This motivates the stronger metrics of performance, notably adaptive and dynamic regret. Adaptive regret is the maximum regret over any continuous sub-interval in time. Dynamic regret is the difference between the total cost and that of the best sequence of decisions in hindsight.   State-of-the-art performance in both adaptive and dynamic regret minimization suffers a computational penalty - typically on the order of a multiplicative factor that grows logarithmically in the number of game iterations. In this paper we show how to reduce this computational penalty to be doubly logarithmic in the number of game iterations, and retain near optimal adaptive and dynamic regret bounds. "
}