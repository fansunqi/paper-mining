{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Multilingual speech synthesis"
  ],
  "datasets": [
    "Open-source dataset with 7 accents"
  ],
  "methods": [
    "RADTTS with explicit control over accent, language, speaker and fine-grained $F_0$ and energy features"
  ],
  "results": [
    "Better retention of speaker's voice and accent quality than controlled baselines",
    "Synthesizing fluent speech in all target languages and accents"
  ],
  "paper_id": "63d340e890e50fcafd910a29",
  "title": "Multilingual Multiaccented Multispeaker TTS with RADTTS",
  "abstract": "  We work to create a multilingual speech synthesis system which can generate speech with the proper accent while retaining the characteristics of an individual voice. This is challenging to do because it is expensive to obtain bilingual training data in multiple languages, and the lack of such data results in strong correlations that entangle speaker, language, and accent, resulting in poor transfer capabilities. To overcome this, we present a multilingual, multiaccented, multispeaker speech synthesis model based on RADTTS with explicit control over accent, language, speaker and fine-grained $F_0$ and energy features. Our proposed model does not rely on bilingual training data. We demonstrate an ability to control synthesized accent for any speaker in an open-source dataset comprising of 7 accents. Human subjective evaluation demonstrates that our model can better retain a speaker's voice and accent quality than controlled baselines while synthesizing fluent speech in all target languages and accents in our dataset. "
}