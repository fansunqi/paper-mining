{
  "code_links": [
    "None"
  ],
  "tasks": [
    "End-to-End Neural Diarization"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Multi-Speaker and Wide-Band Simulated Conversations"
  ],
  "results": [
    "Improved performance over original simulated mixtures",
    "Reduced dependence on fine-tuning stage"
  ],
  "paper_id": "6373035a90e50fcafd09fc6c",
  "title": "Multi-Speaker and Wide-Band Simulated Conversations as Training Data for\n  End-to-End Neural Diarization",
  "abstract": "  End-to-end diarization presents an attractive alternative to standard cascaded diarization systems because a single system can handle all aspects of the task at once. Many flavors of end-to-end models have been proposed but all of them require (so far non-existing) large amounts of annotated data for training. The compromise solution consists in generating synthetic data and the recently proposed simulated conversations (SC) have shown remarkable improvements over the original simulated mixtures (SM). In this work, we create SC with multiple speakers per conversation and show that they allow for substantially better performance than SM, also reducing the dependence on a fine-tuning stage. We also create SC with wide-band public audio sources and present an analysis on several evaluation sets. Together with this publication, we release the recipes for generating such data and models trained on public sets as well as the implementation to efficiently handle multiple speakers per conversation and an auxiliary voice activity detection loss. "
}