{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Uncertainty quantification in machine learning and deep learning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Combining cross entropy with Expected Calibration Error (ECE) and Predictive Entropy (PE)",
    "Monte Carlo dropout (MC-Dropout)"
  ],
  "results": [
    "New loss functions lead to calibrated MC-Dropout method",
    "Minimise overlap between uncertainty estimates for correct and incorrect predictions without sacrificing model performance"
  ],
  "paper_id": "615fb6f05244ab9dcb9c3d1f",
  "title": "An Uncertainty-aware Loss Function for Training Neural Networks with\n  Calibrated Predictions",
  "abstract": "  Uncertainty quantification of machine learning and deep learning methods plays an important role in enhancing trust to the obtained result. In recent years, a numerous number of uncertainty quantification methods have been introduced. Monte Carlo dropout (MC-Dropout) is one of the most well-known techniques to quantify uncertainty in deep learning methods. In this study, we propose two new loss functions by combining cross entropy with Expected Calibration Error (ECE) and Predictive Entropy (PE). The obtained results clearly show that the new proposed loss functions lead to having a calibrated MC-Dropout method. Our results confirmed the great impact of the new hybrid loss functions for minimising the overlap between the distributions of uncertainty estimates for correct and incorrect predictions without sacrificing the model's overall performance. "
}