{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Multi-object Tracking",
    "Lidar Odometry in Dynamic Environment"
  ],
  "datasets": [
    "KITTI"
  ],
  "methods": [
    "Semantic Geometric Fusion",
    "Dynamic Lidar Odometry (MLO)",
    "Semantic Object Detection",
    "Least Square Estimator using Semantic Bounding Box and Object Point Cloud",
    "Absolute Trajectory Tracking List (ATTL) for Dynamic Semantic Object Detection"
  ],
  "results": [
    "More accurate and robust object tracking",
    "Better real-time localization accuracy in complex scenes compared to existing technologies"
  ],
  "paper_id": "626754c85aee126c0fbcdd10",
  "title": "Semantic Geometric Fusion Multi-object Tracking and Lidar Odometry in\n  Dynamic Environment",
  "abstract": "  The SLAM system based on static scene assumption will introduce huge estimation errors when moving objects appear in the field of view. This paper proposes a novel multi-object dynamic lidar odometry (MLO) based on semantic object detection technology to solve this problem. The MLO system can provide reliable localization of robot and semantic objects and build long-term static maps in complex dynamic scenes. For ego-motion estimation, we use the environment features that take semantic and geometric consistency constraints into account in the extraction process. The filtering features are robust to semantic movable and unknown dynamic objects. At the same time, a least square estimator using the semantic bounding box and object point cloud is proposed to achieve accurate and stable multi-object tracking between frames. In the mapping module, we further realize dynamic semantic object detection based on the absolute trajectory tracking list (ATTL). Then, static semantic objects and environmental features can be used to eliminate accumulated localization errors and build pure static maps. Experiments on public KITTI data sets show that the proposed system can achieve more accurate and robust tracking of the object and better real-time localization accuracy in complex scenes compared with existing technologies. "
}