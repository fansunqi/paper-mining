{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Safe Control Transitions",
    "Machine Vision Based Observable Readiness Index and Takeover Time Prediction"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Machine learning models",
    "Feature vectors for hand location and activity, gaze location",
    "Tradeoffs of different views in generating feature vectors",
    "Two metrics to evaluate control transition quality"
  ],
  "results": [
    "Robustness to multiple camera views",
    "Correlations of post-takeover metrics to pre-takeover predictive metrics"
  ],
  "paper_id": "63c8b56b90e50fcafd905ad1",
  "title": "Safe Control Transitions: Machine Vision Based Observable Readiness\n  Index and Data-Driven Takeover Time Prediction",
  "abstract": "  To make safe transitions from autonomous to manual control, a vehicle must have a representation of the awareness of driver state; two metrics which quantify this state are the Observable Readiness Index and Takeover Time. In this work, we show that machine learning models which predict these two metrics are robust to multiple camera views, expanding from the limited view angles in prior research. Importantly, these models take as input feature vectors corresponding to hand location and activity as well as gaze location, and we explore the tradeoffs of different views in generating these feature vectors. Further, we introduce two metrics to evaluate the quality of control transitions following the takeover event (the maximal lateral deviation and velocity deviation) and compute correlations of these post-takeover metrics to the pre-takeover predictive metrics. "
}