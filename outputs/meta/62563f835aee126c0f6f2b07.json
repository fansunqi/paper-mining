{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Sign Language Translation"
  ],
  "datasets": [
    "PHOENIX14T",
    "CSL-Daily"
  ],
  "methods": [
    "ConSLT: token-level contrastive learning framework"
  ],
  "results": [
    "ConSLT achieves better translation quality than strong baselines"
  ],
  "paper_id": "62563f835aee126c0f6f2b07",
  "title": "A Token-level Contrastive Framework for Sign Language Translation",
  "abstract": "  Sign Language Translation (SLT) is a promising technology to bridge the communication gap between the deaf and the hearing people. Recently, researchers have adopted Neural Machine Translation (NMT) methods, which usually require large-scale corpus for training, to achieve SLT. However, the publicly available SLT corpus is very limited, which causes the collapse of the token representations and the inaccuracy of the generated tokens. To alleviate this issue, we propose ConSLT, a novel token-level \\textbf{Con}trastive learning framework for \\textbf{S}ign \\textbf{L}anguage \\textbf{T}ranslation , which learns effective token representations by incorporating token-level contrastive learning into the SLT decoding process. Concretely, ConSLT treats each token and its counterpart generated by different dropout masks as positive pairs during decoding, and then randomly samples $K$ tokens in the vocabulary that are not in the current sentence to construct negative examples. We conduct comprehensive experiments on two benchmarks (PHOENIX14T and CSL-Daily) for both end-to-end and cascaded settings. The experimental results demonstrate that ConSLT can achieve better translation quality than the strong baselines. "
}