{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Monitoring and adapting the physical state of cameras for autonomous vehicles"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Generic and interpretable self-health-maintenance framework for cameras",
    "Data- and physically-grounded models",
    "Real-time estimators for image effects (blur, noise)",
    "Adjusting camera parameters based on input-output performance curves"
  ],
  "results": [
    "Reliable estimators for typical image effects",
    "Demonstrated optimal whole-system capability on a real-world ground vehicle",
    "Ready-to-use solution for camera health evaluation and maintenance"
  ],
  "paper_id": "61b6b9a05244ab9dcbf11955",
  "title": "Monitoring and Adapting the Physical State of a Camera for Autonomous\n  Vehicles",
  "abstract": "  Autonomous vehicles and robots require increasingly more robustness and reliability to meet the demands of modern tasks. These requirements specially apply to cameras onboard such vehicles because they are the predominant sensors to acquire information about the environment and support actions. Cameras must maintain proper functionality and take automatic countermeasures if necessary. However, few works examine the practical use of a general condition monitoring approach for cameras and designs countermeasures in the context of an envisaged high-level application. We propose a generic and interpretable self-health-maintenance framework for cameras based on data- and physically-grounded models. To this end, we determine two reliable, real-time capable estimators for typical image effects of a camera in poor condition (blur, noise phenomena and most common combinations) by comparing traditional and retrained machine learning-based approaches in extensive experiments. Furthermore, we demonstrate on a real-world ground vehicle how one can adjust the camera parameters to achieve optimal whole-system capability based on experimental (non-linear and non-monotonic) input-output performance curves, using object detection, motion blur and sensor noise as examples. Our framework not only provides a practical ready-to-use solution to evaluate and maintain the health of cameras, but can also serve as a basis for extensions to tackle more sophisticated problems that combine additional data sources (e.g., sensor or environment parameters) empirically in order to attain fully reliable and robust machines. "
}