{
  "code_links": [
    "https://lhy.xyz/stereovoxelnet"
  ],
  "tasks": [
    "Obstacle detection",
    "Robot navigation"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Deep neural network",
    "Volumetric representations",
    "Octrees",
    "Stereo matching"
  ],
  "results": [
    "Real-time performance",
    "32 meters detection range",
    "Better IoU and CD scores",
    "2% computation cost of state-of-the-art stereo model"
  ],
  "paper_id": "63292f6890e50fcafd2eba2a",
  "title": "StereoVoxelNet: Real-Time Obstacle Detection Based on Occupancy Voxels\n  from a Stereo Camera Using Deep Neural Networks",
  "abstract": "  Obstacle detection is a safety-critical problem in robot navigation, where stereo matching is a popular vision-based approach. While deep neural networks have shown impressive results in computer vision, most of the previous obstacle detection works only leverage traditional stereo matching techniques to meet the computational constraints for real-time feedback. This paper proposes a computationally efficient method that employs a deep neural network to detect occupancy from stereo images directly. Instead of learning the point cloud correspondence from the stereo data, our approach extracts the compact obstacle distribution based on volumetric representations. In addition, we prune the computation of safety irrelevant spaces in a coarse-to-fine manner based on octrees generated by the decoder. As a result, we achieve real-time performance on the onboard computer (NVIDIA Jetson TX2). Our approach detects obstacles accurately in the range of 32 meters and achieves better IoU (Intersection over Union) and CD (Chamfer Distance) scores with only 2% of the computation cost of the state-of-the-art stereo model. Furthermore, we validate our method's robustness and real-world feasibility through autonomous navigation experiments with a real robot. Hence, our work contributes toward closing the gap between the stereo-based system in robot perception and state-of-the-art stereo models in computer vision. To counter the scarcity of high-quality real-world indoor stereo datasets, we collect a 1.36 hours stereo dataset with a mobile robot which is used to fine-tune our model. The dataset, the code, and further details including additional visualizations are available at https://lhy.xyz/stereovoxelnet "
}