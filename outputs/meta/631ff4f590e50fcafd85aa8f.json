{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Fairness in the Autobidding World"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Machine-learned Advice",
    "parallel VCG auctions",
    "confidence intervals",
    "generalized first price (GFP) and generalized second price (GSP) auctions"
  ],
  "results": [
    "Welfare lower-bound guarantee for individual agents",
    "Platform fairness positively correlated with ML advice quality",
    "Impossibility result for achieving universally better fairness guarantees"
  ],
  "paper_id": "631ff4f590e50fcafd85aa8f",
  "title": "Fairness in the Autobidding World with Machine-learned Advice",
  "abstract": "  The increasing availability of real-time data has fueled the prevalence of algorithmic bidding (or autobidding) in online advertising markets, and has enabled online ad platforms to produce signals through machine learning techniques (i.e., ML advice) on advertisers' true perceived values for ad conversions. Previous works have studied the auction design problem while incorporating ML advice through various forms to improve total welfare of advertisers. Yet, such improvements could come at the cost of individual bidders' welfare, consequently eroding fairness of the ad platform. Motivated by this, we study how ad platforms can utilize ML advice to improve welfare guarantees and fairness on the individual bidder level in the autobidding world. We focus on a practical setting where ML advice takes the form of lower confidence bounds (or confidence intervals). We motivate a simple approach that directly sets such advice as personalized reserve prices when the platform consists of value-maximizing autobidders who are subject to return-on-ad spent (ROAS) constraints competing in multiple parallel auctions. Under parallel VCG auctions with ML advice-based reserves, we present a worst-case welfare lower-bound guarantee for individual agents, and show that platform fairness is positively correlated with ML advice quality. We also present an instance that demonstrates our welfare guarantee is tight. Further, we prove an impossibility result showing that no truthful, and possibly randomized mechanism with anonymous allocations and ML advice as personalized reserves can achieve universally better fairness guarantees than VCG when coupled with ML advice of the same quality. Finally, we extend our fairness guarantees with ML advice to generalized first price (GFP) and generalized second price (GSP) auctions. "
}