{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Collaborative Filtering"
  ],
  "datasets": [
    "11 benchmark datasets"
  ],
  "methods": [
    "SimpleX",
    "Cosine Contrastive Loss (CCL)",
    "Large negative sampling ratio"
  ],
  "results": [
    "Surpass most state-of-the-art models",
    "Max 48.5% improvement in NDCG@20 over LightGCN"
  ],
  "paper_id": "6153e0215244ab9dcb39a8be",
  "title": "SimpleX: A Simple and Strong Baseline for Collaborative Filtering",
  "abstract": "  Collaborative filtering (CF) is a widely studied research topic in recommender systems. The learning of a CF model generally depends on three major components, namely interaction encoder, loss function, and negative sampling. While many existing studies focus on the design of more powerful interaction encoders, the impacts of loss functions and negative sampling ratios have not yet been well explored. In this work, we show that the choice of loss function as well as negative sampling ratio is equivalently important. More specifically, we propose the cosine contrastive loss (CCL) and further incorporate it to a simple unified CF model, dubbed SimpleX. Extensive experiments have been conducted on 11 benchmark datasets and compared with 29 existing CF models in total. Surprisingly, the results show that, under our CCL loss and a large negative sampling ratio, SimpleX can surpass most sophisticated state-of-the-art models by a large margin (e.g., max 48.5% improvement in NDCG@20 over LightGCN). We believe that SimpleX could not only serve as a simple strong baseline to foster future research on CF, but also shed light on the potential research direction towards improving loss function and negative sampling. "
}