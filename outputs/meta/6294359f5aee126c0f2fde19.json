{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Misinformation spread on social media",
    "Community fact-checking"
  ],
  "datasets": [
    "Twitter's Birdwatch pilot"
  ],
  "methods": [
    "Empirical analysis",
    "User study"
  ],
  "results": [
    "Community fact-checked misinformation is less viral",
    "Misleading posts receive 36.62% fewer retweets",
    "Significant differences in virality across different sub-types of misinformation",
    "Users largely agree with community-created fact-checks"
  ],
  "paper_id": "6294359f5aee126c0f2fde19",
  "title": "Diffusion of Community Fact-Checked Misinformation on Twitter",
  "abstract": "  The spread of misinformation on social media is a pressing societal problem that platforms, policymakers, and researchers continue to grapple with. As a countermeasure, recent works have proposed to employ non-expert fact-checkers in the crowd to fact-check social media content. While experimental studies suggest that crowds might be able to accurately assess the veracity of social media content, an understanding of how crowd fact-checked (mis-)information spreads is missing. In this work, we empirically analyze the spread of misleading vs. not misleading community fact-checked posts on social media. For this purpose, we employ a dataset of community-created fact-checks from Twitter's Birdwatch pilot and map them to resharing cascades on Twitter. Different from earlier studies analyzing the spread of misinformation listed on third-party fact-checking websites (e.g., Snopes), we find that community fact-checked misinformation is less viral. Specifically, misleading posts are estimated to receive 36.62% fewer retweets than not misleading posts. A partial explanation may lie in differences in the fact-checking targets: community fact-checkers tend to fact-check posts from influential user accounts with many followers, while expert fact-checks tend to target posts that are shared by less influential users. We further find that there are significant differences in virality across different sub-types of misinformation (e.g., factual errors, missing context, manipulated media). Moreover, we conduct a user study to assess the perceived reliability of (real-world) community-created fact-checks. Here, we find that users, to a large extent, agree with community-created fact-checks. Altogether, our findings offer insights into how misleading vs. not misleading posts spread and highlight the crucial role of sample selection when studying misinformation on social media. "
}