{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Automated Essay Scoring"
  ],
  "datasets": [
    "Automated Student Assessment Prize competition"
  ],
  "methods": [
    "Uncertainty-based",
    "Topological-based",
    "Hybrid"
  ],
  "results": [
    "Strong results",
    "Topological-based method most efficient",
    "Similar classifications"
  ],
  "paper_id": "63b39cbf90e50fcafdd1e7a9",
  "title": "Using Active Learning Methods to Strategically Select Essays for\n  Automated Scoring",
  "abstract": "  Research on automated essay scoring has become increasing important because it serves as a method for evaluating students' written-responses at scale. Scalable methods for scoring written responses are needed as students migrate to online learning environments resulting in the need to evaluate large numbers of written-response assessments. The purpose of this study is to describe and evaluate three active learning methods than can be used to minimize the number of essays that must be scored by human raters while still providing the data needed to train a modern automated essay scoring system. The three active learning methods are the uncertainty-based, the topological-based, and the hybrid method. These three methods were used to select essays included as part of the Automated Student Assessment Prize competition that were then classified using a scoring model that was training with the bidirectional encoder representations from transformer language model. All three active learning methods produced strong results, with the topological-based method producing the most efficient classification. Growth rate accuracy was also evaluated. The active learning methods produced different levels of efficiency under different sample size allocations but, overall, all three methods were highly efficient and produced classifications that were similar to one another. "
}