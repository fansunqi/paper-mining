{
  "code_links": [
    "https://github.com/NiklasZ/transformers-for-variable-action-envs"
  ],
  "tasks": [
    "Reinforcement Learning in Variable Action Environments"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Transformer Encoder",
    "Proximal Policy Optimisation (PPO)",
    "GridNet architecture"
  ],
  "results": [
    "Higher return with half the computational resources compared to the next-best RL agent"
  ],
  "paper_id": "63be28d490e50fcafdf52ab6",
  "title": "Transformers as Policies for Variable Action Environments",
  "abstract": "  In this project we demonstrate the effectiveness of the transformer encoder as a viable architecture for policies in variable action environments. Using it, we train an agent using Proximal Policy Optimisation (PPO) on multiple maps against scripted opponents in the Gym-$\\mu$RTS environment. The final agent is able to achieve a higher return using half the computational resources of the next-best RL agent, which used the GridNet architecture.   The source code and pre-trained models are available here: https://github.com/NiklasZ/transformers-for-variable-action-envs "
}