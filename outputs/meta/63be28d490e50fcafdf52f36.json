{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Automaton Learning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Modulo 2 Multiplicity Automata",
    "Membership and Equivalence Queries",
    "Strongly Unambiguous B\u00fcchi Automata",
    "Minimization Algorithm"
  ],
  "results": [
    "None"
  ],
  "paper_id": "63be28d490e50fcafdf52f36",
  "title": "ALMA: Automata Learner using Modulo 2 Multiplicity Automata",
  "abstract": "  We present ALMA (Automata Learner using modulo 2 Multiplicity Automata), a Java-based tool that can learn any automaton accepting regular languages of finite or infinite words with an implementable membership query function. Users can either pass as input their own membership query function, or use the predefined membership query functions for modulo 2 multiplicity automata and non-deterministic B\\\"uchi automata. While learning, ALMA can output the state of the observation table after every equivalence query, and upon termination, it can output the dimension, transition matrices, and final vector of the learned modulo 2 multiplicity automaton. Users can test whether a word is accepted by performing a membership query on the learned automaton.   ALMA follows the polynomial-time learning algorithm of Beimel et. al. (Learning functions represented as multiplicity automata. J. ACM 47(3), 2000), which uses membership and equivalence queries and represents hypotheses using modulo 2 multiplicity automata. ALMA also implements a polynomial-time learning algorithm for strongly unambiguous B\\\"uchi automata by Angluin et. al. (Strongly unambiguous B\\\"uchi automata are polynomially predictable with membership queries. CSL 2020), and a minimization algorithm for modulo 2 multiplicity automata by Sakarovitch (Elements of Automata Theory. 2009). "
}