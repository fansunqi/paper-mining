{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Emotion aware human intent prediction",
    "Social robot navigation"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "EWareNet",
    "Transformer-based model",
    "Reinforcement learning algorithm",
    "Obstacle profile representation"
  ],
  "results": [
    "Outperforms current state-of-art algorithms for intent prediction from 3D gaits"
  ],
  "paper_id": "5fb6504891e0116363c2c801",
  "title": "EWareNet: Emotion Aware Human Intent Prediction and Adaptive Spatial\n  Profile Fusion for Social Robot Navigation",
  "abstract": "  We present EWareNet, a novel intent and affect-aware social robot navigation algorithm among pedestrians. Our approach predicts the trajectory-based pedestrian intent from gait sequence, which is then used for intent-guided navigation taking into account social and proxemic constraints. We propose a transformer-based model that works on commodity RGB-D cameras mounted onto a moving robot. Our intent prediction routine is integrated into a mapless navigation scheme and makes no assumptions about the environment of pedestrian motion. Our navigation scheme consists of a novel obstacle profile representation methodology that is dynamically adjusted based on the pedestrian pose, intent, and affect. The navigation scheme is based on a reinforcement learning algorithm that takes pedestrian intent and robot's impact on pedestrian intent into consideration, in addition to the environmental configuration. We outperform current state-of-art algorithms for intent prediction from 3D gaits. "
}