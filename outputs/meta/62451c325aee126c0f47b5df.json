{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Weighted Matrix Completion"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Weighted Nuclear Norm Minimization incorporating subspace structure"
  ],
  "results": [
    "Accurate approximation of rank r matrix from near-optimal number of observed entries",
    "Error proportional to measurement noise",
    "Robust to erroneous prior information"
  ],
  "paper_id": "62451c325aee126c0f47b5df",
  "title": "Near-Optimal Weighted Matrix Completion",
  "abstract": "  Recent work in the matrix completion literature has shown that prior knowledge of a matrix's row and column spaces can be successfully incorporated into reconstruction programs to substantially benefit matrix recovery. This paper proposes a novel methodology that exploits more general forms of known matrix structure in terms of subspaces. The work derives reconstruction error bounds that are informative in practice, providing insight to previous approaches in the literature while introducing novel programs that severely reduce sampling complexity. The main result shows that a family of weighted nuclear norm minimization programs incorporating a $M_1 r$-dimensional subspace of $n\\times n$ matrices (where $M_1\\geq 1$ conveys structural properties of the subspace) allow accurate approximation of a rank $r$ matrix aligned with the subspace from a near-optimal number of observed entries (within a logarithmic factor of $M_1 r)$. The result is robust, where the error is proportional to measurement noise, applies to full rank matrices, and reflects degraded output when erroneous prior information is utilized. Numerical experiments are presented that validate the theoretical behavior derived for several example weighted programs. "
}