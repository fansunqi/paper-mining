{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Counterexample-guided repair of neural networks"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Robust optimisation algorithm",
    "Novel algorithm for repairing linear regression models"
  ],
  "results": [
    "Proves termination for more restrained machine learning models",
    "Disproves termination in a general setting",
    "Empirical study demonstrating suitability of common verifiers and falsifiers",
    "Novel algorithm surpassing existing approaches"
  ],
  "paper_id": "63d7352290e50fcafda301df",
  "title": "A Robust Optimisation Perspective on Counterexample-Guided Repair of\n  Neural Networks",
  "abstract": "  Counterexample-guided repair aims at creating neural networks with mathematical safety guarantees, facilitating the application of neural networks in safety-critical domains. However, whether counterexample-guided repair is guaranteed to terminate remains an open question. We approach this question by showing that counterexample-guided repair can be viewed as a robust optimisation algorithm. While termination guarantees for neural network repair itself remain beyond our reach, we prove termination for more restrained machine learning models and disprove termination in a general setting. We empirically study the practical implications of our theoretical results, demonstrating the suitability of common verifiers and falsifiers for repair despite a disadvantageous theoretical result. Additionally, we use our theoretical insights to devise a novel algorithm for repairing linear regression models, surpassing existing approaches. "
}