{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Learning adaptive interventions in health-related sequential decision-making"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Reinforcement Learning",
    "Unified survey on RL methods for dynamic treatment regimes and just-in-time adaptive interventions"
  ],
  "results": [
    "Illustration of collaboration opportunities between statistical, RL, and healthcare researchers"
  ],
  "paper_id": "6226c93c5aee126c0fd577a5",
  "title": "Reinforcement Learning in Modern Biostatistics: Constructing Optimal\n  Adaptive Interventions",
  "abstract": "  In recent years, reinforcement learning (RL) has acquired a prominent position in the space of health-related sequential decision-making, becoming an increasingly popular tool for delivering adaptive interventions (AIs). However, despite potential benefits, its real-life application is still limited, partly due to a poor synergy between the methodological and the applied communities. In this work, we provide the first unified survey on RL methods for learning AIs, using the common methodological umbrella of RL to bridge the two AI areas of dynamic treatment regimes and just-in-time adaptive interventions in mobile health. We outline similarities and differences between these two AI domains and discuss their implications for using RL. Finally, we leverage our experience in designing case studies in both areas to illustrate the tremendous collaboration opportunities between statistical, RL, and healthcare researchers in the space of AIs. "
}