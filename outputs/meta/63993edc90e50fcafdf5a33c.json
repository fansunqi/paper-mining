{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Object recognition",
    "Visual rationales"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Why prompt",
    "Language model transfer"
  ],
  "results": [
    "Improved performance on doubly right object recognition",
    "Zero-shot transfer to unseen tasks and datasets"
  ],
  "paper_id": "63993edc90e50fcafdf5a33c",
  "title": "Doubly Right Object Recognition: A Why Prompt for Visual Rationales",
  "abstract": "  Many visual recognition models are evaluated only on their classification accuracy, a metric for which they obtain strong performance. In this paper, we investigate whether computer vision models can also provide correct rationales for their predictions. We propose a ``doubly right'' object recognition benchmark, where the metric requires the model to simultaneously produce both the right labels as well as the right rationales. We find that state-of-the-art visual models, such as CLIP, often provide incorrect rationales for their categorical predictions. However, by transferring the rationales from language models into visual representations through a tailored dataset, we show that we can learn a ``why prompt,'' which adapts large visual representations to produce correct rationales. Visualizations and empirical experiments show that our prompts significantly improve performance on doubly right object recognition, in addition to zero-shot transfer to unseen tasks and datasets. "
}