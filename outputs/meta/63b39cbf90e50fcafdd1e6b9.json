{
  "code_links": [
    "https://github.com/fredbuhl/EmoGator"
  ],
  "tasks": [
    "Speech emotion recognition"
  ],
  "datasets": [
    "EmoGator"
  ],
  "methods": [
    "Machine learning classification methodologies"
  ],
  "results": [
    "None"
  ],
  "paper_id": "63b39cbf90e50fcafdd1e6b9",
  "title": "EmoGator: A New Open Source Vocal Burst Dataset with Baseline Machine\n  Learning Classification Methodologies",
  "abstract": "  Vocal Bursts -- short, non-speech vocalizations that convey emotions, such as laughter, cries, sighs, moans, and groans -- are an often-overlooked aspect of speech emotion recognition, but an important aspect of human vocal communication. One barrier to study of these interesting vocalizations is a lack of large datasets. I am pleased to introduce the EmoGator dataset, which consists of 32,130 samples from 357 speakers, 16.9654 hours of audio; each sample classified into one of 30 distinct emotion categories by the speaker. Several different approaches to construct classifiers to identify emotion categories will be discussed, and directions for future research will be suggested. Data set is available for download from https://github.com/fredbuhl/EmoGator. "
}