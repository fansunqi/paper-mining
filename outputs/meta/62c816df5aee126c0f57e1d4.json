{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Hand gesture recognition system",
    "Human-Machine Interface (HMI)"
  ],
  "datasets": [
    "Public dataset",
    "Custom dataset"
  ],
  "methods": [
    "Convolutional Neural Networks (CNNs) - VGG16, VGG19, ResNet50, ResNet101, Inception-V1",
    "Vision Transformer (ViT)",
    "Kalman filter"
  ],
  "results": [
    "Inception-V1 shows better classification performance",
    "Average speed of 25 fps",
    "Average response time in milliseconds"
  ],
  "paper_id": "62c816df5aee126c0f57e1d4",
  "title": "Deep learning based Hand gesture recognition system and design of a\n  Human-Machine Interface",
  "abstract": "  In this work, a real-time hand gesture recognition system-based human-computer interface (HCI) is presented. The system consists of six stages: (1) hand detection, (2) gesture segmentation, (3) use of five pre-trained convolutional neural network models (CNN) and vision transformer (ViT), (4) building an interactive human-machine interface (HMI), (5) development of a gesture-controlled virtual mouse, (6) use of Kalman filter to estimate the hand position, based on that the smoothness of the motion of pointer is improved. In our work, five pre-trained CNN (VGG16, VGG19, ResNet50, ResNet101, and Inception-V1) models and ViT have been employed to classify hand gesture images. Two multi-class datasets (one public and one custom) have been used to validate the models. Considering the model's performances, it is observed that Inception-V1 has significantly shown a better classification performance compared to the other four CNN models and ViT in terms of accuracy, precision, recall, and F-score values. We have also expanded this system to control some desktop applications (such as VLC player, audio player, file management, playing 2D Super-Mario-Bros game, etc.) with different customized gesture commands in real-time scenarios. The average speed of this system has reached 25 fps (frames per second), which meets the requirements for the real-time scenario. Performance of the proposed gesture control system obtained the average response time in milisecond for each control which makes it suitable for real-time. This model (prototype) will benefit physically disabled people interacting with desktops. "
}