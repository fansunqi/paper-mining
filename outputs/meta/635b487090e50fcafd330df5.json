{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Target speaker extraction"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Complex-valued spatial autoencoder (COSPA)",
    "Informed COSPA (iCOSPA)"
  ],
  "results": [
    "Effective and flexible extraction of target speaker",
    "Learning pronounced spatial selectivity patterns",
    "Results depend significantly on training target and reference signal"
  ],
  "paper_id": "635b487090e50fcafd330df5",
  "title": "Exploiting spatial information with the informed complex-valued spatial\n  autoencoder for target speaker extraction",
  "abstract": "  In conventional multichannel audio signal enhancement, spatial and spectral filtering are often performed sequentially. In contrast, it has been shown that for neural spatial filtering a joint approach of spectro-spatial filtering is more beneficial. In this contribution, we investigate the spatial filtering performed by such a time-varying spectro-spatial filter. We extend the recently proposed complex-valued spatial autoencoder (COSPA) for the task of target speaker extraction by leveraging its interpretable structure and purposefully informing the network of the target speaker's position. We show that the resulting informed COSPA (iCOSPA) effectively and flexibly extracts a target speaker from a mixture of speakers. We also find that the proposed architecture is well capable of learning pronounced spatial selectivity patterns and show that the results depend significantly on the training target and the reference signal when computing various evaluation metrics. "
}