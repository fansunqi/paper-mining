{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Automated decision-making systems",
    "Public trust in automated decision-making systems"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Fiduciary responsibility",
    "Data science lifecycle (DSL)"
  ],
  "results": [
    "Public lacks trust in automated decision-making systems",
    "Fiduciary responsibility mitigates sources of mistrust"
  ],
  "paper_id": "63d340e890e50fcafd91078d",
  "title": "Fiduciary Responsibility: Facilitating Public Trust in Automated\n  Decision Making",
  "abstract": "  Automated decision-making systems are being increasingly deployed and affect the public in a multitude of positive and negative ways. Governmental and private institutions use these systems to process information according to certain human-devised rules in order to address social problems or organizational challenges. Both research and real-world experience indicate that the public lacks trust in automated decision-making systems and the institutions that deploy them. The recreancy theorem argues that the public is more likely to trust and support decisions made or influenced by automated decision-making systems if the institutions that administer them meet their fiduciary responsibility. However, often the public is never informed of how these systems operate and resultant institutional decisions are made. A ``black box'' effect of automated decision-making systems reduces the public's perceptions of integrity and trustworthiness. The result is that the public loses the capacity to identify, challenge, and rectify unfairness or the costs associated with the loss of public goods or benefits.   The current position paper defines and explains the role of fiduciary responsibility within an automated decision-making system. We formulate an automated decision-making system as a data science lifecycle (DSL) and examine the implications of fiduciary responsibility within the context of the DSL. Fiduciary responsibility within DSLs provides a methodology for addressing the public's lack of trust in automated decision-making systems and the institutions that employ them to make decisions affecting the public. We posit that fiduciary responsibility manifests in several contexts of a DSL, each of which requires its own mitigation of sources of mistrust. To instantiate fiduciary responsibility, a Los Angeles Police Department (LAPD) predictive policing case study is examined. "
}