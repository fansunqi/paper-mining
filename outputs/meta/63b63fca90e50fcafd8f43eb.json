{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Confidential Computing across Edge-to-Cloud Continuum"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "ClusPr",
    "SAED",
    "Edge-MultiAI framework"
  ],
  "results": [
    "Cluster coherency improvement up to 30%-to-60%",
    "Context-aware and personalized semantic search",
    "Concurrent Deep Learning services management"
  ],
  "paper_id": "63b63fca90e50fcafd8f43eb",
  "title": "AI-Driven Confidential Computing across Edge-to-Cloud Continuum",
  "abstract": "  With the meteoric growth of technology, individuals and organizations are widely adopting cloud services to mitigate the burdens of maintenance. Despite its scalability and ease of use, many users who own sensitive data refrain from fully utilizing cloud services due to confidentiality concerns. Maintaining data confidentiality for data at rest and in transit has been widely explored but data remains vulnerable in the cloud while it is in use. This vulnerability is further elevated once the scope of computing spans across the edge-to-cloud continuum. Accordingly, the goal of this dissertation is to enable data confidentiality by adopting confidential computing across the continuum. Towards this goal, one approach we explore is to separate the intelligence aspect of data processing from the pattern-matching aspect. We present our approach to make confidential data clustering on the cloud, and then develop confidential search service across edge-to-cloud for unstructured text data. Our proposed clustering solution named ClusPr, performs topic-based clustering for static and dynamic datasets that improves cluster coherency up to 30%-to-60% when compared with other encryption-based clustering techniques. Our trusted enterprise search service named SAED, provides context-aware and personalized semantic search over confidential data across the continuum. We realized that enabling confidential computing across edge-to-cloud requires major contribution from the edge tiers particularly to run multiple Deep Learning (DL) services concurrently. This raises memory contention on the edge tier. To resolve this, we develop Edge-MultiAI framework to manage Neural Network (NN) models of DL applications such that it can meet the latency constraints of the DL applications without compromising inference accuracy. "
}