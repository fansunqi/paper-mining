{
  "code_links": [
    "None"
  ],
  "tasks": [
    "3D Generative Radiance Field Synthesis"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "3D-aware generative model",
    "progressive-scale patch discrimination"
  ],
  "results": [
    "Outperforms closest related works in quality and diversity"
  ],
  "paper_id": "63881b9290e50fcafd3db40b",
  "title": "SinGRAF: Learning a 3D Generative Radiance Field for a Single Scene",
  "abstract": "  Generative models have shown great promise in synthesizing photorealistic 3D objects, but they require large amounts of training data. We introduce SinGRAF, a 3D-aware generative model that is trained with a few input images of a single scene. Once trained, SinGRAF generates different realizations of this 3D scene that preserve the appearance of the input while varying scene layout. For this purpose, we build on recent progress in 3D GAN architectures and introduce a novel progressive-scale patch discrimination approach during training. With several experiments, we demonstrate that the results produced by SinGRAF outperform the closest related works in both quality and diversity by a large margin. "
}