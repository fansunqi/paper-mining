{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Explainable Artificial Intelligence"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Inductive Logic Programming (ILP)",
    "Statistical Relational Learning",
    "Neural-Symbolic Algorithms"
  ],
  "results": [
    "Summarizes recent advances in ILP",
    "Discusses challenges and potential research avenues for self-explanatory AI systems"
  ],
  "paper_id": "61d269395244ab9dcbc5f3d7",
  "title": "A Critical Review of Inductive Logic Programming Techniques for\n  Explainable AI",
  "abstract": "  Despite recent advances in modern machine learning algorithms, the opaqueness of their underlying mechanisms continues to be an obstacle in adoption. To instill confidence and trust in artificial intelligence systems, Explainable Artificial Intelligence has emerged as a response to improving modern machine learning algorithms' explainability. Inductive Logic Programming (ILP), a subfield of symbolic artificial intelligence, plays a promising role in generating interpretable explanations because of its intuitive logic-driven framework. ILP effectively leverages abductive reasoning to generate explainable first-order clausal theories from examples and background knowledge. However, several challenges in developing methods inspired by ILP need to be addressed for their successful application in practice. For example, existing ILP systems often have a vast solution space, and the induced solutions are very sensitive to noises and disturbances. This survey paper summarizes the recent advances in ILP and a discussion of statistical relational learning and neural-symbolic algorithms, which offer synergistic views to ILP. Following a critical review of the recent advances, we delineate observed challenges and highlight potential avenues of further ILP-motivated research toward developing self-explanatory artificial intelligence systems. "
}