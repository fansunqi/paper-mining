{
  "code_links": [
    "https://mea-lab-421.github.io"
  ],
  "tasks": [
    "Micro-expression Recognition (MER)"
  ],
  "datasets": [
    "DFME (Dynamic Facial Micro-expressions)"
  ],
  "methods": [
    "Spatiotemporal feature learning models"
  ],
  "results": [
    "DFME dataset facilitates MER research",
    "New benchmark for MER"
  ],
  "paper_id": "63b63fd190e50fcafd8f5754",
  "title": "More is Better: A Database for Spontaneous Micro-Expression with High\n  Frame Rates",
  "abstract": "  As one of the most important psychic stress reactions, micro-expressions (MEs), are spontaneous and transient facial expressions that can reveal the genuine emotions of human beings. Thus, recognizing MEs (MER) automatically is becoming increasingly crucial in the field of affective computing, and provides essential technical support in lie detection, psychological analysis and other areas. However, the lack of abundant ME data seriously restricts the development of cutting-edge data-driven MER models. Despite the recent efforts of several spontaneous ME datasets to alleviate this problem, it is still a tiny amount of work. To solve the problem of ME data hunger, we construct a dynamic spontaneous ME dataset with the largest current ME data scale, called DFME (Dynamic Facial Micro-expressions), which includes 7,526 well-labeled ME videos induced by 671 participants and annotated by more than 20 annotators throughout three years. Afterwards, we adopt four classical spatiotemporal feature learning models on DFME to perform MER experiments to objectively verify the validity of DFME dataset. In addition, we explore different solutions to the class imbalance and key-frame sequence sampling problems in dynamic MER respectively on DFME, so as to provide a valuable reference for future research. The comprehensive experimental results show that our DFME dataset can facilitate the research of automatic MER, and provide a new benchmark for MER. DFME will be published via https://mea-lab-421.github.io. "
}