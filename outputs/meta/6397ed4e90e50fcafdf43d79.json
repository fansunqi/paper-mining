{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Multimodal representation learning",
    "Image classification",
    "Visual grounding",
    "Cross-modal retrieval"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Multiple instance learning",
    "Permutation-invariant score functions",
    "Contrastive learning"
  ],
  "results": [
    "State-of-the-art results in several downstream tasks"
  ],
  "paper_id": "6397ed4e90e50fcafdf43d79",
  "title": "Using Multiple Instance Learning to Build Multimodal Representations",
  "abstract": "  Image-text multimodal representation learning aligns data across modalities and enables important medical applications, e.g., image classification, visual grounding, and cross-modal retrieval. In this work, we establish a connection between multimodal representation learning and multiple instance learning. Based on this connection, we propose a generic framework for constructing permutation-invariant score functions with many existing multimodal representation learning approaches as special cases. Furthermore, we use the framework to derive a novel contrastive learning approach and demonstrate that our method achieves state-of-the-art results in several downstream tasks. "
}