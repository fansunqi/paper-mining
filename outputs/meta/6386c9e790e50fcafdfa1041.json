{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Instance Segmentation of Surgical Instruments"
  ],
  "datasets": [
    "EndoVis2017",
    "EndoVis2018"
  ],
  "methods": [
    "Neural Network Framework with Classification Module",
    "Multi-scale Mask Attention",
    "Metric Learning with Arc Loss"
  ],
  "results": [
    "Outperforms all (more than 18) SOTA methods",
    "Improves SOTA performance by at least 12 points (20%) on EndoVis2017"
  ],
  "paper_id": "6386c9e790e50fcafdfa1041",
  "title": "From Forks to Forceps: A New Framework for Instance Segmentation of\n  Surgical Instruments",
  "abstract": "  Minimally invasive surgeries and related applications demand surgical tool classification and segmentation at the instance level. Surgical tools are similar in appearance and are long, thin, and handled at an angle. The fine-tuning of state-of-the-art (SOTA) instance segmentation models trained on natural images for instrument segmentation has difficulty discriminating instrument classes. Our research demonstrates that while the bounding box and segmentation mask are often accurate, the classification head mis-classifies the class label of the surgical instrument. We present a new neural network framework that adds a classification module as a new stage to existing instance segmentation models. This module specializes in improving the classification of instrument masks generated by the existing model. The module comprises multi-scale mask attention, which attends to the instrument region and masks the distracting background features. We propose training our classifier module using metric learning with arc loss to handle low inter-class variance of surgical instruments. We conduct exhaustive experiments on the benchmark datasets EndoVis2017 and EndoVis2018. We demonstrate that our method outperforms all (more than 18) SOTA methods compared with, and improves the SOTA performance by at least 12 points (20%) on the EndoVis2017 benchmark challenge and generalizes effectively across the datasets. "
}