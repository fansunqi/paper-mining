{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Speech Enhancement in Audio-Visual Hearing Aids"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Canonical Cortical Graph Neural Networks",
    "Multimodal information integration",
    "Canonical Correlation Analysis",
    "Memory mechanism"
  ],
  "results": [
    "Outperforms recent state-of-the-art models",
    "Reduced neuron firing rate distribution"
  ],
  "paper_id": "629ec1f95aee126c0fb704d0",
  "title": "Canonical Cortical Graph Neural Networks and its Application for Speech\n  Enhancement in Audio-Visual Hearing Aids",
  "abstract": "  Despite the recent success of machine learning algorithms, most models face drawbacks when considering more complex tasks requiring interaction between different sources, such as multimodal input data and logical time sequences. On the other hand, the biological brain is highly sharpened in this sense, empowered to automatically manage and integrate such streams of information. In this context, this work draws inspiration from recent discoveries in brain cortical circuits to propose a more biologically plausible self-supervised machine learning approach. This combines multimodal information using intra-layer modulations together with Canonical Correlation Analysis, and a memory mechanism to keep track of temporal data, the overall approach termed Canonical Cortical Graph Neural networks. This is shown to outperform recent state-of-the-art models in terms of clean audio reconstruction and energy efficiency for a benchmark audio-visual speech dataset. The enhanced performance is demonstrated through a reduced and smother neuron firing rate distribution. suggesting that the proposed model is amenable for speech enhancement in future audio-visual hearing aid devices. "
}