{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Robust variance-regularized risk minimization"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Modified variance-free robust mean estimation",
    "Standard gradient-based solvers"
  ],
  "results": [
    "Performs as well or better than CVaR or DRO risks"
  ],
  "paper_id": "63d7352390e50fcafda30348",
  "title": "Robust variance-regularized risk minimization with concomitant scaling",
  "abstract": "  Under losses which are potentially heavy-tailed, we consider the task of minimizing sums of the loss mean and standard deviation, without trying to accurately estimate the variance. By modifying a technique for variance-free robust mean estimation to fit our problem setting, we derive a simple learning procedure which can be easily combined with standard gradient-based solvers to be used in traditional machine learning workflows. Empirically, we verify that our proposed approach, despite its simplicity, performs as well or better than even the best-performing candidates derived from alternative criteria such as CVaR or DRO risks on a variety of datasets. "
}