{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Generalized Private Selection and Testing"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Exponential mechanism",
    "Sparse vector technique",
    "Private selection framework",
    "Private testing"
  ],
  "results": [
    "Improved utility guarantee",
    "Improved accuracy/confidence trade-off",
    "Adaptive query releasing mechanism"
  ],
  "paper_id": "637d8f5c90e50fcafd6e6ef8",
  "title": "Generalized Private Selection and Testing with High Confidence",
  "abstract": "  Composition theorems are general and powerful tools that facilitate privacy accounting across multiple data accesses from per-access privacy bounds. However they often result in weaker bounds compared with end-to-end analysis. Two popular tools that mitigate that are the exponential mechanism (or report noisy max) and the sparse vector technique. They were generalized in a couple of recent private selection/test frameworks, including the work by Liu and Talwar (STOC 2019), and Papernot and Steinke (ICLR 2022).   In this work, we first present an alternative framework for private selection and testing with a simpler privacy proof and equally-good utility guarantee. Second, we observe that the private selection framework (both previous ones and ours) can be applied to improve the accuracy/confidence trade-off for many fundamental privacy-preserving data-analysis tasks, including query releasing, top-$k$ selection, and stable selection.   Finally, for online settings, we apply the private testing to design a mechanism for adaptive query releasing, which improves the sample complexity dependence on the confidence parameter for the celebrated private multiplicative weights algorithm of Hardt and Rothblum (FOCS 2010). "
}