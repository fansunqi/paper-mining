{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Backdoor injection attack on DNN models"
  ],
  "datasets": [
    "CIFAR-10"
  ],
  "methods": [
    "Rowhammer-based fault injection",
    "Constrained optimization for network training"
  ],
  "results": [
    "ResNet-20 model achieves over 89% test accuracy and 92% attack success rate by flipping only 10 out of 2.2 million bits"
  ],
  "paper_id": "616ce5a05244ab9dcbacfaef",
  "title": "Don't Knock! Rowhammer at the Backdoor of DNN Models",
  "abstract": "  State-of-the-art deep neural networks (DNNs) have been proven to be vulnerable to adversarial manipulation and backdoor attacks. Backdoored models deviate from expected behavior on inputs with predefined triggers while retaining performance on clean data. Recent works focus on software simulation of backdoor injection during the inference phase by modifying network weights, which we find often unrealistic in practice due to restrictions in hardware.   In contrast, in this work for the first time, we present an end-to-end backdoor injection attack realized on actual hardware on a classifier model using Rowhammer as the fault injection method. To this end, we first investigate the viability of backdoor injection attacks in real-life deployments of DNNs on hardware and address such practical issues in hardware implementation from a novel optimization perspective. We are motivated by the fact that vulnerable memory locations are very rare, device-specific, and sparsely distributed. Consequently, we propose a novel network training algorithm based on constrained optimization to achieve a realistic backdoor injection attack in hardware. By modifying parameters uniformly across the convolutional and fully-connected layers as well as optimizing the trigger pattern together, we achieve state-of-the-art attack performance with fewer bit flips. For instance, our method on a hardware-deployed ResNet-20 model trained on CIFAR-10 achieves over 89% test accuracy and 92% attack success rate by flipping only 10 out of 2.2 million bits. "
}