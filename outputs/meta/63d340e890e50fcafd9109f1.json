{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Event segmentation in narrative text"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "GPT-3"
  ],
  "results": [
    "GPT-3-annotated events are significantly correlated with human event annotations",
    "GPT-derived annotations achieve a good approximation of the 'consensus' solution",
    "Boundaries identified by GPT-3 are closer to the consensus than individual human annotators"
  ],
  "paper_id": "63d340e890e50fcafd9109f1",
  "title": "Large language models can segment narrative events similarly to humans",
  "abstract": "  Humans perceive discrete events such as \"restaurant visits\" and \"train rides\" in their continuous experience. One important prerequisite for studying human event perception is the ability of researchers to quantify when one event ends and another begins. Typically, this information is derived by aggregating behavioral annotations from several observers. Here we present an alternative computational approach where event boundaries are derived using a large language model, GPT-3, instead of using human annotations. We demonstrate that GPT-3 can segment continuous narrative text into events. GPT-3-annotated events are significantly correlated with human event annotations. Furthermore, these GPT-derived annotations achieve a good approximation of the \"consensus\" solution (obtained by averaging across human annotations); the boundaries identified by GPT-3 are closer to the consensus, on average, than boundaries identified by individual human annotators. This finding suggests that GPT-3 provides a feasible solution for automated event annotations, and it demonstrates a further parallel between human cognition and prediction in large language models. In the future, GPT-3 may thereby help to elucidate the principles underlying human event perception. "
}