{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Short-timescale predictions in data communications networks"
  ],
  "datasets": [
    "synthetic networking datasets",
    "real-world networking datasets"
  ],
  "methods": [
    "Physics Constrained Flow Neural Network (FlowNN)",
    "Induction layer for physics connected data correlations",
    "Self-supervised learning with stop-gradient"
  ],
  "results": [
    "17% - 71% loss decrease compared to state-of-the-art baselines"
  ],
  "paper_id": "61c53a805244ab9dcbcaf15c",
  "title": "Physics Constrained Flow Neural Network for Short-Timescale Predictions\n  in Data Communications Networks",
  "abstract": "  Machine learning is gaining growing momentum in various recent models for the dynamic analysis of information flows in data communications networks. These preliminary models often rely on off-the-shelf learning models to predict from historical statistics while disregarding the physics governing the generating behaviors of these flows. This paper instead introduces Flow Neural Network (FlowNN) to improve the feature representation with learned physical bias. This is implemented by an induction layer, working upon the embedding layer, to impose the physics connected data correlations, and a self-supervised learning strategy with stop-gradient to make the learned physics universal. For the short-timescale network prediction tasks, FlowNN achieves 17% - 71% of loss decrease than the state-of-the-art baselines on both synthetic and real-world networking datasets, which shows the strength of this new approach. "
}