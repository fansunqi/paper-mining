{
  "code_links": [
    "https://mvig-rhos.com/ocl"
  ],
  "tasks": [
    "Object Concept Learning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Object Concept Reasoning Network (OCRN)",
    "causal intervention",
    "concept instantiation"
  ],
  "results": [
    "OCRN effectively infers the object knowledge while following the causalities well"
  ],
  "paper_id": "6390044c90e50fcafd837d65",
  "title": "Beyond Object Recognition: A New Benchmark towards Object Concept\n  Learning",
  "abstract": "  Understanding objects is a central building block of artificial intelligence, especially for embodied AI. Even though object recognition excels with deep learning, current machines still struggle to learn higher-level knowledge, e.g., what attributes an object has, and what can we do with an object. In this work, we propose a challenging Object Concept Learning (OCL) task to push the envelope of object understanding. It requires machines to reason out object affordances and simultaneously give the reason: what attributes make an object possesses these affordances. To support OCL, we build a densely annotated knowledge base including extensive labels for three levels of object concept (category, attribute, affordance), and the causal relations of three levels. By analyzing the causal structure of OCL, we present a baseline, Object Concept Reasoning Network (OCRN). It leverages causal intervention and concept instantiation to infer the three levels following their causal relations. In experiments, OCRN effectively infers the object knowledge while following the causalities well. Our data and code are available at https://mvig-rhos.com/ocl. "
}