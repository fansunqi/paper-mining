{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Lost and found item identification"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Photo matching network (combining fine-tuning of MobileNetv2 with CBAM Attention)"
  ],
  "results": [
    "Testing accuracy: 96.8%, 665.12M GLFOPs, 3.5M training parameters"
  ],
  "paper_id": "63bb859d90e50fcafd06edbd",
  "title": "LostNet: A smart way for lost and find",
  "abstract": "  Due to the enormous population growth of cities in recent years, objects are frequently lost and unclaimed on public transportation, in restaurants, or any other public areas. While services like Find My iPhone can easily identify lost electronic devices, more valuable objects cannot be tracked in an intelligent manner, making it impossible for administrators to reclaim a large number of lost and found items in a timely manner. We present a method that significantly reduces the complexity of searching by comparing previous images of lost and recovered things provided by the owner with photos taken when registered lost and found items are received. In this research, we will primarily design a photo matching network by combining the fine-tuning method of MobileNetv2 with CBAM Attention and using the Internet framework to develop an online lost and found image identification system. Our implementation gets a testing accuracy of 96.8% using only 665.12M GLFOPs and 3.5M training parameters. It can recognize practice images and can be run on a regular laptop. "
}