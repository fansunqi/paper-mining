{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Multifidelity forward uncertainty quantification (UQ)"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Multilevel best linear unbiased estimators (MLBLUE)",
    "Semidefinite programming"
  ],
  "results": [
    "Optimal number of samples",
    "Optimal selection of low-fidelity models"
  ],
  "paper_id": "63ca069790e50fcafd683033",
  "title": "Multi-output multilevel best linear unbiased estimators via semidefinite\n  programming",
  "abstract": "  Multifidelity forward uncertainty quantification (UQ) problems often involve multiple quantities of interest and heterogeneous models (e.g., different grids, equations, dimensions, physics, surrogate and reduced-order models). While computational efficiency is key in this context, multi-output strategies in multilevel/multifidelity methods are either sub-optimal or non-existent. In this paper we extend multilevel best linear unbiased estimators (MLBLUE) to multi-output forward UQ problems and we present new semidefinite programming formulations for their optimal setup. Not only do these formulations yield the optimal number of samples required, but also the optimal selection of low-fidelity models to use. While existing MLBLUE approaches are single-output only and require a non-trivial nonlinear optimization procedure, the new multi-output formulations can be solved reliably and efficiently. We demonstrate the efficacy of the new methods and formulations in practical UQ problems with model heterogeneity. "
}