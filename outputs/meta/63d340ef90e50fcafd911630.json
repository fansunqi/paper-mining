{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Neuromorphic spintronics",
    "Waveform classification",
    "Speech recognition",
    "Image recognition"
  ],
  "datasets": [
    "TI-46",
    "MNIST"
  ],
  "methods": [
    "Neural network based on STVO",
    "Thiele equation approach",
    "Reservoir computing"
  ],
  "results": [
    "High accuracy and low root-mean-square error in waveform classification",
    "Agreement between new models and experimental measurements in speech recognition",
    "State-of-the-art performances in image recognition"
  ],
  "paper_id": "63d340ef90e50fcafd911630",
  "title": "Neuromorphic spintronics accelerated by an unconventional data-driven\n  Thiele equation approach",
  "abstract": "  We design a neural network based on a single spin-torque vortex nano-oscillator (STVO) multiplexed in time. The behavior of the STVO is simulated with an improved ultra-fast and quantitative model based on the Thiele equation approach. Different mathematical and numerical adaptations are brought to the model in order to increase the accuracy and the speed of the simulations. We demonstrate the high added value and adaptability of such a neural network through the resolution of three standard machine learning tasks in the framework of reservoir computing. The first one is a task of waveform (sines and squares) classification. We show the ability of the system to effectively classify waveforms with high accuracy and low root-mean-square error thanks to the intrinsic short-term memory of the device. Given the high throughput of the simulations, two innovative parametric studies on the intensity of the input signal and the level of noise in the system are performed to demonstrate the value of our new models. The efficiency of our system is then tested during a speech recognition task on the TI-46 dataset and shows the agreement between the new models and the corresponding experimental measurements. Finally, we use our STVO-based neural network to perform image recognition on the MNIST dataset. State-of-the-art performances are demonstrated, and the interest of using the STVO dynamics as an activation function is highlighted. These results support and facilitate the future development of neuromorphic STVO-based hardware for energy-efficient machine learning. "
}