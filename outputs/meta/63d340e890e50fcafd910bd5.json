{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Motion Planning with Separated Path and Velocity Preferences"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Incremental Inverse Reinforcement Learning",
    "Parameterized features for motion preferences"
  ],
  "results": [
    "Non-expert users can teach preferences with few iterations"
  ],
  "paper_id": "63d340e890e50fcafd910bd5",
  "title": "An Incremental Inverse Reinforcement Learning Approach for Motion\n  Planning with Separated Path and Velocity Preferences",
  "abstract": "  Humans often demonstrate diverse behaviors due to their personal preferences, for instance, related to their individual execution style or personal margin for safety. In this paper, we consider the problem of integrating both path and velocity preferences into trajectory planning for robotic manipulators. We first learn reward functions that represent the user path and velocity preferences from kinesthetic demonstration. We then optimize the trajectory in two steps: first the path and then the velocity, to produce trajectories that adhere to both task requirements and user preferences. We design a set of parameterized features that capture the fundamental preferences in a pick-and-place type of object-transportation task, both in shape and timing of the motion. We demonstrate that our method is capable of generalizing such preferences to new scenarios. We implement our algorithm on a Franka Emika 7-DoF robot arm, and validate the functionality and flexibility of our approach in a user study. The results show that non-expert users are able to teach the robot their preferences with just a few iterations of feedback. "
}