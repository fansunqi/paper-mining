{
  "code_links": [
    "https://github.com/THUYimingLi/DVBW"
  ],
  "tasks": [
    "Black-box Dataset Ownership Verification"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Backdoor Watermarking",
    "Poison-only backdoor attacks (e.g., BadNets)",
    "Hypothesis-test-guided method"
  ],
  "results": [
    "None"
  ],
  "paper_id": "6321467390e50fcafdb9bde5",
  "title": "Black-box Dataset Ownership Verification via Backdoor Watermarking",
  "abstract": "  Deep learning, especially deep neural networks (DNNs), has been widely and successfully adopted in many critical applications for its high effectiveness and efficiency. The rapid development of DNNs has benefited from the existence of some high-quality datasets ($e.g.$, ImageNet), which allow researchers and developers to easily verify the performance of their methods. Currently, almost all existing released datasets require that they can only be adopted for academic or educational purposes rather than commercial purposes without permission. However, there is still no good way to ensure that. In this paper, we formulate the protection of released datasets as verifying whether they are adopted for training a (suspicious) third-party model, where defenders can only query the model while having no information about its parameters and training details. Based on this formulation, we propose to embed external patterns via backdoor watermarking for the ownership verification to protect them. Our method contains two main parts, including dataset watermarking and dataset verification. Specifically, we exploit poison-only backdoor attacks ($e.g.$, BadNets) for dataset watermarking and design a hypothesis-test-guided method for dataset verification. We also provide some theoretical analyses of our methods. Experiments on multiple benchmark datasets of different tasks are conducted, which verify the effectiveness of our method. The code for reproducing main experiments is available at \\url{https://github.com/THUYimingLi/DVBW}. "
}