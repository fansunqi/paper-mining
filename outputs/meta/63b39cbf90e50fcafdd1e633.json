{
  "code_links": [
    "https://med-air.github.io/SurRoL/"
  ],
  "tasks": [
    "Surgical robot learning"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Interactive simulation platform",
    "Reinforcement learning"
  ],
  "results": [
    "None"
  ],
  "paper_id": "63b39cbf90e50fcafdd1e633",
  "title": "Human-in-the-loop Embodied Intelligence with Interactive Simulation\n  Environment for Surgical Robot Learning",
  "abstract": "  Surgical robot automation has attracted increasing research interest over the past decade, expecting its huge potential to benefit surgeons, nurses and patients. Recently, the learning paradigm of embodied AI has demonstrated promising ability to learn good control policies for various complex tasks, where embodied AI simulators play an essential role to facilitate relevant researchers. However, existing open-sourced simulators for surgical robot are still not sufficiently supporting human interactions through physical input devices, which further limits effective investigations on how human demonstrations would affect policy learning. In this paper, we study human-in-the-loop embodied intelligence with a new interactive simulation platform for surgical robot learning. Specifically, we establish our platform based on our previously released SurRoL simulator with several new features co-developed to allow high-quality human interaction via an input device. With these, we further propose to collect human demonstrations and imitate the action patterns to achieve more effective policy learning. We showcase the improvement of our simulation environment with the designed new features and tasks, and validate state-of-the-art reinforcement learning algorithms using the interactive environment. Promising results are obtained, with which we hope to pave the way for future research on surgical embodied intelligence. Our platform is released and will be continuously updated in the website: https://med-air.github.io/SurRoL/ "
}