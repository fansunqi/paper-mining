{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Multi-agent reinforcement learning",
    "Stochastic games"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Satisficing paths",
    "Independent learning algorithm"
  ],
  "results": [
    "Existence of \u03b5-satisficing paths into \u03b5-equilibrium",
    "High probability guarantees of convergence to \u03b5-equilibrium under self-play"
  ],
  "paper_id": "6164fcc15244ab9dcb24d024",
  "title": "Satisficing Paths and Independent Multi-Agent Reinforcement Learning in\n  Stochastic Games",
  "abstract": "  In multi-agent reinforcement learning (MARL), independent learners are those that do not observe the actions of other agents in the system. Due to the decentralization of information, it is challenging to design independent learners that drive play to equilibrium. This paper investigates the feasibility of using satisficing dynamics to guide independent learners to approximate equilibrium in stochastic games. For $\\epsilon \\geq 0$, an $\\epsilon$-satisficing policy update rule is any rule that instructs the agent to not change its policy when it is $\\epsilon$-best-responding to the policies of the remaining players; $\\epsilon$-satisficing paths are defined to be sequences of joint policies obtained when each agent uses some $\\epsilon$-satisficing policy update rule to select its next policy. We establish structural results on the existence of $\\epsilon$-satisficing paths into $\\epsilon$-equilibrium in both symmetric $N$-player games and general stochastic games with two players. We then present an independent learning algorithm for $N$-player symmetric games and give high probability guarantees of convergence to $\\epsilon$-equilibrium under self-play. This guarantee is made using symmetry alone, leveraging the previously unexploited structure of $\\epsilon$-satisficing paths. "
}