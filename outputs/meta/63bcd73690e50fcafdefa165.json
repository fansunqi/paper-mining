{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Automatic generation of German drama texts"
  ],
  "datasets": [
    "German Drama Corpus (GerDraCor)",
    "German Text Archive (Deutsches Textarchiv or DTA)"
  ],
  "methods": [
    "Fine-tuning GPT-2 models"
  ],
  "results": [
    "Automatic quantitative evaluation shows good performance",
    "Manual qualitative analysis reveals poor quality of generated texts"
  ],
  "paper_id": "63bcd73690e50fcafdefa165",
  "title": "Automatic Generation of German Drama Texts Using Fine Tuned GPT-2 Models",
  "abstract": "  This study is devoted to the automatic generation of German drama texts. We suggest an approach consisting of two key steps: fine-tuning a GPT-2 model (the outline model) to generate outlines of scenes based on keywords and fine-tuning a second model (the generation model) to generate scenes from the scene outline. The input for the neural model comprises two datasets: the German Drama Corpus (GerDraCor) and German Text Archive (Deutsches Textarchiv or DTA). In order to estimate the effectiveness of the proposed method, our models are compared with baseline GPT-2 models. Our models perform well according to automatic quantitative evaluation, but, conversely, manual qualitative analysis reveals a poor quality of generated texts. This may be due to the quality of the dataset or training inputs. "
}