{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Markerless estimation of 3D Kinematics"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Deep neural networks for direct 3D human kinematic estimation"
  ],
  "results": [
    "Joint angles error reduced by 35% (from 5.44 to 3.54 degrees) compared to 2D and 3D markerless motion capture"
  ],
  "paper_id": "63c4c02990e50fcafdadfff7",
  "title": "Towards Single Camera Human 3D-Kinematics",
  "abstract": "  Markerless estimation of 3D Kinematics has the great potential to clinically diagnose and monitor movement disorders without referrals to expensive motion capture labs; however, current approaches are limited by performing multiple de-coupled steps to estimate the kinematics of a person from videos. Most current techniques work in a multi-step approach by first detecting the pose of the body and then fitting a musculoskeletal model to the data for accurate kinematic estimation. Errors in training data of the pose detection algorithms, model scaling, as well the requirement of multiple cameras limit the use of these techniques in a clinical setting. Our goal is to pave the way toward fast, easily applicable and accurate 3D kinematic estimation \\xdeleted{in a clinical setting}. To this end, we propose a novel approach for direct 3D human kinematic estimation D3KE from videos using deep neural networks. Our experiments demonstrate that the proposed end-to-end training is robust and outperforms 2D and 3D markerless motion capture based kinematic estimation pipelines in terms of joint angles error by a large margin (35\\% from 5.44 to 3.54 degrees). We show that D3KE is superior to the multi-step approach and can run at video framerate speeds. This technology shows the potential for clinical analysis from mobile devices in the future. "
}