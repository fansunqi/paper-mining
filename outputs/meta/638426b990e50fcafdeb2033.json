{
  "code_links": [
    "https://github.com/Talented-Q/IFER-master"
  ],
  "tasks": [
    "Facial expression recognition"
  ],
  "datasets": [
    "FFHQ",
    "CelebA-HQ",
    "RAF-DB",
    "SFEW",
    "AffectNet"
  ],
  "methods": [
    "Adversarial Style Inversion Transformer (ASIT)",
    "image inversion discriminator",
    "feature modulation module"
  ],
  "results": [
    "state-of-the-art facial inversion performance",
    "competitive results in facial expression recognition datasets"
  ],
  "paper_id": "638426b990e50fcafdeb2033",
  "title": "More comprehensive facial inversion for more effective expression\n  recognition",
  "abstract": "  Facial expression recognition (FER) plays a significant role in the ubiquitous application of computer vision. We revisit this problem with a new perspective on whether it can acquire useful representations that improve FER performance in the image generation process, and propose a novel generative method based on the image inversion mechanism for the FER task, termed Inversion FER (IFER). Particularly, we devise a novel Adversarial Style Inversion Transformer (ASIT) towards IFER to comprehensively extract features of generated facial images. In addition, ASIT is equipped with an image inversion discriminator that measures the cosine similarity of semantic features between source and generated images, constrained by a distribution alignment loss. Finally, we introduce a feature modulation module to fuse the structural code and latent codes from ASIT for the subsequent FER work. We extensively evaluate ASIT on facial datasets such as FFHQ and CelebA-HQ, showing that our approach achieves state-of-the-art facial inversion performance. IFER also achieves competitive results in facial expression recognition datasets such as RAF-DB, SFEW and AffectNet. The code and models are available at https://github.com/Talented-Q/IFER-master. "
}