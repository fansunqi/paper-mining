{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Network Slicing",
    "Resource Management"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Transfer Learning",
    "Distributed Deep Reinforcement Learning",
    "Multi-Agent Deep Reinforcement Learning",
    "Inter-agent Similarity Analysis"
  ],
  "results": [
    "Outperforms state-of-the-art solutions",
    "27% higher gain than coordinate MADRL without TL"
  ],
  "paper_id": "63bcd73690e50fcafdefa231",
  "title": "Network Slicing via Transfer Learning aided Distributed Deep\n  Reinforcement Learning",
  "abstract": "  Deep reinforcement learning (DRL) has been increasingly employed to handle the dynamic and complex resource management in network slicing. The deployment of DRL policies in real networks, however, is complicated by heterogeneous cell conditions. In this paper, we propose a novel transfer learning (TL) aided multi-agent deep reinforcement learning (MADRL) approach with inter-agent similarity analysis for inter-cell inter-slice resource partitioning. First, we design a coordinated MADRL method with information sharing to intelligently partition resource to slices and manage inter-cell interference. Second, we propose an integrated TL method to transfer the learned DRL policies among different local agents for accelerating the policy deployment. The method is composed of a new domain and task similarity measurement approach and a new knowledge transfer approach, which resolves the problem of from whom to transfer and how to transfer. We evaluated the proposed solution with extensive simulations in a system-level simulator and show that our approach outperforms the state-of-the-art solutions in terms of performance, convergence speed and sample efficiency. Moreover, by applying TL, we achieve an additional gain over 27% higher than the coordinate MADRL approach without TL. "
}