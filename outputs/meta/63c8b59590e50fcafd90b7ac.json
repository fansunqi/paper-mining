{
  "code_links": [
    "https://github.com/IN2-ViAUn/DR-WLC"
  ],
  "tasks": [
    "object detection",
    "pose estimation"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "dimensionality reduction cognitive model",
    "bounding boxes generation strategy"
  ],
  "results": [
    "qualifies work without manual annotations",
    "easy to deploy for practical applications"
  ],
  "paper_id": "63c8b59590e50fcafd90b7ac",
  "title": "DR-WLC: Dimensionality Reduction cognition for object detection and pose\n  estimation by Watching, Learning and Checking",
  "abstract": "  Object detection and pose estimation are difficult tasks in robotics and autonomous driving. Existing object detection and pose estimation methods mostly adopt the same-dimensional data for training. For example, 2D object detection usually requires a large amount of 2D annotation data with high cost. Using high-dimensional information to supervise lower-dimensional tasks is a feasible way to reduce datasets size. In this work, the DR-WLC, a dimensionality reduction cognitive model, which can perform both object detection and pose estimation tasks at the same time is proposed. The model only requires 3D model of objects and unlabeled environment images (with or without objects) to finish the training. In addition, a bounding boxes generation strategy is also proposed to build the relationship between 3D model and 2D object detection task. Experiments show that our method can qualify the work without any manual annotations and it is easy to deploy for practical applications. Source code is at https://github.com/IN2-ViAUn/DR-WLC. "
}