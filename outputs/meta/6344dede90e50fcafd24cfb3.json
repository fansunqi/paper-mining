{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Tabular data synthesis"
  ],
  "datasets": [
    "15 benchmark tabular datasets"
  ],
  "methods": [
    "Score-based Tabular data Synthesis (STaSy)",
    "self-paced learning technique",
    "fine-tuning strategy",
    "denoising score matching training"
  ],
  "results": [
    "Outperforms existing methods in terms of task-dependant evaluations",
    "Improved diversity"
  ],
  "paper_id": "6344dede90e50fcafd24cfb3",
  "title": "STaSy: Score-based Tabular data Synthesis",
  "abstract": "  Tabular data synthesis is a long-standing research topic in machine learning. Many different methods have been proposed over the past decades, ranging from statistical methods to deep generative methods. However, it has not always been successful due to the complicated nature of real-world tabular data. In this paper, we present a new model named Score-based Tabular data Synthesis (STaSy) and its training strategy based on the paradigm of score-based generative modeling. Despite the fact that score-based generative models have resolved many issues in generative models, there still exists room for improvement in tabular data synthesis. Our proposed training strategy includes a self-paced learning technique and a fine-tuning strategy, which further increases the sampling quality and diversity by stabilizing the denoising score matching training. Furthermore, we also conduct rigorous experimental studies in terms of the generative task trilemma: sampling quality, diversity, and time. In our experiments with 15 benchmark tabular datasets and 7 baselines, our method outperforms existing methods in terms of task-dependant evaluations and diversity. "
}