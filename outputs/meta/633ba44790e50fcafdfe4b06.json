{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Question answering over knowledge bases"
  ],
  "datasets": [
    "WebQSP",
    "FreebaseQA",
    "GrailQA",
    "ComplexWebQuestions"
  ],
  "methods": [
    "DecAF: Joint Decoding of Answers and Logical Forms"
  ],
  "results": [
    "New state-of-the-art accuracy on WebQSP, FreebaseQA, and GrailQA benchmarks",
    "Competitive results on the ComplexWebQuestions benchmark"
  ],
  "paper_id": "633ba44790e50fcafdfe4b06",
  "title": "DecAF: Joint Decoding of Answers and Logical Forms for Question\n  Answering over Knowledge Bases",
  "abstract": "  Question answering over knowledge bases (KBs) aims to answer natural language questions with factual information such as entities and relations in KBs. Previous methods either generate logical forms that can be executed over KBs to obtain final answers or predict answers directly. Empirical results show that the former often produces more accurate answers, but it suffers from non-execution issues due to potential syntactic and semantic errors in the generated logical forms. In this work, we propose a novel framework DecAF that jointly generates both logical forms and direct answers, and then combines the merits of them to get the final answers. Moreover, different from most of the previous methods, DecAF is based on simple free-text retrieval without relying on any entity linking tools -- this simplification eases its adaptation to different datasets. DecAF achieves new state-of-the-art accuracy on WebQSP, FreebaseQA, and GrailQA benchmarks, while getting competitive results on the ComplexWebQuestions benchmark. "
}