{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Online Backfilling in Large-Scale Retrieval"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Distance rank merge technique",
    "Reverse transformation module",
    "Metric-compatible contrastive learning"
  ],
  "results": [
    "Progressive performance improvement during backfilling",
    "No extra computational overhead"
  ],
  "paper_id": "63be28d490e50fcafdf52bd6",
  "title": "Metric Compatible Training for Online Backfilling in Large-Scale Retrieval",
  "abstract": "Backfilling is the process of re-extracting all gallery embeddings from upgraded models in image retrieval systems. It inevitably requires a prohibitively large amount of computational cost and even entails the downtime of the service. Although backward-compatible learning sidesteps this challenge by tackling query-side representations, this leads to suboptimal solutions in principle because gallery embeddings cannot benefit from model upgrades. We address this dilemma by introducing an online backfilling algorithm, which enables us to achieve a progressive performance improvement during the backfilling process while not sacrificing the final performance of new model after the completion of backfilling. To this end, we first propose a simple distance rank merge technique for online backfilling. Then, we incorporate a reverse transformation module for more effective and efficient merging, which is further enhanced by adopting a metric-compatible contrastive learning approach. These two components help to make the distances of old and new models compatible, resulting in desirable merge results during backfilling with no extra computational overhead. Extensive experiments show the effectiveness of our framework on four standard benchmarks in various settings."
}