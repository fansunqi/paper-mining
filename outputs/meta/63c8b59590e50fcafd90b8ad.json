{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Complex Activity Recognition"
  ],
  "datasets": [
    "Smartphone sensing dataset"
  ],
  "methods": [
    "Deep learning-based, binary classification"
  ],
  "results": [
    "AUROC scores up to 0.76"
  ],
  "paper_id": "63c8b59590e50fcafd90b8ad",
  "title": "Your Day in Your Pocket: Complex Activity Recognition from Smartphone\n  Accelerometers",
  "abstract": "  Human Activity Recognition (HAR) enables context-aware user experiences where mobile apps can alter content and interactions depending on user activities. Hence, smartphones have become valuable for HAR as they allow large, and diversified data collection. Although previous work in HAR managed to detect simple activities (i.e., sitting, walking, running) with good accuracy using inertial sensors (i.e., accelerometer), the recognition of complex daily activities remains an open problem, specially in remote work/study settings when people are more sedentary. Moreover, understanding the everyday activities of a person can support the creation of applications that aim to support their well-being. This paper investigates the recognition of complex activities exclusively using smartphone accelerometer data. We used a large smartphone sensing dataset collected from over 600 users in five countries during the pandemic and showed that deep learning-based, binary classification of eight complex activities (sleeping, eating, watching videos, online communication, attending a lecture, sports, shopping, studying) can be achieved with AUROC scores up to 0.76 with partially personalized models. This shows encouraging signs toward assessing complex activities only using phone accelerometer data in the post-pandemic world. "
}