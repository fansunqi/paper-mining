{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Weakly supervised Video Anomaly Detection"
  ],
  "datasets": [
    "UCF-Crime",
    "ShanghaiTech",
    "IITB-Corridor"
  ],
  "methods": [
    "Human-Scene Network",
    "self-rectifying loss"
  ],
  "results": [
    "Outperforms state-of-the-art approaches on five out of six scenarios"
  ],
  "paper_id": "63ca069890e50fcafd6830b4",
  "title": "Human-Scene Network: A Novel Baseline with Self-rectifying Loss for\n  Weakly supervised Video Anomaly Detection",
  "abstract": "  Video anomaly detection in surveillance systems with only video-level labels (i.e. weakly-supervised) is challenging. This is due to, (i) the complex integration of human and scene based anomalies comprising of subtle and sharp spatio-temporal cues in real-world scenarios, (ii) non-optimal optimization between normal and anomaly instances under weak supervision. In this paper, we propose a Human-Scene Network to learn discriminative representations by capturing both subtle and strong cues in a dissociative manner. In addition, a self-rectifying loss is also proposed that dynamically computes the pseudo temporal annotations from video-level labels for optimizing the Human-Scene Network effectively. The proposed Human-Scene Network optimized with self-rectifying loss is validated on three publicly available datasets i.e. UCF-Crime, ShanghaiTech and IITB-Corridor, outperforming recently reported state-of-the-art approaches on five out of the six scenarios considered. "
}