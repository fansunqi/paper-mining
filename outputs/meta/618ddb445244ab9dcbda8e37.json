{
  "code_links": [
    "None"
  ],
  "tasks": [
    "Illustrating concept-emerging phenomenon in trained DNNs"
  ],
  "datasets": [
    "None"
  ],
  "methods": [
    "Disentangling inference score into few interactive concepts",
    "Using sparse, symbolic causal graph to explain DNN",
    "Simplifying causal graph to And-Or graph (AOG)"
  ],
  "results": [
    "Causal graph can mimic DNN's outputs on exponential number of masked samples",
    "AOG retains explanation accuracy"
  ],
  "paper_id": "618ddb445244ab9dcbda8e37",
  "title": "Defining and Quantifying the Emergence of Sparse Concepts in DNNs",
  "abstract": "  This paper aims to illustrate the concept-emerging phenomenon in a trained DNN. Specifically, we find that the inference score of a DNN can be disentangled into the effects of a few interactive concepts. These concepts can be understood as causal patterns in a sparse, symbolic causal graph, which explains the DNN. The faithfulness of using such a causal graph to explain the DNN is theoretically guaranteed, because we prove that the causal graph can well mimic the DNN's outputs on an exponential number of different masked samples. Besides, such a causal graph can be further simplified and re-written as an And-Or graph (AOG), without losing much explanation accuracy. "
}